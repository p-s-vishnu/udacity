{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Classifier Project - Modified - v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "7MDFp5bA3Kth",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Developing an AI application\n",
        "\n",
        "Going forward, AI algorithms will be incorporated into more and more everyday applications. For example, you might want to include an image classifier in a smart phone app. To do this, you'd use a deep learning model trained on hundreds of thousands of images as part of the overall application architecture. A large part of software development in the future will be using these types of models as common parts of applications. \n",
        "\n",
        "In this project, you'll train an image classifier to recognize different species of flowers. You can imagine using something like this in a phone app that tells you the name of the flower your camera is looking at. In practice you'd train this classifier, then export it for use in your application. We'll be using [this dataset](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/index.html) of 102 flower categories, you can see a few examples below. \n",
        "\n",
        "<img src='https://github.com/udacity/pytorch_challenge/blob/master/assets/Flowers.png?raw=1' width=500px>\n",
        "\n",
        "The project is broken down into multiple steps:\n",
        "\n",
        "* Load and preprocess the image dataset\n",
        "* Train the image classifier on your dataset\n",
        "* Use the trained classifier to predict image content\n",
        "\n",
        "We'll lead you through each part which you'll implement in Python.\n",
        "\n",
        "**When you've completed this project, you'll have an application that can be trained on any set of labeled images.** Here your network will be learning about flowers and end up as a command line application. But, what you do with your new skills depends on your imagination and effort in building a dataset. For example, imagine an app where you take a picture of a car, it tells you what the make and model is, then looks up information about it. Go build your own dataset and make something new.\n",
        "\n",
        "First up is importing the packages you'll need. It's good practice to keep all the imports at the beginning of your code. As you work through this notebook and find you need to import a package, make sure to add the import up here."
      ]
    },
    {
      "metadata": {
        "id": "bQ0VpMDB68bR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tips, Model Performance, Submission Troubleshooting, etc \n",
        "\n",
        "The amazing people at Slack have compiled an amazing list of tips for this project. Check it here - [link](https://docs.google.com/document/d/1-MCDPOejsn2hq9EoBzMpzGv9jEdtMWoIwjkAa1cVbSM/edit#heading=h.yspy8tt3f0xe)"
      ]
    },
    {
      "metadata": {
        "id": "4IX8JftM5ZLy",
        "colab_type": "code",
        "outputId": "5fd7dc40-5d58-49d1-c2d0-634a609a6f91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# google colab does not come with torch installed. And also, in course we are using torch 0.4. \n",
        "# so following snippet of code installs the relevant version\n",
        "\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x57620000 @  0x7f7d30eae2a4 0x591a07 0x5b5d56 0x502e9a 0x506859 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x502209 0x502f3d 0x506859 0x504c28 0x502540 0x502f3d 0x507641 0x504c28 0x502540 0x502f3d 0x507641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gcQnqSIu5aQq",
        "colab_type": "code",
        "outputId": "af131da0-01f3-4b94-8ddf-5026c67b4d3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "# we will verify that GPU is enabled for this notebook\n",
        "# following should print: CUDA is available!  Training on GPU ...\n",
        "# \n",
        "# if it prints otherwise, then you need to enable GPU: \n",
        "# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a6WqsETVV-_B",
        "colab_type": "code",
        "outputId": "50da5a34-0e45-422f-d0e1-f4fef276d431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        }
      },
      "cell_type": "code",
      "source": [
        "# we need pillow version of 5.3.0\n",
        "# we will uninstall the older version first\n",
        "!pip uninstall -y Pillow\n",
        "# install the new one\n",
        "!pip install Pillow==5.3.0\n",
        "# import the new one\n",
        "import PIL\n",
        "print('Using PIL version: ',PIL.PILLOW_VERSION)\n",
        "# this should print 5.3.0. If it doesn't, then restart your runtime:\n",
        "# Menu > Runtime > Restart Runtime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling Pillow-5.3.0:\n",
            "  Successfully uninstalled Pillow-5.3.0\n",
            "Collecting Pillow==5.3.0\n",
            "  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Installing collected packages: Pillow\n",
            "Successfully installed Pillow-5.3.0\n",
            "Using PIL version:  4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JzKELNjh3Ktj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "from torchvision import datasets, transforms, models\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os, time, copy\n",
        "from collections import OrderedDict\n",
        "\n",
        "plt.ion()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nHGZkiGB3Ktn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the data\n",
        "\n",
        "Here you'll use `torchvision` to load the data ([documentation](http://pytorch.org/docs/0.3.0/torchvision/index.html)). You can [download the data here](https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip). The dataset is split into two parts, training and validation. For the training, you'll want to apply **transformations such as random scaling, cropping, and flipping**. This will help the network generalize leading to better performance. If you use a pre-trained network, you'll also need to make sure the *input data is resized to 224x224 pixels* as required by the networks.\n",
        "\n",
        "The validation set is used to measure the model's performance on data it hasn't seen yet. For this you don't want any scaling or rotation transformations, but you'll need to resize then crop the images to the appropriate size.\n",
        "\n",
        "The pre-trained networks available from `torchvision` were trained on the ImageNet dataset where each color channel was normalized separately. For both sets you'll need to normalize the means and standard deviations of the images to what the network expects. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`, calculated from the ImageNet images.  These values will shift each color channel to be centered at 0 and range from -1 to 1."
      ]
    },
    {
      "metadata": {
        "id": "vyw-aBuE4Az8",
        "colab_type": "code",
        "outputId": "6cda241c-4125-4322-c338-bc4ef86e7415",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "# we will download the required data files\n",
        "!wget -cq https://github.com/udacity/pytorch_challenge/raw/master/cat_to_name.json\n",
        "!wget -cq https://s3.amazonaws.com/content.udacity-data.com/courses/nd188/flower_data.zip\n",
        "!rm -r flower_data || true\n",
        "!unzip -qq flower_data.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove 'flower_data': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G5vIb2ChHJsa",
        "colab_type": "code",
        "outputId": "946f1ce0-ffbb-48cc-b03e-fdbe5e332118",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zJf-hrbx3Kto",
        "colab_type": "code",
        "outputId": "a761d0a4-04c1-42b9-a26a-a912232d9dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "data_dir = 'flower_data'\n",
        "# train_dir = data_dir + '/train'\n",
        "# valid_dir = data_dir + '/valid'\n",
        "os.listdir('flower_data/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'valid']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "2KvmdFb-3Kts",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Define your transforms for the training and validation sets\n",
        "data_transforms = {\n",
        "    'train' : transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'valid' : transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "}\n",
        "# TODO: Load the datasets with ImageFolder\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                         data_transforms[x])\n",
        "                 for x in ['train', 'valid']}\n",
        "\n",
        "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4, \n",
        "                                              shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'valid']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cKAaMgMDZHAv",
        "colab_type": "code",
        "outputId": "0633a694-042b-4f04-89fc-aacb9fb8b446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid']}\n",
        "device = 'cuda:0' if torch.cuda.is_available else 'cpu'\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "1vGuzGEl3Ktv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Label mapping\n",
        "\n",
        "You'll also need to load in a mapping from category label to category name. You can find this in the file `cat_to_name.json`. It's a JSON object which you can read in with the [`json` module](https://docs.python.org/2/library/json.html). This will give you a dictionary mapping the integer encoded categories to the actual names of the flowers."
      ]
    },
    {
      "metadata": {
        "id": "fTVLNuhs3Ktw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('cat_to_name.json', 'r') as f:\n",
        "    cat_to_name = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t4wHNVKztf85",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### View loaded images"
      ]
    },
    {
      "metadata": {
        "id": "tQLMqvh9nzeo",
        "colab_type": "code",
        "outputId": "9d61cb0b-c02b-4704-aa66-305e7ef0d63c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAACTCAYAAABf/mo0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fa2c3423fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kfHsUYS93Ktz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Building and training the classifier\n",
        "\n",
        "Now that the data is ready, it's time to build and train the classifier. As usual, you should use one of the pretrained models from `torchvision.models` to get the image features. Build and train a new feed-forward classifier using those features.\n",
        "\n",
        "We're going to leave this part up to you. If you want to talk through it with someone, chat with your fellow students! You can also ask questions on the forums or join the instructors in office hours.\n",
        "\n",
        "Refer to [the rubric](https://review.udacity.com/#!/rubrics/1663/view) for guidance on successfully completing this section. Things you'll need to do:\n",
        "\n",
        "* Load a [pre-trained network](http://pytorch.org/docs/master/torchvision/models.html) (If you need a starting point, the VGG networks work great and are straightforward to use)\n",
        "* Define a new, untrained feed-forward network as a classifier, using ReLU activations and dropout\n",
        "* Train the classifier layers using backpropagation using the pre-trained network to get the features\n",
        "* Track the loss and accuracy on the validation set to determine the best hyperparameters\n",
        "\n",
        "We've left a cell open for you below, but use as many as you need. Our advice is to break the problem up into smaller parts you can run separately. Check that each part is doing what you expect, then move on to the next. You'll likely find that as you work through each part, you'll need to go back and modify your previous code. This is totally normal!\n",
        "\n",
        "When training make sure you're updating only the weights of the feed-forward network. You should be able to get the validation accuracy above 70% if you build everything right. Make sure to try different hyperparameters (learning rate, units in the classifier, epochs, etc) to find the best model. Save those hyperparameters to use as default values in the next part of the project."
      ]
    },
    {
      "metadata": {
        "id": "xW2PnSKK3Kt0",
        "colab_type": "code",
        "outputId": "71c9ec1d-1e72-4ead-d6d3-784806b10517",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet18(pretrained=True)\n",
        "# Overwrite fully connected layer\n",
        "fc_len = model_ft.fc.in_features\n",
        "fc_out_len = model_ft.fc.out_features\n",
        "\n",
        "# For knowing the last layer use\n",
        "# print(model_ft)\n",
        "model_ft.fc = nn.Linear(fc_len, fc_out_len)\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optim_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optim_ft, step_size=7, gamma=0.1) \n",
        "print('Done...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZedxWmtrPv1V",
        "colab_type": "code",
        "outputId": "ac76e6e3-3f3e-4577-b837-47235102e193",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        }
      },
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "start_time = time.time()\n",
        "\n",
        "best_model_wt = copy.deepcopy(model_ft)\n",
        "best_acc = 0.0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('Epoch {}/{}'.format(epoch+1,epochs))\n",
        "  print('-' * 5)\n",
        "  \n",
        "  for phase in ['train', 'valid']:\n",
        "    # set model to evaluation mode if validation set\n",
        "    # or else to train mode and step scheduler\n",
        "    if phase == 'train':\n",
        "      exp_lr_scheduler.step()\n",
        "      model_ft.train()\n",
        "    else:\n",
        "      model_ft.eval()\n",
        "      \n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "    \n",
        "    # Iterate over train/valid data\n",
        "    for inputs, labels in dataloaders[phase]:\n",
        "      inputs = inputs.to(device)\n",
        "      labels = labels.to(device)\n",
        "\n",
        "      # reset optimizer\n",
        "      optim_ft.zero_grad()\n",
        "\n",
        "      # freeze gradient if validation\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "        outputs = model_ft(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # if train then backpropagate\n",
        "        if phase == 'train':\n",
        "          loss.backward()\n",
        "          optim_ft.step()\n",
        "\n",
        "      running_loss += loss.item() * inputs.size(0)\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / dataset_sizes[phase]\n",
        "    epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
        "\n",
        "    print('{} Loss {:.4f} Acc {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "    # if current accuracy is the best then save model\n",
        "    if phase == 'valid' and epoch_acc > best_acc:\n",
        "      best_acc = epoch_acc\n",
        "      best_model = copy.deepcopy(model_ft.state_dict())\n",
        "          \n",
        "  print()\n",
        "\n",
        "duration = time.time() - start_time\n",
        "print('It took {:.0f} mins and {:.0f} seconds to complete'.format(duration//60, \n",
        "                                                                  duration%60))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "-----\n",
            "train Loss 0.6404 Acc 0.8629\n",
            "valid Loss 0.1859 Acc 0.9548\n",
            "\n",
            "It took 2 mins and 17 seconds to complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3oE_YhrS3Kt3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the checkpoint\n",
        "\n",
        "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: `image_datasets['train'].class_to_idx`. You can attach this to the model as an attribute which makes inference easier later on.\n",
        "\n",
        "```model.class_to_idx = image_datasets['train'].class_to_idx```\n",
        "\n",
        "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, `optimizer.state_dict`. You'll likely want to use this trained model in the next part of the project, so best to save it now."
      ]
    },
    {
      "metadata": {
        "id": "9L8upwFNfvbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_save_name = 'classifier.pt'\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "amyJDhi0YTbr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(best_model, path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kTzSWddW3Kt6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading the checkpoint\n",
        "\n",
        "At this point it's good to write a function that can load a checkpoint and rebuild the model. That way you can come back to this project and keep working on it without having to retrain the network."
      ]
    },
    {
      "metadata": {
        "id": "HCZN5U523Kt8",
        "colab_type": "code",
        "outputId": "aa7b0c84-ec79-4545-8068-12a424e05744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95883
        }
      },
      "cell_type": "code",
      "source": [
        "model_ft.load_state_dict(torch.load(path))\n",
        "model_ft.state_dict()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('conv1.weight',\n",
              "              tensor([[[[ 8.5612e-03,  4.2417e-03,  3.8349e-03,  ...,  5.8713e-02,\n",
              "                          2.3228e-02, -5.2649e-03],\n",
              "                        [ 2.7084e-02,  1.9585e-02, -1.0353e-01,  ..., -2.6913e-01,\n",
              "                         -1.2419e-01,  8.9582e-03],\n",
              "                        [ 2.2825e-03,  6.2049e-02,  2.9942e-01,  ...,  5.2748e-01,\n",
              "                          2.6288e-01,  6.7542e-02],\n",
              "                        ...,\n",
              "                        [-2.5819e-02,  1.0002e-02,  6.2768e-02,  ..., -3.4509e-01,\n",
              "                         -4.3083e-01, -2.6844e-01],\n",
              "                        [ 3.3042e-02,  3.6542e-02,  5.4347e-02,  ...,  4.1139e-01,\n",
              "                          3.9038e-01,  1.5483e-01],\n",
              "                        [-1.1130e-02, -9.4342e-03, -3.1819e-02,  ..., -1.5040e-01,\n",
              "                         -8.1611e-02, -1.3562e-02]],\n",
              "              \n",
              "                       [[-1.7782e-02, -3.3990e-02, -4.1941e-02,  ...,  2.9557e-02,\n",
              "                          1.0406e-04, -2.8953e-02],\n",
              "                        [ 4.7676e-02,  3.6260e-02, -1.0148e-01,  ..., -3.0687e-01,\n",
              "                         -1.5292e-01,  3.4556e-03],\n",
              "                        [-1.6420e-03,  9.9151e-02,  4.0707e-01,  ...,  7.2216e-01,\n",
              "                          3.8143e-01,  1.3159e-01],\n",
              "                        ...,\n",
              "                        [-6.6649e-02, -1.5287e-02,  1.7510e-02,  ..., -4.6865e-01,\n",
              "                         -5.7906e-01, -3.7526e-01],\n",
              "                        [ 1.9232e-02,  4.4233e-02,  8.9227e-02,  ...,  5.4671e-01,\n",
              "                          4.7847e-01,  1.8602e-01],\n",
              "                        [-9.0197e-03, -8.4484e-03, -2.8763e-02,  ..., -1.4890e-01,\n",
              "                         -8.1411e-02, -9.8837e-03]],\n",
              "              \n",
              "                       [[ 2.7822e-03, -5.0817e-03,  2.4559e-02,  ...,  8.6917e-02,\n",
              "                          3.3748e-02, -2.1390e-02],\n",
              "                        [ 2.1798e-02, -1.1216e-02, -1.1882e-01,  ..., -2.5227e-01,\n",
              "                         -1.2667e-01, -2.6196e-02],\n",
              "                        [ 1.0333e-02,  4.9777e-02,  2.2167e-01,  ...,  3.5408e-01,\n",
              "                          1.0720e-01,  1.8513e-02],\n",
              "                        ...,\n",
              "                        [-3.2595e-02,  1.3126e-02,  9.3936e-02,  ..., -1.2960e-01,\n",
              "                         -2.6941e-01, -1.6322e-01],\n",
              "                        [ 1.5685e-02, -7.7035e-03, -4.2312e-02,  ...,  2.3779e-01,\n",
              "                          2.3822e-01,  1.0886e-01],\n",
              "                        [-2.6518e-03, -5.1651e-03, -1.2407e-02,  ..., -1.4508e-01,\n",
              "                         -1.1408e-01, -3.9862e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-9.0990e-03, -8.6069e-03, -1.5956e-03,  ..., -4.2623e-02,\n",
              "                         -2.6723e-02, -4.8863e-02],\n",
              "                        [ 4.4559e-02,  4.8107e-02,  7.4964e-02,  ...,  1.3748e-01,\n",
              "                          1.3857e-01,  1.2125e-01],\n",
              "                        [-1.6396e-02, -6.4146e-03,  2.9139e-02,  ...,  5.1478e-02,\n",
              "                          7.4669e-02,  1.1459e-01],\n",
              "                        ...,\n",
              "                        [-3.7300e-02, -1.3562e-01, -1.5082e-01,  ..., -1.5463e-01,\n",
              "                         -1.2099e-01, -5.6749e-02],\n",
              "                        [ 1.3586e-02, -2.8001e-02, -2.3501e-02,  ..., -3.3126e-02,\n",
              "                         -3.4119e-02, -3.8606e-02],\n",
              "                        [ 2.1214e-02,  1.4186e-02,  3.8527e-02,  ...,  1.1568e-02,\n",
              "                          2.6310e-02,  4.2958e-03]],\n",
              "              \n",
              "                       [[ 2.6168e-03,  1.5778e-02,  4.5885e-02,  ...,  5.1467e-02,\n",
              "                          4.6301e-02, -9.5623e-03],\n",
              "                        [ 4.8924e-02,  7.6890e-02,  1.4053e-01,  ...,  2.9526e-01,\n",
              "                          2.7823e-01,  2.1859e-01],\n",
              "                        [-5.2354e-02, -1.6293e-02,  3.6973e-02,  ...,  1.4696e-01,\n",
              "                          1.7571e-01,  1.9005e-01],\n",
              "                        ...,\n",
              "                        [-1.0463e-01, -2.4997e-01, -2.9442e-01,  ..., -2.7615e-01,\n",
              "                         -2.0529e-01, -9.3223e-02],\n",
              "                        [ 4.4988e-02, -2.8861e-02, -5.9451e-02,  ..., -8.5052e-02,\n",
              "                         -6.1996e-02, -4.1360e-02],\n",
              "                        [ 8.8118e-02,  9.4118e-02,  1.0737e-01,  ...,  5.8017e-02,\n",
              "                          6.8018e-02,  5.0044e-02]],\n",
              "              \n",
              "                       [[-2.0127e-02, -1.6538e-02,  4.0472e-03,  ...,  4.1773e-02,\n",
              "                          2.2170e-02, -4.7268e-02],\n",
              "                        [ 3.1524e-02,  4.2400e-02,  9.5291e-02,  ...,  2.6127e-01,\n",
              "                          2.2929e-01,  1.6709e-01],\n",
              "                        [-4.8594e-02, -1.8622e-02,  2.5847e-02,  ...,  1.4695e-01,\n",
              "                          1.3008e-01,  1.3391e-01],\n",
              "                        ...,\n",
              "                        [-7.4635e-02, -1.9489e-01, -2.3987e-01,  ..., -1.9618e-01,\n",
              "                         -1.6104e-01, -8.0766e-02],\n",
              "                        [ 5.2454e-02, -2.6768e-02, -7.1185e-02,  ..., -6.3036e-02,\n",
              "                         -6.4832e-02, -4.8146e-02],\n",
              "                        [ 1.1744e-01,  8.3633e-02,  6.9330e-02,  ...,  3.0210e-02,\n",
              "                          2.5433e-02,  7.6501e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[-7.0826e-08, -6.4306e-08, -7.3806e-08,  ..., -9.8000e-08,\n",
              "                         -1.0905e-07, -8.3421e-08],\n",
              "                        [-6.1125e-09,  2.0613e-09, -8.0922e-09,  ..., -4.9840e-08,\n",
              "                         -4.3836e-08, -3.0538e-09],\n",
              "                        [ 7.1953e-08,  7.5616e-08,  5.9282e-08,  ..., -9.7509e-09,\n",
              "                         -1.0951e-09,  4.2442e-08],\n",
              "                        ...,\n",
              "                        [ 9.5889e-08,  1.0039e-07,  7.9817e-08,  ..., -1.7491e-08,\n",
              "                         -4.7666e-08, -1.3265e-08],\n",
              "                        [ 1.2904e-07,  1.4762e-07,  1.7477e-07,  ...,  1.3233e-07,\n",
              "                          1.0628e-07,  9.3316e-08],\n",
              "                        [ 1.2558e-07,  1.3644e-07,  1.8431e-07,  ...,  2.1399e-07,\n",
              "                          1.7710e-07,  1.7166e-07]],\n",
              "              \n",
              "                       [[-1.2690e-07, -9.6139e-08, -1.0372e-07,  ..., -1.1808e-07,\n",
              "                         -1.3309e-07, -1.0820e-07],\n",
              "                        [-5.7412e-08, -2.5055e-08, -3.0115e-08,  ..., -7.2922e-08,\n",
              "                         -6.7022e-08, -2.2574e-08],\n",
              "                        [ 2.1813e-08,  4.8608e-08,  3.1222e-08,  ..., -1.8694e-08,\n",
              "                         -7.9591e-09,  3.9750e-08],\n",
              "                        ...,\n",
              "                        [ 5.6013e-08,  7.5526e-08,  4.4496e-08,  ..., -4.4128e-08,\n",
              "                         -5.9930e-08, -1.8247e-08],\n",
              "                        [ 7.7614e-08,  9.8348e-08,  1.0455e-07,  ...,  6.3272e-08,\n",
              "                          4.1781e-08,  4.5901e-08],\n",
              "                        [ 5.9834e-08,  7.1006e-08,  9.0437e-08,  ...,  1.1654e-07,\n",
              "                          8.7550e-08,  9.8837e-08]],\n",
              "              \n",
              "                       [[-4.3810e-08,  1.3270e-08,  7.8275e-09,  ..., -5.8804e-09,\n",
              "                         -2.6217e-08, -1.5649e-08],\n",
              "                        [ 4.1700e-08,  1.0778e-07,  1.0946e-07,  ...,  7.6403e-08,\n",
              "                          7.1450e-08,  9.7615e-08],\n",
              "                        [ 1.0436e-07,  1.6586e-07,  1.5933e-07,  ...,  1.3517e-07,\n",
              "                          1.3487e-07,  1.6449e-07],\n",
              "                        ...,\n",
              "                        [ 9.8763e-08,  1.5072e-07,  1.2547e-07,  ...,  6.8316e-08,\n",
              "                          6.8382e-08,  1.1367e-07],\n",
              "                        [ 9.1435e-08,  1.3576e-07,  1.3793e-07,  ...,  1.1678e-07,\n",
              "                          1.1723e-07,  1.4394e-07],\n",
              "                        [ 6.2183e-08,  8.8184e-08,  1.0456e-07,  ...,  1.3941e-07,\n",
              "                          1.3333e-07,  1.5844e-07]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-6.4495e-02, -3.1444e-02,  1.6976e-02,  ...,  3.7991e-02,\n",
              "                         -2.9622e-02, -5.0541e-02],\n",
              "                        [-3.8715e-02,  7.3042e-03,  4.6929e-02,  ...,  9.3176e-02,\n",
              "                          5.4991e-02,  2.5327e-02],\n",
              "                        [-3.2882e-02,  1.8188e-03,  2.0054e-02,  ...,  5.7127e-02,\n",
              "                          3.7908e-02,  2.0442e-02],\n",
              "                        ...,\n",
              "                        [ 7.7316e-03,  4.1496e-02,  4.0416e-02,  ...,  4.4098e-02,\n",
              "                          1.8546e-02, -8.4435e-03],\n",
              "                        [-3.6923e-02, -1.5759e-02,  1.8040e-02,  ...,  5.5368e-02,\n",
              "                         -9.8303e-03, -6.0448e-02],\n",
              "                        [-4.8107e-02, -3.1760e-02, -9.6335e-03,  ...,  8.4465e-02,\n",
              "                          6.1839e-03, -4.9568e-02]],\n",
              "              \n",
              "                       [[-5.9216e-02, -1.0423e-02,  2.0975e-02,  ...,  1.9713e-02,\n",
              "                         -3.0860e-02, -4.0682e-02],\n",
              "                        [-2.8453e-02,  2.9542e-02,  5.2386e-02,  ...,  7.0334e-02,\n",
              "                          5.0898e-02,  3.6225e-02],\n",
              "                        [-3.0474e-02,  2.5013e-02,  2.9960e-02,  ...,  3.8889e-02,\n",
              "                          4.0916e-02,  3.5840e-02],\n",
              "                        ...,\n",
              "                        [ 1.7856e-02,  6.1494e-02,  4.9841e-02,  ...,  4.0033e-02,\n",
              "                          3.1421e-02,  1.5399e-02],\n",
              "                        [-1.1193e-02,  2.2769e-02,  4.3959e-02,  ...,  6.3478e-02,\n",
              "                          2.0466e-02, -8.5960e-03],\n",
              "                        [-2.3956e-02,  1.2402e-02,  3.1192e-02,  ...,  1.0523e-01,\n",
              "                          4.4014e-02, -1.1287e-03]],\n",
              "              \n",
              "                       [[-7.5146e-02, -3.3045e-02,  1.6656e-02,  ...,  3.8953e-02,\n",
              "                         -2.5933e-02, -4.2762e-02],\n",
              "                        [-2.1866e-02,  2.5664e-02,  5.9789e-02,  ...,  9.6920e-02,\n",
              "                          6.1360e-02,  4.6943e-02],\n",
              "                        [-3.3594e-02,  6.0885e-03,  1.8716e-02,  ...,  3.2091e-02,\n",
              "                          3.6345e-02,  3.5840e-02],\n",
              "                        ...,\n",
              "                        [ 5.4675e-04,  3.3855e-02,  2.0668e-02,  ...,  1.1205e-02,\n",
              "                          1.0219e-03, -7.9019e-04],\n",
              "                        [-2.0217e-02,  4.0375e-04,  2.7338e-02,  ...,  4.2372e-02,\n",
              "                         -5.8203e-03, -2.2974e-02],\n",
              "                        [-7.5056e-03,  9.9711e-03,  1.5319e-02,  ...,  7.6908e-02,\n",
              "                          2.2941e-02,  2.7433e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.4331e-02,  1.2604e-02,  2.8660e-02,  ...,  2.5207e-02,\n",
              "                          1.0269e-02,  1.5977e-02],\n",
              "                        [ 4.3311e-03, -3.9383e-02, -4.1974e-02,  ...,  6.7833e-02,\n",
              "                          4.2384e-02,  4.9803e-02],\n",
              "                        [-4.0089e-02, -1.2621e-01, -1.4571e-01,  ...,  2.7740e-02,\n",
              "                          3.2512e-02,  2.2853e-02],\n",
              "                        ...,\n",
              "                        [ 1.5422e-02, -9.7873e-04, -1.4672e-02,  ..., -5.5058e-03,\n",
              "                          1.1229e-02,  1.0949e-02],\n",
              "                        [-3.0459e-03,  1.1095e-02,  1.0460e-02,  ..., -6.2518e-03,\n",
              "                          1.4448e-02, -5.1722e-03],\n",
              "                        [ 4.9354e-03,  2.2868e-02,  9.6279e-03,  ..., -6.5837e-04,\n",
              "                          1.1381e-02,  9.5949e-03]],\n",
              "              \n",
              "                       [[-1.5596e-02, -1.3472e-03,  9.6680e-03,  ..., -3.2763e-03,\n",
              "                          1.1508e-02,  1.6535e-02],\n",
              "                        [-1.6011e-02, -6.5346e-02, -6.6870e-02,  ...,  3.4010e-02,\n",
              "                          3.0074e-02,  2.6860e-02],\n",
              "                        [-5.0585e-02, -1.4338e-01, -1.5825e-01,  ...,  1.5791e-02,\n",
              "                          3.5733e-02,  1.5152e-02],\n",
              "                        ...,\n",
              "                        [ 4.4347e-03, -1.3577e-02, -1.5895e-02,  ..., -3.1789e-03,\n",
              "                          2.5721e-02,  1.5806e-02],\n",
              "                        [-3.0211e-04,  1.2679e-02,  2.5702e-02,  ...,  3.7907e-03,\n",
              "                          3.7536e-02,  1.0631e-02],\n",
              "                        [-8.6536e-03,  6.1966e-03,  6.1194e-03,  ..., -9.7402e-03,\n",
              "                          2.5647e-02,  1.7406e-02]],\n",
              "              \n",
              "                       [[-7.0803e-03, -1.1750e-02, -2.6952e-03,  ..., -5.0583e-02,\n",
              "                         -2.9521e-02, -2.8014e-02],\n",
              "                        [-3.1628e-03, -5.4376e-02, -6.1842e-02,  ..., -1.7412e-02,\n",
              "                         -2.3972e-02, -3.8777e-02],\n",
              "                        [-2.5243e-02, -1.0237e-01, -1.1426e-01,  ..., -1.2320e-02,\n",
              "                         -9.6311e-03, -4.2398e-02],\n",
              "                        ...,\n",
              "                        [ 8.2317e-03, -9.8398e-03, -3.7911e-03,  ..., -3.7566e-02,\n",
              "                         -1.1603e-02, -2.5429e-02],\n",
              "                        [-2.5061e-03, -3.9098e-03,  1.4860e-02,  ..., -2.8495e-02,\n",
              "                          8.7675e-03, -1.8590e-02],\n",
              "                        [-2.5175e-02, -3.4892e-02, -2.8652e-02,  ..., -5.5649e-02,\n",
              "                         -1.9815e-02, -3.0418e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.5840e-02,  1.3232e-02,  2.2690e-02,  ...,  1.3354e-02,\n",
              "                          7.9132e-03, -2.5219e-02],\n",
              "                        [ 1.6539e-03,  9.3227e-02,  1.2998e-01,  ...,  6.9090e-03,\n",
              "                         -7.8196e-03, -3.8842e-02],\n",
              "                        [ 1.1941e-01,  1.8813e-01,  5.0323e-02,  ..., -1.8455e-01,\n",
              "                         -8.1657e-02, -7.1198e-02],\n",
              "                        ...,\n",
              "                        [-5.4456e-02, -2.6136e-01, -2.6987e-01,  ...,  2.6875e-01,\n",
              "                          1.4142e-01,  5.1956e-02],\n",
              "                        [-2.9579e-02, -3.9232e-02,  9.7862e-02,  ...,  2.0737e-01,\n",
              "                         -8.7247e-03, -4.6165e-02],\n",
              "                        [-3.0459e-02,  2.7901e-03,  7.7073e-02,  ..., -5.0244e-02,\n",
              "                         -1.5306e-01, -9.8785e-02]],\n",
              "              \n",
              "                       [[-8.9844e-03,  2.4839e-02,  5.4787e-03,  ..., -2.1219e-02,\n",
              "                         -7.1778e-03, -7.7200e-03],\n",
              "                        [ 6.7425e-02,  1.5007e-01,  1.4465e-01,  ..., -3.3089e-02,\n",
              "                         -2.0410e-02, -6.0864e-03],\n",
              "                        [ 1.6170e-01,  2.0605e-01, -2.8638e-02,  ..., -2.7958e-01,\n",
              "                         -1.0583e-01, -5.5651e-02],\n",
              "                        ...,\n",
              "                        [-1.4034e-01, -4.1275e-01, -3.8765e-01,  ...,  4.1213e-01,\n",
              "                          2.6754e-01,  1.4303e-01],\n",
              "                        [-6.2059e-02, -6.3889e-02,  1.4400e-01,  ...,  3.6285e-01,\n",
              "                          9.4961e-02,  2.3477e-03],\n",
              "                        [ 7.2954e-03,  5.6439e-02,  1.5261e-01,  ...,  4.5420e-02,\n",
              "                         -1.0162e-01, -9.6107e-02]],\n",
              "              \n",
              "                       [[-5.9228e-03,  1.2069e-02, -2.8813e-02,  ..., -2.2091e-03,\n",
              "                         -2.4222e-03,  7.2204e-03],\n",
              "                        [ 8.4572e-03,  4.4923e-02,  5.8129e-02,  ...,  9.2261e-03,\n",
              "                         -6.1644e-03,  3.1789e-03],\n",
              "                        [ 4.9587e-02,  1.1816e-01,  3.7304e-02,  ..., -1.5377e-01,\n",
              "                         -7.5893e-02, -5.6052e-02],\n",
              "                        ...,\n",
              "                        [-4.0526e-02, -1.6944e-01, -1.6063e-01,  ...,  2.3426e-01,\n",
              "                          1.2748e-01,  7.9985e-02],\n",
              "                        [-2.0125e-02, -6.4634e-03,  8.5499e-02,  ...,  1.6425e-01,\n",
              "                          2.9214e-02, -4.6071e-03],\n",
              "                        [-1.4297e-02, -1.0342e-02,  3.5094e-02,  ..., -2.1726e-02,\n",
              "                         -6.6472e-02, -6.0934e-02]]]], device='cuda:0')),\n",
              "             ('bn1.weight',\n",
              "              tensor([ 1.9547e-01,  3.2138e-01, -5.1096e-08,  4.6505e-01,  3.4404e-09,\n",
              "                       3.0035e-01,  4.0513e-01,  1.3153e-07,  2.3209e-01,  1.5152e-06,\n",
              "                       3.0322e-01,  2.6600e-01,  4.1785e-01,  1.0862e-05,  3.4007e-01,\n",
              "                       2.6865e-01,  1.9932e-01,  4.3323e-01,  4.2816e-01,  3.2940e-01,\n",
              "                       3.2336e-01,  2.6537e-01,  3.0672e-01,  2.3290e-01,  2.4507e-01,\n",
              "                       2.8183e-01,  3.4406e-01,  3.2650e-01,  4.1613e-01,  3.2139e-01,\n",
              "                       2.8702e-01,  2.5250e-01,  2.9817e-01,  3.7880e-01,  4.5831e-01,\n",
              "                       3.9820e-01,  7.4804e-08,  2.4807e-01,  1.4740e-08,  1.8284e-01,\n",
              "                       2.0560e-01,  2.4231e-01,  2.9804e-01,  3.0272e-01,  2.9356e-01,\n",
              "                       3.9492e-01,  2.1542e-01,  2.0727e-01,  2.2001e-08,  2.7831e-01,\n",
              "                       2.1951e-01,  3.1141e-01,  3.6242e-01,  1.5864e-01,  3.8224e-01,\n",
              "                       1.6780e-01,  2.6295e-01,  2.6456e-01,  5.3286e-01,  2.4007e-01,\n",
              "                       3.0272e-01,  2.4342e-01,  5.1152e-01,  2.7217e-01], device='cuda:0')),\n",
              "             ('bn1.bias',\n",
              "              tensor([ 0.2081,  0.2759, -0.0000, -0.6969, -0.0000,  0.1517,  0.4544, -0.0000,\n",
              "                       0.3078, -0.0000,  0.3343,  0.3236, -0.2019, -0.0000,  0.1111,  0.2066,\n",
              "                       0.4100, -0.5059, -0.6354,  0.6000,  0.3120,  0.6070,  0.4940,  0.2927,\n",
              "                       0.1377,  0.2032,  0.1715,  0.0715,  0.5632,  0.0573,  0.1874,  0.3754,\n",
              "                       0.2885,  0.4079, -0.2495,  0.0429, -0.0000,  0.3287, -0.0000,  0.2251,\n",
              "                       0.2109,  0.3105,  0.4354,  0.2995,  0.2554,  0.6235,  0.4361,  0.3152,\n",
              "                      -0.0000,  0.2621,  0.3067,  0.6120,  0.4798,  0.2844, -0.3992,  0.3528,\n",
              "                       0.1957,  0.2796, -0.4262,  0.2012,  0.5517,  0.5731, -0.3797,  0.2374],\n",
              "                     device='cuda:0')),\n",
              "             ('bn1.running_mean',\n",
              "              tensor([ 9.7026e-02,  8.5416e-02, -1.9555e-06,  1.6561e-01,  3.6289e-09,\n",
              "                      -1.5461e-01,  1.7167e-01,  1.3145e-07,  1.2030e-01, -2.3097e-05,\n",
              "                      -4.0085e-01, -1.9419e-02,  6.2683e-01,  1.1007e-04, -7.3418e-02,\n",
              "                       1.1488e-02,  1.7118e-01,  5.7973e-02, -6.8344e-01,  4.1454e-01,\n",
              "                       2.0857e-01, -6.6205e-01,  3.7982e-01, -1.2474e-03, -8.6690e-02,\n",
              "                      -2.9990e-01,  1.1712e-02, -1.8633e+00,  2.1122e+00,  3.8321e-01,\n",
              "                      -8.6691e-02, -1.9473e-01, -1.4318e+00, -1.0762e+00,  2.6076e-01,\n",
              "                       1.3625e+00, -3.9159e-08, -4.7986e-01,  1.3183e-07, -5.1523e-02,\n",
              "                       9.1665e-02, -1.4665e-01,  1.2744e-01, -1.3970e-01, -3.0023e-01,\n",
              "                      -9.7658e-01, -4.0650e-01, -3.9142e-02, -4.9714e-08, -2.0608e-02,\n",
              "                      -1.2143e-01,  2.5442e-01,  4.4726e-01,  6.2644e-02,  6.1808e-01,\n",
              "                      -3.1445e-02,  1.2692e-01, -3.6198e-01,  5.8249e-01,  8.9134e-02,\n",
              "                       2.1754e-01, -8.9851e-01,  7.9265e-01,  9.2225e-02], device='cuda:0')),\n",
              "             ('bn1.running_var',\n",
              "              tensor([5.3691e-01, 3.1434e+00, 5.2493e-11, 5.1478e+00, 1.7254e-13, 9.8020e-01,\n",
              "                      1.7726e+01, 6.7632e-12, 5.4291e-01, 1.7401e-09, 2.5051e+00, 1.7391e+00,\n",
              "                      4.5756e+00, 4.4132e-08, 1.0226e+01, 7.0009e-01, 1.1446e+01, 5.9790e+00,\n",
              "                      2.8737e+00, 6.4798e+00, 2.9470e+00, 5.2748e+00, 3.9346e+00, 4.3152e-01,\n",
              "                      2.4413e-01, 6.2154e+00, 1.1083e+01, 1.5727e+01, 2.3377e+01, 1.9727e+00,\n",
              "                      9.9741e-01, 1.9498e+00, 7.3941e+00, 1.3971e+01, 6.7311e+00, 6.6575e+00,\n",
              "                      1.5925e-12, 3.1795e+00, 8.5938e-14, 1.8247e-01, 2.2103e-01, 9.6252e-01,\n",
              "                      1.1718e+00, 1.6479e+00, 1.9221e+00, 1.3556e+01, 2.2492e+00, 6.5031e-01,\n",
              "                      3.1677e-13, 1.0615e+00, 3.0249e-01, 1.9659e+00, 1.4606e+01, 3.7131e-01,\n",
              "                      2.6700e+00, 3.2714e-01, 2.4491e+00, 5.8099e+00, 4.3427e+00, 7.6473e-01,\n",
              "                      1.6830e+00, 1.0935e+01, 5.2384e+00, 1.3849e+00], device='cuda:0')),\n",
              "             ('bn1.num_batches_tracked', tensor(12041, device='cuda:0')),\n",
              "             ('layer1.0.conv1.weight',\n",
              "              tensor([[[[ 6.5846e-02, -8.7176e-02, -1.5358e-02],\n",
              "                        [-7.1619e-02, -7.9838e-01, -2.1103e-01],\n",
              "                        [ 7.0779e-02, -8.8590e-02, -5.0866e-03]],\n",
              "              \n",
              "                       [[-4.4759e-03,  1.6313e-02, -1.3409e-03],\n",
              "                        [ 3.5655e-02, -1.6844e-01, -3.2494e-02],\n",
              "                        [ 7.8829e-04,  8.7205e-03,  6.9061e-02]],\n",
              "              \n",
              "                       [[-2.3627e-09, -3.9270e-08, -3.2971e-08],\n",
              "                        [ 2.1737e-08,  8.3299e-09,  1.2543e-08],\n",
              "                        [ 1.1382e-08,  8.8096e-09,  1.5506e-08]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-3.4752e-02,  2.0978e-02, -2.5485e-02],\n",
              "                        [-9.7939e-02, -4.3827e-02, -5.0404e-02],\n",
              "                        [-7.9275e-02,  3.0835e-02,  7.9356e-03]],\n",
              "              \n",
              "                       [[ 1.6558e-02,  1.5103e-02,  9.3010e-03],\n",
              "                        [ 1.4313e-02,  1.4133e-03, -2.0666e-02],\n",
              "                        [ 1.3506e-02,  3.9084e-02, -1.9692e-02]],\n",
              "              \n",
              "                       [[-2.0267e-02, -2.5226e-02, -2.8537e-02],\n",
              "                        [ 5.5715e-02, -1.0398e-01,  1.6220e-02],\n",
              "                        [-1.8284e-02,  8.6694e-02,  1.9226e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.2174e-02,  4.0159e-02, -1.8766e-02],\n",
              "                        [-3.0794e-02,  5.8948e-02,  2.8334e-02],\n",
              "                        [ 4.1449e-03,  4.8011e-02,  8.9376e-03]],\n",
              "              \n",
              "                       [[ 2.4115e-02,  5.9470e-02,  6.0032e-02],\n",
              "                        [-3.1970e-02, -2.1024e-01, -6.1719e-02],\n",
              "                        [ 5.9656e-02,  7.2874e-02,  1.8731e-02]],\n",
              "              \n",
              "                       [[-3.1458e-08,  3.5335e-08,  5.3791e-08],\n",
              "                        [-2.6896e-08,  5.1530e-08,  5.4480e-08],\n",
              "                        [-3.8487e-08, -1.1234e-08, -7.5787e-09]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.3100e-01,  3.9372e-02, -7.0414e-02],\n",
              "                        [-6.4085e-02,  1.5653e-01, -1.3055e-02],\n",
              "                        [-9.5959e-02,  4.8666e-02, -8.1315e-02]],\n",
              "              \n",
              "                       [[-3.3060e-02,  3.0860e-03, -6.6928e-03],\n",
              "                        [ 1.7388e-02, -5.8211e-02, -2.7513e-02],\n",
              "                        [ 1.4111e-02, -2.9261e-02, -1.8967e-03]],\n",
              "              \n",
              "                       [[-1.9307e-03,  3.7909e-02,  2.2555e-03],\n",
              "                        [ 6.3615e-02, -1.0884e-02,  3.7581e-02],\n",
              "                        [ 1.4282e-04,  1.7547e-02,  1.2996e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-4.0249e-02,  4.8899e-03,  1.8576e-02],\n",
              "                        [ 2.1925e-02, -2.0702e-02,  2.4209e-03],\n",
              "                        [-1.9336e-03,  2.9700e-02,  9.1644e-04]],\n",
              "              \n",
              "                       [[-2.6701e-02, -8.8115e-03, -1.0549e-02],\n",
              "                        [-2.5101e-03,  3.1218e-03,  1.5152e-02],\n",
              "                        [ 7.2661e-03, -4.3432e-02, -7.5313e-02]],\n",
              "              \n",
              "                       [[ 3.1002e-08,  5.3568e-08,  3.1873e-08],\n",
              "                        [-1.6063e-08, -1.8072e-08, -1.9508e-09],\n",
              "                        [-5.8339e-08, -4.5366e-08, -1.2395e-08]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-3.2388e-03, -2.6123e-02, -4.2255e-02],\n",
              "                        [ 2.1606e-02, -2.7542e-02, -3.2371e-02],\n",
              "                        [-3.3813e-03, -2.3187e-02, -1.5917e-02]],\n",
              "              \n",
              "                       [[ 2.0791e-02,  1.3135e-03, -2.7591e-02],\n",
              "                        [ 2.4516e-02, -6.8488e-03, -1.8173e-03],\n",
              "                        [-3.6823e-03, -2.5832e-02, -1.4813e-02]],\n",
              "              \n",
              "                       [[-2.3646e-02,  2.7342e-02, -2.0791e-02],\n",
              "                        [ 6.2517e-02, -3.4135e-02,  3.1820e-04],\n",
              "                        [-2.2659e-02,  1.5697e-02, -2.1483e-03]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 2.4526e-03, -7.2238e-03, -6.8669e-02],\n",
              "                        [ 1.1672e-02, -2.5218e-02, -5.1474e-02],\n",
              "                        [ 2.7552e-02,  1.3877e-02, -1.7257e-02]],\n",
              "              \n",
              "                       [[ 4.2845e-02, -2.6322e-02, -3.6822e-02],\n",
              "                        [ 6.8504e-02,  3.4016e-03, -1.1717e-01],\n",
              "                        [ 1.8360e-02,  4.6254e-02, -5.6154e-04]],\n",
              "              \n",
              "                       [[ 2.6680e-09,  2.7671e-08,  2.4702e-08],\n",
              "                        [ 6.3905e-09,  4.1020e-08,  3.3631e-08],\n",
              "                        [ 5.8335e-09,  1.3334e-08,  9.6604e-09]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 1.0694e-02,  5.3404e-02, -5.8268e-03],\n",
              "                        [-3.5788e-03,  6.2132e-02,  4.7345e-03],\n",
              "                        [-1.8640e-02,  4.4421e-02,  2.8854e-03]],\n",
              "              \n",
              "                       [[-2.0583e-03, -8.3204e-03, -1.0764e-02],\n",
              "                        [ 3.3233e-03,  5.2290e-03, -1.5947e-02],\n",
              "                        [-3.2439e-03,  3.6237e-03, -2.4094e-02]],\n",
              "              \n",
              "                       [[ 1.7475e-02,  4.3810e-02, -2.8932e-02],\n",
              "                        [ 1.9431e-02,  4.7513e-02,  1.8671e-02],\n",
              "                        [ 1.8199e-02,  6.5765e-02,  1.7208e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-3.2079e-02, -8.2416e-05, -1.9121e-02],\n",
              "                        [-2.5604e-02,  2.1285e-02, -3.9446e-02],\n",
              "                        [-1.0635e-02, -5.2710e-03, -2.5048e-02]],\n",
              "              \n",
              "                       [[-4.9894e-02, -9.9397e-03, -1.7026e-02],\n",
              "                        [-1.6050e-02,  4.5484e-02,  3.4310e-03],\n",
              "                        [-2.3990e-02, -3.6146e-02, -7.4798e-02]],\n",
              "              \n",
              "                       [[-4.9804e-08, -2.8211e-08, -2.0583e-08],\n",
              "                        [-5.2389e-08, -2.8522e-08, -3.5099e-08],\n",
              "                        [-3.2171e-08, -3.4110e-08, -4.3153e-08]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 5.5975e-03,  2.5043e-02, -1.8088e-02],\n",
              "                        [ 1.1049e-02,  3.8529e-02, -3.7401e-02],\n",
              "                        [ 4.6983e-02,  3.6450e-02,  1.4337e-03]],\n",
              "              \n",
              "                       [[-5.9481e-03,  1.6617e-02,  2.3697e-02],\n",
              "                        [-1.1146e-02,  2.1459e-02,  1.3012e-02],\n",
              "                        [-9.2445e-03, -6.4538e-04, -6.7907e-03]],\n",
              "              \n",
              "                       [[ 5.7446e-03,  8.0038e-02,  2.4028e-03],\n",
              "                        [-3.3260e-02,  8.3382e-02, -2.2819e-02],\n",
              "                        [ 5.2736e-03, -5.6770e-02, -8.3637e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 5.6854e-02,  5.6685e-03, -3.0079e-02],\n",
              "                        [ 2.7005e-02,  1.1938e-02,  1.2049e-02],\n",
              "                        [ 1.4482e-02,  2.5471e-02, -3.3396e-03]],\n",
              "              \n",
              "                       [[-1.9150e-02,  1.0862e-02, -5.6061e-02],\n",
              "                        [-1.7892e-02,  5.9206e-02, -5.7021e-02],\n",
              "                        [-2.8374e-02, -2.5645e-04,  3.8166e-02]],\n",
              "              \n",
              "                       [[ 1.8496e-08,  5.2798e-09,  4.1820e-08],\n",
              "                        [ 3.7489e-08,  2.5450e-08,  3.0419e-08],\n",
              "                        [ 1.1246e-08, -5.6956e-09, -2.0008e-08]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 1.4031e-02, -3.6105e-02, -2.2086e-03],\n",
              "                        [ 3.0139e-02, -6.1229e-02,  1.9636e-02],\n",
              "                        [ 3.6625e-02, -3.5376e-03,  1.9733e-02]],\n",
              "              \n",
              "                       [[-3.0584e-03,  2.2496e-02, -1.8884e-02],\n",
              "                        [-6.0559e-02,  4.4992e-02,  2.8881e-02],\n",
              "                        [-1.9203e-02,  2.2695e-02,  2.3610e-02]],\n",
              "              \n",
              "                       [[ 3.1705e-02, -7.4080e-02,  8.7562e-03],\n",
              "                        [-3.0262e-02,  9.5078e-02,  2.5182e-02],\n",
              "                        [-2.5397e-02, -8.4159e-03, -6.7144e-02]]]], device='cuda:0')),\n",
              "             ('layer1.0.bn1.weight',\n",
              "              tensor([0.2809, 0.2603, 0.2561, 0.4228, 0.5313, 0.2170, 0.2269, 0.2292, 0.2320,\n",
              "                      0.2817, 0.2419, 0.4805, 0.3009, 0.2351, 0.3975, 0.2529, 0.2517, 0.3726,\n",
              "                      0.3453, 0.2656, 0.3543, 0.5149, 0.6681, 0.1650, 0.4463, 0.3094, 0.2836,\n",
              "                      0.4644, 0.2411, 0.2593, 0.3301, 0.4272, 0.4076, 0.4303, 0.5588, 0.5012,\n",
              "                      0.2563, 0.2366, 0.5729, 0.6655, 0.2461, 0.1553, 0.2643, 0.1895, 0.2665,\n",
              "                      0.2137, 0.6452, 0.3339, 0.5176, 0.2347, 0.3271, 0.3694, 0.3976, 0.4205,\n",
              "                      0.2829, 0.3186, 0.2646, 0.2906, 0.2039, 0.4641, 0.1902, 0.5294, 0.2475,\n",
              "                      0.3157], device='cuda:0')),\n",
              "             ('layer1.0.bn1.bias',\n",
              "              tensor([ 0.1805,  0.2441,  0.2109, -0.0144, -0.1549,  0.2275,  0.2916,  0.0850,\n",
              "                       0.1191,  0.1032,  0.1090, -0.1417,  0.1750,  0.0908, -0.1261,  0.1563,\n",
              "                       0.0874, -0.1901, -0.0098,  0.1847,  0.0393, -0.2859, -0.2669, -0.0636,\n",
              "                      -0.4332, -0.0975,  0.1639, -0.0452,  0.2043, -0.0727, -0.5370, -0.0754,\n",
              "                      -0.4302,  0.0012, -0.1412, -0.1578,  0.1587,  0.0086, -0.2344, -0.2449,\n",
              "                       0.1715,  0.2701,  0.1189, -0.0308,  0.0265,  0.3448, -0.2296, -0.0177,\n",
              "                      -0.2027,  0.2030,  0.0460, -0.0540, -0.1738, -0.0728,  0.2325, -0.4910,\n",
              "                       0.1212, -0.0969,  0.3203, -0.4740,  0.3126, -0.2246, -0.1553,  0.0583],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.0.bn1.running_mean',\n",
              "              tensor([-0.7023, -0.2141, -0.1241, -0.6221, -1.5283, -0.9400, -0.1480, -0.5191,\n",
              "                      -1.1790, -1.2125,  0.0631, -1.9680, -0.3406, -0.9657, -0.9322,  0.0675,\n",
              "                      -0.9190, -0.7973, -1.5437, -0.1910, -1.3239, -1.3934, -2.0881, -1.1314,\n",
              "                      -1.1585, -1.0722,  0.5382, -1.1875,  0.3973,  0.1878, -0.3184, -1.4117,\n",
              "                      -1.4237, -2.5933, -2.3008, -1.4763, -1.1320, -0.5451, -2.7191, -2.5024,\n",
              "                      -0.4945, -0.8468,  0.8139,  1.3631, -0.8362, -0.3156, -2.8162, -1.8224,\n",
              "                      -2.0821, -1.8159, -2.0910, -1.7305, -0.5392, -1.6870, -1.7503,  0.1855,\n",
              "                      -1.5660,  0.2352, -0.6409, -0.9211, -0.1807, -1.5811,  1.4228, -0.6842],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.0.bn1.running_var',\n",
              "              tensor([0.4506, 0.2080, 0.3870, 0.4913, 0.8566, 0.4794, 0.1066, 0.8053, 0.4409,\n",
              "                      1.3915, 0.1687, 0.7338, 0.2937, 0.6493, 0.9256, 0.2473, 0.1946, 0.7619,\n",
              "                      0.3037, 0.2385, 1.0786, 0.6697, 1.6438, 0.2673, 0.5533, 0.8616, 0.6035,\n",
              "                      0.8487, 0.3212, 0.3475, 0.2096, 0.4549, 0.6902, 1.0332, 1.3840, 0.7366,\n",
              "                      0.4378, 0.2663, 1.2102, 1.7033, 0.4615, 0.3398, 0.2168, 0.3112, 0.4076,\n",
              "                      0.1480, 1.7488, 0.3743, 0.7632, 0.2797, 0.9773, 0.5134, 0.4274, 0.5981,\n",
              "                      0.4475, 0.1464, 0.4086, 0.1476, 0.1873, 0.4413, 0.0638, 0.6902, 0.2906,\n",
              "                      0.2649], device='cuda:0')),\n",
              "             ('layer1.0.bn1.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer1.0.conv2.weight', tensor([[[[ 0.0232, -0.1055, -0.0039],\n",
              "                        [-0.0918, -0.3337, -0.1023],\n",
              "                        [-0.0634, -0.1923, -0.0535]],\n",
              "              \n",
              "                       [[-0.0109,  0.0281, -0.0011],\n",
              "                        [-0.0011,  0.0481, -0.0122],\n",
              "                        [-0.0619,  0.0064,  0.0001]],\n",
              "              \n",
              "                       [[-0.0067,  0.0264,  0.0214],\n",
              "                        [ 0.0099, -0.0020,  0.0180],\n",
              "                        [ 0.0152,  0.0186,  0.0119]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0013, -0.0090,  0.0195],\n",
              "                        [-0.0442, -0.0424, -0.0360],\n",
              "                        [-0.0240, -0.0120,  0.0130]],\n",
              "              \n",
              "                       [[ 0.0000,  0.0323, -0.0048],\n",
              "                        [ 0.0117,  0.0105,  0.0001],\n",
              "                        [-0.0104, -0.0119,  0.0017]],\n",
              "              \n",
              "                       [[ 0.0113,  0.0182, -0.0092],\n",
              "                        [-0.0165,  0.0440,  0.0197],\n",
              "                        [ 0.0310,  0.0662,  0.0213]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0512,  0.0380,  0.0092],\n",
              "                        [ 0.0241, -0.0294,  0.0325],\n",
              "                        [-0.0154,  0.0476,  0.0526]],\n",
              "              \n",
              "                       [[ 0.0365,  0.0513,  0.0351],\n",
              "                        [ 0.0310, -0.0333, -0.0483],\n",
              "                        [-0.0543, -0.0686, -0.0801]],\n",
              "              \n",
              "                       [[ 0.0950,  0.1264, -0.0642],\n",
              "                        [-0.0448, -0.0022,  0.0557],\n",
              "                        [-0.1165, -0.0841,  0.1480]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0114,  0.0172,  0.0177],\n",
              "                        [-0.0100, -0.0012,  0.0048],\n",
              "                        [-0.0085, -0.0108, -0.0014]],\n",
              "              \n",
              "                       [[-0.0269, -0.0261,  0.0391],\n",
              "                        [-0.0199, -0.0127,  0.0285],\n",
              "                        [ 0.0012, -0.0037, -0.0020]],\n",
              "              \n",
              "                       [[ 0.0032,  0.0231,  0.0599],\n",
              "                        [-0.0301,  0.0253,  0.0111],\n",
              "                        [-0.0222, -0.0063, -0.0399]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0072, -0.0163,  0.0157],\n",
              "                        [ 0.0133,  0.0428,  0.0614],\n",
              "                        [ 0.0339,  0.0745,  0.0609]],\n",
              "              \n",
              "                       [[-0.0001,  0.0061,  0.0191],\n",
              "                        [ 0.0174,  0.0340,  0.0300],\n",
              "                        [-0.0480, -0.0430,  0.0096]],\n",
              "              \n",
              "                       [[-0.0227, -0.0228, -0.0080],\n",
              "                        [ 0.0003,  0.0191,  0.0095],\n",
              "                        [-0.0096, -0.0009, -0.0299]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0069, -0.0144,  0.0030],\n",
              "                        [-0.0021,  0.0188,  0.0508],\n",
              "                        [-0.0077,  0.0236,  0.0441]],\n",
              "              \n",
              "                       [[ 0.0247,  0.0443,  0.0746],\n",
              "                        [-0.0062, -0.0013,  0.0391],\n",
              "                        [-0.0025, -0.0154,  0.0078]],\n",
              "              \n",
              "                       [[-0.0355,  0.0065,  0.0442],\n",
              "                        [-0.0166,  0.0046,  0.0642],\n",
              "                        [-0.0315, -0.0017,  0.0740]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0013, -0.0085, -0.0012],\n",
              "                        [ 0.0058,  0.0152,  0.0185],\n",
              "                        [ 0.0115,  0.0078,  0.0250]],\n",
              "              \n",
              "                       [[-0.0280,  0.0238, -0.0604],\n",
              "                        [ 0.0448,  0.1367, -0.0076],\n",
              "                        [ 0.0558,  0.1406,  0.0290]],\n",
              "              \n",
              "                       [[ 0.0139, -0.0005,  0.0079],\n",
              "                        [ 0.0136,  0.0111,  0.0295],\n",
              "                        [ 0.0100, -0.0219,  0.0229]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0088, -0.0086,  0.0302],\n",
              "                        [-0.0218, -0.0181,  0.0400],\n",
              "                        [-0.0372, -0.0449,  0.0165]],\n",
              "              \n",
              "                       [[-0.0025, -0.0262,  0.0088],\n",
              "                        [-0.0202, -0.0442, -0.0071],\n",
              "                        [-0.0242, -0.0593, -0.0246]],\n",
              "              \n",
              "                       [[ 0.0256, -0.0011,  0.0002],\n",
              "                        [ 0.0333, -0.0040,  0.0070],\n",
              "                        [ 0.0357,  0.0093,  0.0078]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0118,  0.0088,  0.0232],\n",
              "                        [-0.0678, -0.0003,  0.0987],\n",
              "                        [-0.0631, -0.0228,  0.0381]],\n",
              "              \n",
              "                       [[ 0.0287,  0.0249, -0.0217],\n",
              "                        [ 0.0457, -0.0036, -0.1097],\n",
              "                        [-0.0389, -0.0051,  0.0057]],\n",
              "              \n",
              "                       [[-0.0159, -0.0089,  0.0560],\n",
              "                        [ 0.0447,  0.0373,  0.0498],\n",
              "                        [ 0.0014, -0.0072, -0.0075]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0219,  0.0101,  0.0101],\n",
              "                        [ 0.0163,  0.0227,  0.0001],\n",
              "                        [ 0.0187,  0.0362, -0.0117]],\n",
              "              \n",
              "                       [[ 0.0403,  0.0457, -0.0996],\n",
              "                        [ 0.0214,  0.0083, -0.0779],\n",
              "                        [ 0.0053,  0.0287, -0.0769]],\n",
              "              \n",
              "                       [[-0.0194, -0.0335, -0.0384],\n",
              "                        [ 0.0125,  0.0030, -0.0759],\n",
              "                        [ 0.0371,  0.0386, -0.0043]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.1310,  0.0746, -0.0108],\n",
              "                        [ 0.0949,  0.0722,  0.0219],\n",
              "                        [-0.0249, -0.0708,  0.0845]],\n",
              "              \n",
              "                       [[ 0.0116, -0.0440,  0.0198],\n",
              "                        [ 0.0027,  0.0328,  0.0046],\n",
              "                        [-0.0246, -0.0054, -0.0747]],\n",
              "              \n",
              "                       [[-0.0641,  0.1038,  0.0177],\n",
              "                        [ 0.0551, -0.1652, -0.0315],\n",
              "                        [ 0.0008,  0.0471, -0.0362]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0579, -0.0474, -0.0092],\n",
              "                        [ 0.0467,  0.0402, -0.0763],\n",
              "                        [ 0.0077,  0.0404, -0.0510]],\n",
              "              \n",
              "                       [[ 0.0019,  0.0263, -0.0198],\n",
              "                        [-0.0834, -0.0541, -0.0086],\n",
              "                        [-0.0333, -0.1081, -0.0260]],\n",
              "              \n",
              "                       [[-0.0621, -0.0303, -0.0463],\n",
              "                        [-0.0635,  0.1034,  0.0087],\n",
              "                        [ 0.0828, -0.0283, -0.0032]]]], device='cuda:0')),\n",
              "             ('layer1.0.bn2.weight',\n",
              "              tensor([0.1352, 0.1962, 0.2712, 0.6428, 0.2058, 0.2809, 0.0576, 0.4635, 0.2811,\n",
              "                      0.3129, 0.2472, 0.4187, 0.5002, 0.3286, 0.4331, 0.1463, 0.2185, 0.5283,\n",
              "                      0.1936, 0.4148, 0.4906, 0.4319, 0.4755, 0.1718, 0.1396, 0.2719, 0.3719,\n",
              "                      0.2582, 0.2346, 0.4065, 0.2793, 0.3129, 0.1632, 0.2101, 0.2243, 0.1191,\n",
              "                      0.4286, 0.2943, 0.3692, 0.2129, 0.2662, 0.2088, 0.2153, 0.4511, 0.3012,\n",
              "                      0.2610, 0.5074, 0.2367, 0.6240, 0.4470, 0.3620, 0.4139, 0.0635, 0.2350,\n",
              "                      0.5927, 0.2163, 0.4764, 0.4584, 0.4476, 0.2397, 0.2988, 0.1057, 0.5255,\n",
              "                      0.4565], device='cuda:0')),\n",
              "             ('layer1.0.bn2.bias',\n",
              "              tensor([ 0.2077,  0.0315, -0.0565, -0.0469,  0.3832, -0.2118,  0.0290,  0.0399,\n",
              "                       0.3943,  0.0321, -0.0109,  0.2850, -0.0392, -0.2515, -0.1170, -0.1182,\n",
              "                      -0.1141,  0.0794, -0.3737, -0.3814, -0.3988,  0.0371, -0.2814, -0.0664,\n",
              "                      -0.0844,  0.2103, -0.0264, -0.1903, -0.2732,  0.0185,  0.2626, -0.0462,\n",
              "                      -0.1818, -0.1195,  0.1970,  0.0619, -0.2380, -0.0361,  0.2630,  0.2023,\n",
              "                       0.1528,  0.0984,  0.1100, -0.1412, -0.0553, -0.3538,  0.5007,  0.0783,\n",
              "                       0.0399,  0.1219,  0.4178, -0.0182,  0.0756,  0.0498, -0.1443,  0.0758,\n",
              "                      -0.1497, -0.2144,  0.1429,  0.1994, -0.0817,  0.2334, -0.1096,  0.3060],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.0.bn2.running_mean',\n",
              "              tensor([ 0.1487, -0.0477,  0.7986,  0.1935,  0.6021, -0.1045, -0.1351, -0.0654,\n",
              "                      -0.2631,  0.0393, -0.1171,  0.0352, -0.1020, -0.0152, -0.0091, -0.2904,\n",
              "                      -0.1932,  0.1735, -0.0189,  0.0174,  0.2221, -0.0761,  0.0665, -0.1987,\n",
              "                      -0.0256, -0.6223,  0.0950, -0.0651, -0.6050, -0.1793, -0.0377, -0.4353,\n",
              "                      -0.3348, -0.6510,  0.1210,  0.1371,  0.3467, -0.7081, -0.1224, -0.2659,\n",
              "                      -0.2804,  0.0027,  0.2098, -0.1629,  0.2295, -0.5631, -0.6929,  0.2076,\n",
              "                       0.1623, -0.0793, -0.1673,  0.2195, -0.0547, -0.2387,  0.1158, -0.1360,\n",
              "                      -0.3305, -0.0328, -0.1336,  0.3432, -0.0388,  0.1893,  0.0815, -0.0406],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.0.bn2.running_var',\n",
              "              tensor([0.2870, 0.0543, 0.0432, 0.1841, 0.2451, 0.0429, 0.0574, 0.0917, 0.0278,\n",
              "                      0.0673, 0.2547, 0.0493, 0.0479, 0.0312, 0.2105, 0.0587, 0.0806, 0.1125,\n",
              "                      0.0196, 0.2239, 0.1215, 0.3500, 0.2042, 0.0773, 0.0279, 0.1248, 0.2340,\n",
              "                      0.0611, 0.0648, 0.1926, 0.0482, 0.1832, 0.0563, 0.1410, 0.0568, 0.0455,\n",
              "                      0.0672, 0.1695, 0.0890, 0.0336, 0.0230, 0.2582, 0.1928, 0.1243, 0.2033,\n",
              "                      0.2113, 0.0696, 0.1672, 0.2462, 0.0448, 0.0333, 0.3696, 0.0663, 0.2137,\n",
              "                      0.1267, 0.1597, 0.1486, 0.2136, 0.1341, 0.0370, 0.4716, 0.0789, 0.0857,\n",
              "                      0.0415], device='cuda:0')),\n",
              "             ('layer1.0.bn2.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer1.1.conv1.weight', tensor([[[[ 0.0221, -0.0038,  0.0010],\n",
              "                        [-0.0201, -0.0132, -0.0348],\n",
              "                        [ 0.0545,  0.0759,  0.0437]],\n",
              "              \n",
              "                       [[ 0.0129, -0.0126, -0.0097],\n",
              "                        [-0.0448, -0.0263, -0.0583],\n",
              "                        [-0.0014,  0.0478,  0.0486]],\n",
              "              \n",
              "                       [[ 0.0248,  0.0063, -0.0098],\n",
              "                        [-0.0061, -0.0227, -0.0277],\n",
              "                        [-0.0267, -0.0447, -0.0254]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0058,  0.0900,  0.0016],\n",
              "                        [-0.0190,  0.0537, -0.0116],\n",
              "                        [-0.0370, -0.0274, -0.0373]],\n",
              "              \n",
              "                       [[ 0.0277, -0.0320, -0.0532],\n",
              "                        [ 0.0735, -0.0117, -0.0685],\n",
              "                        [ 0.0398,  0.0371, -0.0205]],\n",
              "              \n",
              "                       [[-0.0668, -0.0036, -0.0220],\n",
              "                        [ 0.0862,  0.0089, -0.0568],\n",
              "                        [ 0.0655, -0.1012,  0.0359]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0038, -0.0246,  0.0192],\n",
              "                        [-0.0274, -0.0005, -0.0131],\n",
              "                        [ 0.0102, -0.0155,  0.0020]],\n",
              "              \n",
              "                       [[ 0.0209,  0.0005,  0.0770],\n",
              "                        [-0.0319, -0.0787, -0.0138],\n",
              "                        [ 0.0369, -0.0451,  0.0092]],\n",
              "              \n",
              "                       [[-0.0317, -0.0601, -0.0602],\n",
              "                        [-0.0303, -0.0372, -0.0126],\n",
              "                        [-0.0229, -0.0035, -0.0026]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0190,  0.0091,  0.0568],\n",
              "                        [-0.0046, -0.0103, -0.0037],\n",
              "                        [ 0.0165, -0.0297,  0.0051]],\n",
              "              \n",
              "                       [[-0.0631, -0.0330,  0.0187],\n",
              "                        [-0.0765, -0.0775,  0.0887],\n",
              "                        [-0.0396, -0.0323, -0.0871]],\n",
              "              \n",
              "                       [[-0.1361,  0.0859,  0.0814],\n",
              "                        [-0.0086,  0.4241, -0.0108],\n",
              "                        [-0.0306, -0.1090, -0.1041]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0737,  0.0366, -0.0022],\n",
              "                        [ 0.0354, -0.0166, -0.0348],\n",
              "                        [-0.0147, -0.0229, -0.0297]],\n",
              "              \n",
              "                       [[ 0.0436,  0.0487,  0.0153],\n",
              "                        [-0.0384,  0.0251, -0.0258],\n",
              "                        [-0.0279, -0.0652,  0.0292]],\n",
              "              \n",
              "                       [[ 0.0379,  0.0414,  0.0418],\n",
              "                        [ 0.0176, -0.0157, -0.0305],\n",
              "                        [ 0.0044, -0.0169, -0.0289]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.1339, -0.1406,  0.0528],\n",
              "                        [-0.1189, -0.1277,  0.0803],\n",
              "                        [-0.0362, -0.0101,  0.0772]],\n",
              "              \n",
              "                       [[ 0.0615,  0.0099, -0.0313],\n",
              "                        [ 0.0755,  0.0332, -0.0301],\n",
              "                        [ 0.0264,  0.0231,  0.0341]],\n",
              "              \n",
              "                       [[-0.0020, -0.0459, -0.0112],\n",
              "                        [-0.0075,  0.0184,  0.0358],\n",
              "                        [ 0.0248, -0.0077, -0.0277]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0353,  0.0685,  0.0070],\n",
              "                        [-0.0163, -0.0547, -0.0679],\n",
              "                        [ 0.0011, -0.0462, -0.0490]],\n",
              "              \n",
              "                       [[-0.0028,  0.0101,  0.0003],\n",
              "                        [ 0.0019,  0.0177,  0.0081],\n",
              "                        [-0.0297, -0.0668, -0.0486]],\n",
              "              \n",
              "                       [[-0.0080,  0.0115,  0.0104],\n",
              "                        [-0.0564, -0.0457, -0.0402],\n",
              "                        [-0.0822, -0.0912, -0.0991]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0249,  0.0676,  0.0308],\n",
              "                        [-0.0203,  0.0012, -0.0240],\n",
              "                        [ 0.0509,  0.0702,  0.0369]],\n",
              "              \n",
              "                       [[ 0.0079,  0.0318,  0.0970],\n",
              "                        [-0.0052, -0.0484, -0.0415],\n",
              "                        [-0.0036, -0.0619, -0.0473]],\n",
              "              \n",
              "                       [[ 0.0135, -0.0351,  0.0004],\n",
              "                        [-0.0264, -0.1314, -0.0671],\n",
              "                        [-0.0094,  0.0736,  0.1096]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0282, -0.0138, -0.0053],\n",
              "                        [ 0.0227,  0.0064, -0.0296],\n",
              "                        [-0.0213,  0.0005,  0.0134]],\n",
              "              \n",
              "                       [[ 0.0067,  0.0027,  0.0113],\n",
              "                        [ 0.0010, -0.0039,  0.0337],\n",
              "                        [ 0.0778,  0.0077,  0.0038]],\n",
              "              \n",
              "                       [[-0.0657, -0.0406, -0.0291],\n",
              "                        [-0.0352, -0.0385, -0.0168],\n",
              "                        [-0.0116, -0.0092, -0.0020]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0183, -0.0266, -0.0095],\n",
              "                        [-0.0068, -0.0336, -0.0330],\n",
              "                        [ 0.0040, -0.0203,  0.0008]],\n",
              "              \n",
              "                       [[-0.0776, -0.0716, -0.0656],\n",
              "                        [-0.0820, -0.0816,  0.0549],\n",
              "                        [-0.0318, -0.0364, -0.0005]],\n",
              "              \n",
              "                       [[ 0.0861, -0.0024,  0.0729],\n",
              "                        [-0.0601, -0.1294,  0.0412],\n",
              "                        [ 0.0978, -0.0457,  0.0359]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0416, -0.0011, -0.0610],\n",
              "                        [ 0.0460,  0.0053, -0.0203],\n",
              "                        [ 0.0842,  0.0576, -0.0017]],\n",
              "              \n",
              "                       [[ 0.0233,  0.0041,  0.0154],\n",
              "                        [-0.0727, -0.1169, -0.0702],\n",
              "                        [-0.0055, -0.0271, -0.0206]],\n",
              "              \n",
              "                       [[-0.0188,  0.0010, -0.0306],\n",
              "                        [-0.0291, -0.0337, -0.0480],\n",
              "                        [-0.0255, -0.0328, -0.0204]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0060,  0.0888,  0.0294],\n",
              "                        [ 0.0597,  0.1373,  0.0394],\n",
              "                        [ 0.0011,  0.0488, -0.0408]],\n",
              "              \n",
              "                       [[ 0.0283, -0.0423,  0.0230],\n",
              "                        [ 0.0033, -0.0510, -0.0653],\n",
              "                        [ 0.0087,  0.0447,  0.0428]],\n",
              "              \n",
              "                       [[-0.1013,  0.0058,  0.0917],\n",
              "                        [-0.0067, -0.0326, -0.0693],\n",
              "                        [ 0.0177,  0.0246, -0.0975]]]], device='cuda:0')),\n",
              "             ('layer1.1.bn1.weight',\n",
              "              tensor([0.4097, 0.4301, 0.3553, 0.3774, 0.3623, 0.3814, 0.2766, 0.3041, 0.3060,\n",
              "                      0.4332, 0.2082, 0.2974, 0.3988, 0.2923, 0.2287, 0.3087, 0.2901, 0.2715,\n",
              "                      0.2278, 0.4658, 0.2299, 0.2213, 0.4688, 0.2907, 0.3337, 0.2784, 0.3332,\n",
              "                      0.2916, 0.3092, 0.2979, 0.1885, 0.4255, 0.3109, 0.3350, 0.4607, 0.3820,\n",
              "                      0.2502, 0.3245, 0.3110, 0.3376, 0.3455, 0.3119, 0.1645, 0.3571, 0.2971,\n",
              "                      0.2466, 0.2815, 0.2895, 0.3305, 0.2969, 0.3164, 0.2624, 0.3494, 0.4758,\n",
              "                      0.3702, 0.2791, 0.3268, 0.3577, 0.3984, 0.3762, 0.4051, 0.2819, 0.4643,\n",
              "                      0.3736], device='cuda:0')),\n",
              "             ('layer1.1.bn1.bias',\n",
              "              tensor([-0.0796, -0.4689, -0.0586, -0.2816, -0.0637,  0.0432,  0.0641,  0.1579,\n",
              "                      -0.0109, -0.1668,  0.2325,  0.1596, -0.1569,  0.0688,  0.1426, -0.2001,\n",
              "                       0.1397, -0.1611,  0.0884, -0.2822, -0.2694,  0.2498, -0.3012, -0.0003,\n",
              "                      -0.2772,  0.0990, -0.2528,  0.0627, -0.4078,  0.1033, -0.2354, -0.1415,\n",
              "                      -0.0143, -0.2906, -0.2932, -0.1040,  0.0811, -0.1388, -0.0025,  0.0172,\n",
              "                      -0.3276, -0.0514, -0.0833, -0.1429,  0.0497,  0.0383, -0.2594,  0.1605,\n",
              "                      -0.4063,  0.1411,  0.0129,  0.1582, -0.0280, -0.2981, -0.0075,  0.1699,\n",
              "                      -0.0910, -0.1669, -0.1031, -0.0463, -0.1227,  0.0730, -0.4495, -0.0088],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.1.bn1.running_mean',\n",
              "              tensor([-0.6233,  0.9330, -1.3185, -0.7633, -0.7013, -1.6984, -0.6741,  0.0677,\n",
              "                      -0.3318, -0.8196, -0.3689,  0.0619, -1.2268, -0.8088,  0.5081, -0.0579,\n",
              "                      -0.2999, -0.5848, -1.2873, -0.7259, -0.1359, -1.4296, -1.6537, -0.0676,\n",
              "                      -0.1470, -1.3961, -1.5951, -0.7982, -0.0356, -0.0441,  0.1974, -2.7774,\n",
              "                      -0.8236, -0.2029, -1.6838, -2.5144,  0.4050, -0.1928, -0.7629, -1.3321,\n",
              "                       0.5517, -0.6548,  0.8671, -1.0943, -1.2579, -0.0502, -0.5704,  0.6330,\n",
              "                       0.9029, -0.3905, -0.0629, -1.7137, -0.3518, -0.9017, -1.8281,  0.3399,\n",
              "                      -1.1342, -0.6340, -0.4354, -2.2208, -1.4127,  0.3869,  0.6501, -1.0728],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.1.bn1.running_var',\n",
              "              tensor([0.7585, 0.7247, 0.7478, 0.3953, 0.2890, 0.6003, 0.3875, 0.4953, 0.3143,\n",
              "                      0.5204, 0.1734, 0.8929, 0.3663, 0.3489, 0.1539, 0.3642, 0.4920, 0.2881,\n",
              "                      0.3757, 0.5405, 0.1436, 0.1897, 0.6384, 0.2985, 0.2034, 0.4550, 0.3008,\n",
              "                      0.5832, 0.5785, 0.6516, 0.1769, 1.0131, 0.5086, 0.2293, 0.4613, 0.4810,\n",
              "                      0.4256, 0.3419, 0.7025, 0.5823, 0.3565, 0.3851, 0.2361, 0.7471, 0.4979,\n",
              "                      0.2489, 0.4980, 0.4569, 0.4012, 0.5582, 0.4040, 0.5948, 0.6174, 0.5166,\n",
              "                      0.7185, 0.6154, 0.3765, 0.3563, 0.6943, 0.6547, 0.5533, 0.7682, 0.6034,\n",
              "                      0.6009], device='cuda:0')),\n",
              "             ('layer1.1.bn1.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer1.1.conv2.weight', tensor([[[[-0.0180,  0.0034,  0.0090],\n",
              "                        [-0.0099,  0.0423,  0.0259],\n",
              "                        [-0.0112,  0.0590,  0.0296]],\n",
              "              \n",
              "                       [[ 0.0582,  0.0448,  0.0447],\n",
              "                        [ 0.0225, -0.0127,  0.0091],\n",
              "                        [ 0.0450,  0.0301,  0.0372]],\n",
              "              \n",
              "                       [[-0.0134, -0.0370, -0.0458],\n",
              "                        [-0.0224,  0.0262,  0.0026],\n",
              "                        [-0.0206,  0.0162,  0.0284]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0513,  0.0427,  0.0565],\n",
              "                        [ 0.0431,  0.0534,  0.0127],\n",
              "                        [ 0.0132,  0.0208,  0.0169]],\n",
              "              \n",
              "                       [[ 0.0079,  0.0131,  0.0460],\n",
              "                        [-0.0043, -0.0228,  0.0187],\n",
              "                        [ 0.0120,  0.0202,  0.0188]],\n",
              "              \n",
              "                       [[ 0.0657,  0.0740,  0.0646],\n",
              "                        [ 0.0634,  0.1029,  0.0613],\n",
              "                        [ 0.0565,  0.0799,  0.0845]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0094, -0.0119,  0.0097],\n",
              "                        [ 0.0488,  0.0394,  0.0563],\n",
              "                        [ 0.0538,  0.0367,  0.0447]],\n",
              "              \n",
              "                       [[ 0.0025, -0.0307, -0.0097],\n",
              "                        [-0.0443, -0.0454,  0.0046],\n",
              "                        [-0.0464, -0.0147,  0.0067]],\n",
              "              \n",
              "                       [[ 0.0333,  0.0299, -0.0046],\n",
              "                        [ 0.0195, -0.0004, -0.0266],\n",
              "                        [-0.0146,  0.0019, -0.0009]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0250,  0.0529,  0.0441],\n",
              "                        [-0.0293, -0.0102, -0.0115],\n",
              "                        [-0.0315, -0.0132, -0.0309]],\n",
              "              \n",
              "                       [[-0.0251, -0.0382, -0.0433],\n",
              "                        [-0.0175, -0.0430, -0.0356],\n",
              "                        [ 0.0240, -0.0001, -0.0047]],\n",
              "              \n",
              "                       [[-0.0501, -0.0468,  0.0118],\n",
              "                        [ 0.0056,  0.0220,  0.0693],\n",
              "                        [ 0.0324,  0.0540,  0.0279]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0210, -0.0274, -0.0343],\n",
              "                        [ 0.0336,  0.0274,  0.0233],\n",
              "                        [ 0.0034,  0.0246,  0.0378]],\n",
              "              \n",
              "                       [[-0.0363,  0.0102,  0.0454],\n",
              "                        [ 0.0144,  0.0594,  0.0895],\n",
              "                        [ 0.0492,  0.1017,  0.0906]],\n",
              "              \n",
              "                       [[-0.0271, -0.0343,  0.0219],\n",
              "                        [-0.0342, -0.0223, -0.0300],\n",
              "                        [ 0.0135,  0.0167, -0.0209]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0370, -0.0686, -0.0579],\n",
              "                        [ 0.0295,  0.0174, -0.0240],\n",
              "                        [ 0.0851,  0.1212,  0.0920]],\n",
              "              \n",
              "                       [[ 0.0394,  0.0796,  0.0739],\n",
              "                        [ 0.0298,  0.1214,  0.1282],\n",
              "                        [ 0.0009,  0.0410,  0.0507]],\n",
              "              \n",
              "                       [[ 0.0282,  0.0393, -0.0113],\n",
              "                        [ 0.0421,  0.0278, -0.0086],\n",
              "                        [ 0.0000,  0.0008,  0.0151]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0462, -0.0873, -0.0576],\n",
              "                        [ 0.0388,  0.0156,  0.0260],\n",
              "                        [ 0.0083, -0.0130,  0.0449]],\n",
              "              \n",
              "                       [[-0.0001,  0.0074,  0.0023],\n",
              "                        [ 0.0078, -0.0183, -0.0227],\n",
              "                        [-0.0107, -0.0184,  0.0032]],\n",
              "              \n",
              "                       [[ 0.0079,  0.0474,  0.0785],\n",
              "                        [-0.0615, -0.0324, -0.0141],\n",
              "                        [-0.0366, -0.0246, -0.0099]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0449, -0.0455, -0.0213],\n",
              "                        [-0.0054,  0.0052,  0.0262],\n",
              "                        [ 0.0252,  0.0542,  0.0705]],\n",
              "              \n",
              "                       [[ 0.0017,  0.0107, -0.0126],\n",
              "                        [-0.0126, -0.0203, -0.0048],\n",
              "                        [-0.0033, -0.0045, -0.0133]],\n",
              "              \n",
              "                       [[ 0.0034, -0.0099, -0.0084],\n",
              "                        [ 0.0187, -0.0205,  0.0433],\n",
              "                        [ 0.0103,  0.0477,  0.1082]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0119, -0.0130,  0.0061],\n",
              "                        [ 0.0334, -0.0271, -0.0223],\n",
              "                        [-0.0237,  0.0034, -0.0196]],\n",
              "              \n",
              "                       [[-0.0270, -0.0297,  0.0228],\n",
              "                        [-0.0203,  0.0134,  0.0222],\n",
              "                        [ 0.0085,  0.0019,  0.0044]],\n",
              "              \n",
              "                       [[ 0.0148,  0.0593, -0.0279],\n",
              "                        [ 0.0523,  0.0470,  0.0006],\n",
              "                        [ 0.0351, -0.0446,  0.0176]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0030, -0.0068,  0.0039],\n",
              "                        [ 0.0240,  0.0089, -0.0306],\n",
              "                        [ 0.0092,  0.0062, -0.0507]],\n",
              "              \n",
              "                       [[ 0.0261, -0.0079, -0.0102],\n",
              "                        [-0.0124,  0.0052, -0.0048],\n",
              "                        [-0.0264,  0.0077, -0.0297]],\n",
              "              \n",
              "                       [[-0.0299, -0.0573, -0.0198],\n",
              "                        [-0.0463, -0.0202, -0.0001],\n",
              "                        [-0.0119,  0.0065,  0.0023]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0212, -0.0621, -0.0366],\n",
              "                        [ 0.0023,  0.0560, -0.0076],\n",
              "                        [-0.0345,  0.0347, -0.0158]],\n",
              "              \n",
              "                       [[ 0.0888, -0.1144, -0.0771],\n",
              "                        [-0.1015, -0.1000, -0.1941],\n",
              "                        [-0.1204, -0.0732,  0.0311]],\n",
              "              \n",
              "                       [[-0.0177,  0.0100,  0.0651],\n",
              "                        [-0.0463,  0.0799, -0.0532],\n",
              "                        [-0.0568, -0.0596, -0.0239]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0465, -0.0821,  0.0504],\n",
              "                        [-0.0863, -0.0592,  0.0722],\n",
              "                        [ 0.0144,  0.0381,  0.0465]],\n",
              "              \n",
              "                       [[ 0.0051,  0.0251, -0.0231],\n",
              "                        [ 0.0223,  0.0204,  0.0020],\n",
              "                        [-0.0504, -0.0152, -0.0244]],\n",
              "              \n",
              "                       [[ 0.0240,  0.0094,  0.0059],\n",
              "                        [-0.0837,  0.0737,  0.1287],\n",
              "                        [ 0.0080,  0.1378,  0.0331]]]], device='cuda:0')),\n",
              "             ('layer1.1.bn2.weight',\n",
              "              tensor([0.2320, 0.5637, 0.3764, 0.5281, 0.1977, 0.4736, 0.3977, 0.5406, 0.4410,\n",
              "                      0.5661, 0.2189, 0.5003, 0.6001, 0.5289, 0.2425, 0.2619, 0.4843, 0.6355,\n",
              "                      0.4217, 0.2395, 0.5085, 0.3078, 0.5975, 0.2631, 0.1809, 0.1224, 0.2172,\n",
              "                      0.2355, 0.6287, 0.3557, 0.4229, 0.2648, 0.5934, 0.3025, 0.2476, 0.1909,\n",
              "                      0.6215, 0.4034, 0.6711, 0.4010, 0.7550, 0.1832, 0.3298, 0.4416, 0.2732,\n",
              "                      0.2283, 0.4486, 0.2913, 0.5897, 0.6696, 0.4428, 0.2608, 0.7005, 0.1752,\n",
              "                      0.5824, 0.2146, 0.3764, 0.2175, 0.5840, 0.3171, 0.1726, 0.0722, 0.3979,\n",
              "                      0.4309], device='cuda:0')),\n",
              "             ('layer1.1.bn2.bias',\n",
              "              tensor([-0.1989, -0.1070,  0.0502, -0.1309,  0.2070, -0.1632, -0.4018, -0.1279,\n",
              "                       0.2243, -0.1829,  0.0324, -0.0152, -0.1569, -0.0498, -0.0580, -0.1271,\n",
              "                       0.0310,  0.0978, -0.1681,  0.0268, -0.2507, -0.0536, -0.0389, -0.0924,\n",
              "                      -0.2677,  0.1411, -0.0201,  0.2242,  0.0089, -0.0249, -0.0260,  0.0473,\n",
              "                      -0.1065, -0.3767,  0.2880, -0.0997,  0.3083, -0.0760,  0.2847,  0.1078,\n",
              "                      -0.3180,  0.0387,  0.0532,  0.2413, -0.0792,  0.0280, -0.0448,  0.1236,\n",
              "                       0.0419, -0.1196,  0.1477, -0.0725, -0.3198, -0.1935, -0.0337, -0.1403,\n",
              "                      -0.1722,  0.0469,  0.0905,  0.0800, -0.0865,  0.0679, -0.0510,  0.0426],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.1.bn2.running_mean',\n",
              "              tensor([-0.0412, -0.2443,  0.7756, -0.0730,  0.4853, -0.1074, -0.0796,  0.0524,\n",
              "                      -0.2790, -0.4167,  0.2696, -0.0062, -0.0015, -0.6354,  0.1932, -0.1166,\n",
              "                      -0.1120, -0.0894,  0.0258, -0.0125, -0.1790,  0.0598,  0.0215,  0.0414,\n",
              "                      -0.0151,  0.0107, -0.0965,  0.0238, -0.6025, -0.0622, -0.0306, -0.0919,\n",
              "                      -0.3789, -0.2553, -0.2590,  0.0850, -0.2433, -0.3157, -0.1044, -0.0319,\n",
              "                      -0.1654,  0.3194,  0.1974, -0.1555, -0.4752, -0.2415, -0.2735,  0.1107,\n",
              "                      -0.1599, -0.2466, -0.0211,  0.0751, -0.2455, -0.0810, -0.0338,  0.3103,\n",
              "                       0.0502, -0.1652,  0.0144,  0.2183,  0.0688,  0.0664,  0.0185,  0.0801],\n",
              "                     device='cuda:0')),\n",
              "             ('layer1.1.bn2.running_var',\n",
              "              tensor([0.0662, 0.1806, 0.0592, 0.0635, 0.1126, 0.0739, 0.0766, 0.0589, 0.0525,\n",
              "                      0.1498, 0.0370, 0.0527, 0.0476, 0.0901, 0.0613, 0.0350, 0.1256, 0.0917,\n",
              "                      0.0252, 0.0655, 0.0724, 0.1136, 0.1294, 0.0403, 0.0184, 0.0369, 0.0516,\n",
              "                      0.0513, 0.0966, 0.0756, 0.0579, 0.0640, 0.0671, 0.0710, 0.0533, 0.0377,\n",
              "                      0.0701, 0.0683, 0.0693, 0.0452, 0.0781, 0.0395, 0.0508, 0.0917, 0.0745,\n",
              "                      0.0798, 0.0569, 0.0396, 0.1059, 0.0777, 0.0451, 0.1181, 0.0829, 0.0660,\n",
              "                      0.0733, 0.0463, 0.0641, 0.0722, 0.1260, 0.0337, 0.0793, 0.0229, 0.0832,\n",
              "                      0.0472], device='cuda:0')),\n",
              "             ('layer1.1.bn2.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer2.0.conv1.weight', tensor([[[[-0.0719, -0.1098, -0.1360],\n",
              "                        [ 0.0712, -0.0140, -0.0998],\n",
              "                        [ 0.1185,  0.0847, -0.0090]],\n",
              "              \n",
              "                       [[-0.0216, -0.0054,  0.0011],\n",
              "                        [ 0.0083,  0.0187,  0.0248],\n",
              "                        [ 0.0012, -0.0039, -0.0123]],\n",
              "              \n",
              "                       [[ 0.0037,  0.0015, -0.0159],\n",
              "                        [ 0.0073, -0.0152, -0.0452],\n",
              "                        [ 0.0159, -0.0166, -0.0511]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0291,  0.0274,  0.0200],\n",
              "                        [ 0.0028, -0.0062, -0.0153],\n",
              "                        [-0.0110, -0.0204, -0.0319]],\n",
              "              \n",
              "                       [[-0.0141, -0.0266, -0.0194],\n",
              "                        [ 0.0111,  0.0167, -0.0167],\n",
              "                        [ 0.0223,  0.0587,  0.0458]],\n",
              "              \n",
              "                       [[ 0.0109, -0.0308, -0.0089],\n",
              "                        [ 0.0326, -0.0123, -0.0110],\n",
              "                        [ 0.0476,  0.0145,  0.0305]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0776, -0.0720, -0.0338],\n",
              "                        [-0.0333, -0.0590, -0.0344],\n",
              "                        [-0.0261, -0.0516, -0.0462]],\n",
              "              \n",
              "                       [[-0.0153, -0.0231, -0.0019],\n",
              "                        [ 0.0077,  0.0158,  0.0127],\n",
              "                        [ 0.0400,  0.0219, -0.0054]],\n",
              "              \n",
              "                       [[-0.0880, -0.0870, -0.0565],\n",
              "                        [-0.0788, -0.0836, -0.0357],\n",
              "                        [-0.0571, -0.0444,  0.0132]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0357, -0.0421, -0.0317],\n",
              "                        [-0.0188, -0.0171, -0.0008],\n",
              "                        [ 0.0087,  0.0212,  0.0208]],\n",
              "              \n",
              "                       [[-0.0007, -0.0319, -0.0347],\n",
              "                        [ 0.0049,  0.0015, -0.0137],\n",
              "                        [-0.0033,  0.0062,  0.0083]],\n",
              "              \n",
              "                       [[ 0.0288,  0.0530,  0.0040],\n",
              "                        [ 0.0547,  0.0717,  0.0320],\n",
              "                        [ 0.0267,  0.0442, -0.0019]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0122,  0.0311,  0.0463],\n",
              "                        [-0.0097,  0.0006,  0.0150],\n",
              "                        [-0.0711, -0.0545, -0.0480]],\n",
              "              \n",
              "                       [[ 0.0528,  0.0406,  0.0383],\n",
              "                        [ 0.0645,  0.0597,  0.0338],\n",
              "                        [ 0.0314,  0.0511,  0.0113]],\n",
              "              \n",
              "                       [[-0.0378, -0.0438, -0.0265],\n",
              "                        [-0.0067,  0.0052,  0.0071],\n",
              "                        [ 0.0180,  0.0091,  0.0001]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0142, -0.0685, -0.0895],\n",
              "                        [ 0.0422,  0.0152, -0.0242],\n",
              "                        [ 0.1057,  0.1236,  0.0639]],\n",
              "              \n",
              "                       [[-0.0075,  0.0453, -0.0101],\n",
              "                        [-0.0303,  0.0022, -0.0135],\n",
              "                        [-0.0680, -0.0629, -0.0300]],\n",
              "              \n",
              "                       [[-0.0047, -0.0121, -0.0396],\n",
              "                        [ 0.0088, -0.0034,  0.0129],\n",
              "                        [ 0.0279,  0.0349,  0.0340]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0393, -0.0626, -0.0159],\n",
              "                        [-0.0888, -0.0551,  0.0149],\n",
              "                        [-0.0198,  0.0344,  0.0753]],\n",
              "              \n",
              "                       [[ 0.0018,  0.0006, -0.0144],\n",
              "                        [ 0.0166, -0.0060, -0.0116],\n",
              "                        [ 0.0097, -0.0104, -0.0257]],\n",
              "              \n",
              "                       [[-0.0247, -0.0506, -0.0149],\n",
              "                        [-0.0504, -0.0483, -0.0070],\n",
              "                        [-0.0487, -0.0288,  0.0038]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0019,  0.0122, -0.0006],\n",
              "                        [ 0.0092,  0.0098, -0.0088],\n",
              "                        [-0.0343, -0.0359, -0.0488]],\n",
              "              \n",
              "                       [[-0.0062, -0.0107,  0.0338],\n",
              "                        [-0.0069, -0.0514,  0.0609],\n",
              "                        [ 0.0182,  0.0276,  0.0863]],\n",
              "              \n",
              "                       [[-0.0347, -0.0242, -0.0051],\n",
              "                        [-0.0520, -0.0314, -0.0136],\n",
              "                        [-0.0119,  0.0080,  0.0220]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0514, -0.0543, -0.0542],\n",
              "                        [ 0.0194, -0.0191, -0.0273],\n",
              "                        [ 0.0149,  0.0917,  0.1012]],\n",
              "              \n",
              "                       [[-0.0379,  0.0023,  0.0098],\n",
              "                        [-0.0417, -0.0376, -0.0386],\n",
              "                        [ 0.0361,  0.0637,  0.0822]],\n",
              "              \n",
              "                       [[ 0.0157,  0.0106,  0.0223],\n",
              "                        [-0.0336, -0.0427, -0.0181],\n",
              "                        [ 0.0086, -0.0179, -0.0026]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0048,  0.0173,  0.0107],\n",
              "                        [-0.0076,  0.0210,  0.0219],\n",
              "                        [-0.0294, -0.0008, -0.0055]],\n",
              "              \n",
              "                       [[-0.0143,  0.0031, -0.0000],\n",
              "                        [-0.0045, -0.0260, -0.0024],\n",
              "                        [ 0.0393, -0.0211,  0.0174]],\n",
              "              \n",
              "                       [[-0.0133,  0.0004,  0.0013],\n",
              "                        [ 0.0338,  0.0475,  0.0369],\n",
              "                        [-0.0365, -0.0344, -0.0344]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0377, -0.0022,  0.0020],\n",
              "                        [-0.0092,  0.0100,  0.0080],\n",
              "                        [-0.0160, -0.0074,  0.0027]],\n",
              "              \n",
              "                       [[-0.0005,  0.0032, -0.0077],\n",
              "                        [ 0.0007,  0.0153, -0.0204],\n",
              "                        [-0.0014, -0.0058, -0.0007]],\n",
              "              \n",
              "                       [[-0.0174, -0.0308,  0.0097],\n",
              "                        [-0.0245, -0.0472,  0.0069],\n",
              "                        [-0.0033, -0.0498,  0.0036]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0020, -0.0036,  0.0156],\n",
              "                        [ 0.0071,  0.0049,  0.0285],\n",
              "                        [ 0.0077,  0.0056,  0.0183]],\n",
              "              \n",
              "                       [[ 0.0081,  0.0236, -0.0065],\n",
              "                        [-0.0343,  0.0309, -0.0062],\n",
              "                        [-0.0528, -0.0088,  0.0240]],\n",
              "              \n",
              "                       [[-0.0724,  0.0428,  0.0190],\n",
              "                        [ 0.0302, -0.0637,  0.0411],\n",
              "                        [ 0.1028, -0.0449,  0.0439]]]], device='cuda:0')),\n",
              "             ('layer2.0.bn1.weight',\n",
              "              tensor([0.3345, 0.2851, 0.3000, 0.2417, 0.3289, 0.3573, 0.3012, 0.3399, 0.2592,\n",
              "                      0.3864, 0.3002, 0.2692, 0.3115, 0.1893, 0.2239, 0.3736, 0.3985, 0.2343,\n",
              "                      0.3262, 0.1689, 0.3487, 0.3571, 0.3233, 0.3877, 0.3477, 0.3313, 0.3302,\n",
              "                      0.3438, 0.3794, 0.2349, 0.2788, 0.3632, 0.2767, 0.2776, 0.3373, 0.3352,\n",
              "                      0.3637, 0.3216, 0.3061, 0.3388, 0.3155, 0.3289, 0.3297, 0.3529, 0.3098,\n",
              "                      0.2990, 0.1617, 0.3328, 0.3252, 0.3386, 0.3591, 0.3261, 0.3353, 0.2786,\n",
              "                      0.3034, 0.3173, 0.3207, 0.2665, 0.3070, 0.3531, 0.2779, 0.3659, 0.3351,\n",
              "                      0.2940, 0.2950, 0.2549, 0.3379, 0.3155, 0.3110, 0.2937, 0.3352, 0.3313,\n",
              "                      0.3676, 0.3163, 0.3476, 0.3202, 0.2918, 0.2817, 0.3493, 0.3785, 0.3060,\n",
              "                      0.3283, 0.3510, 0.2920, 0.3041, 0.3011, 0.3189, 0.3502, 0.1778, 0.3516,\n",
              "                      0.3213, 0.2364, 0.3230, 0.3590, 0.2797, 0.3159, 0.3387, 0.2163, 0.3081,\n",
              "                      0.2919, 0.3358, 0.3280, 0.3034, 0.3304, 0.2710, 0.2979, 0.3198, 0.2760,\n",
              "                      0.3377, 0.3142, 0.3432, 0.2899, 0.4139, 0.1749, 0.2962, 0.4160, 0.3129,\n",
              "                      0.3577, 0.2829, 0.3045, 0.2873, 0.3659, 0.3320, 0.3628, 0.3122, 0.2931,\n",
              "                      0.3486, 0.3613], device='cuda:0')),\n",
              "             ('layer2.0.bn1.bias',\n",
              "              tensor([-0.0675, -0.2092, -0.0168, -0.0652, -0.1025, -0.0825,  0.0418, -0.1036,\n",
              "                      -0.2681, -0.1750, -0.1406, -0.0567, -0.1032,  0.2256, -0.0585, -0.2004,\n",
              "                      -0.1029,  0.3118, -0.0682,  0.2021, -0.0955, -0.1453, -0.1305, -0.1362,\n",
              "                      -0.1191, -0.0607, -0.1215, -0.0765, -0.1155,  0.1622, -0.1268, -0.1613,\n",
              "                       0.0981, -0.0709, -0.1485, -0.1484, -0.0841, -0.0490, -0.1067, -0.0747,\n",
              "                      -0.0936, -0.2560, -0.3311, -0.2327, -0.0794, -0.0896,  0.5142, -0.0832,\n",
              "                      -0.1101, -0.0848, -0.2002, -0.1327, -0.1098, -0.0903, -0.1100, -0.0611,\n",
              "                      -0.0561, -0.0272, -0.0349, -0.2517,  0.0021, -0.1538, -0.0776, -0.1066,\n",
              "                      -0.0607,  0.0877, -0.0885, -0.1042, -0.1196, -0.0720, -0.1109, -0.1460,\n",
              "                      -0.0680, -0.1172, -0.1345, -0.0810, -0.0344, -0.0213, -0.0061, -0.2137,\n",
              "                      -0.1654, -0.1690, -0.1278, -0.0667, -0.2061, -0.1329, -0.0747, -0.1177,\n",
              "                       0.2587, -0.2328, -0.1606,  0.1285, -0.0915, -0.1237,  0.0035, -0.1098,\n",
              "                      -0.1090,  0.1729, -0.1086, -0.0633, -0.1437, -0.0641, -0.0483, -0.0563,\n",
              "                       0.0501, -0.0426, -0.0581, -0.0527, -0.0980, -0.1639, -0.1249, -0.0367,\n",
              "                      -0.1961,  0.2246,  0.0520, -0.1248, -0.0576, -0.1056, -0.0317, -0.0544,\n",
              "                      -0.0581, -0.1415, -0.0979, -0.1019, -0.1596, -0.1463, -0.0907, -0.0897],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.0.bn1.running_mean',\n",
              "              tensor([ 0.0749,  0.1311, -0.2017, -0.0117, -0.7286, -0.7363, -0.0537, -0.2475,\n",
              "                      -0.5789,  0.0787, -0.0047, -0.8779, -0.0421, -0.2144, -0.3857, -0.0208,\n",
              "                       0.0706, -1.4186,  0.4164,  0.0530, -0.5644, -0.0254,  0.3341, -0.8106,\n",
              "                      -0.1040, -0.5062, -0.2182, -0.2563, -0.3729,  0.6721,  0.1637,  0.1570,\n",
              "                      -1.8053,  0.2220, -0.1428, -0.5421,  0.4822, -0.0261, -0.5736, -0.7875,\n",
              "                      -0.2947, -0.0293, -0.3087, -0.5916, -1.0702, -0.0754, -1.0057, -0.8370,\n",
              "                      -0.5092, -0.5484, -0.5203, -0.2893, -0.3014, -1.0311, -0.4062, -0.5935,\n",
              "                      -0.3265, -0.2645, -0.2607, -0.9206, -0.1314, -0.4071, -0.1954, -0.7550,\n",
              "                      -0.8720, -0.0265,  0.1292,  0.7622,  0.1685, -0.4727, -0.9134,  0.6062,\n",
              "                      -0.3837, -0.0693, -0.5847, -0.1339, -0.8736, -1.2521,  0.2294, -0.6679,\n",
              "                      -0.5677, -0.0169, -0.0796,  0.1314, -1.2734,  0.1241, -0.7346, -0.2449,\n",
              "                       0.4213, -0.8142, -0.3897,  0.2117, -0.5834, -0.2287, -0.0667, -0.2656,\n",
              "                      -0.2606, -1.5017,  0.2217, -0.0588,  0.4812, -0.1593, -0.2937, -0.4599,\n",
              "                      -0.2181, -0.2227,  0.0494,  0.1247, -0.7541, -0.5465, -0.3662, -0.1036,\n",
              "                      -0.4378, -0.5944, -0.6876, -0.6351, -0.2844, -0.1095, -0.2425, -0.0284,\n",
              "                       0.5576, -0.3746,  0.2585, -0.4457, -0.1185, -1.0651,  0.1166, -0.0345],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.0.bn1.running_var',\n",
              "              tensor([0.7044, 0.4600, 1.2854, 1.7010, 1.0448, 0.6641, 1.0723, 1.0123, 0.3412,\n",
              "                      0.6017, 0.4686, 0.9249, 0.7297, 0.6620, 0.6246, 0.7862, 0.9030, 0.4169,\n",
              "                      0.9617, 0.5551, 0.8775, 0.7553, 0.5349, 1.0339, 1.0126, 1.0554, 0.6908,\n",
              "                      1.0254, 1.1935, 0.5862, 0.4731, 0.5514, 0.9738, 0.5515, 0.7616, 0.6325,\n",
              "                      0.6507, 0.8952, 0.7156, 0.7958, 0.8085, 0.3359, 0.2348, 0.5943, 1.0366,\n",
              "                      0.9337, 0.4568, 0.8112, 0.9136, 0.7735, 0.5218, 0.7497, 0.7485, 0.8216,\n",
              "                      0.8416, 0.7532, 1.4621, 0.9758, 1.2527, 0.4687, 1.0413, 0.6438, 0.8379,\n",
              "                      1.3568, 0.7301, 0.9860, 0.7889, 0.6937, 0.6268, 0.9554, 0.8264, 0.4591,\n",
              "                      0.9349, 0.9856, 0.7104, 0.8426, 0.7194, 0.6353, 1.1000, 0.6446, 0.9147,\n",
              "                      0.6908, 0.9903, 0.7802, 0.3859, 0.6567, 1.0900, 0.9380, 0.5125, 0.7234,\n",
              "                      0.5024, 0.9414, 0.4870, 0.6802, 1.3297, 0.7767, 0.7509, 0.4629, 0.6892,\n",
              "                      0.6712, 0.8808, 0.9868, 0.7400, 1.0481, 1.3942, 0.7046, 0.9054, 0.7626,\n",
              "                      1.0847, 0.8379, 0.6055, 0.7806, 0.8539, 0.8072, 1.0011, 1.2624, 0.8057,\n",
              "                      0.9691, 0.9090, 0.8899, 0.6971, 0.9710, 0.5001, 0.8895, 0.6955, 0.6210,\n",
              "                      0.7928, 0.9150], device='cuda:0')),\n",
              "             ('layer2.0.bn1.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer2.0.conv2.weight', tensor([[[[-0.0082, -0.0117, -0.0051],\n",
              "                        [-0.0122,  0.0258,  0.0396],\n",
              "                        [-0.0293, -0.0011,  0.0045]],\n",
              "              \n",
              "                       [[ 0.0350,  0.0240,  0.0077],\n",
              "                        [ 0.0031,  0.0219,  0.0309],\n",
              "                        [ 0.0373,  0.0400,  0.0171]],\n",
              "              \n",
              "                       [[ 0.0159, -0.0251, -0.0412],\n",
              "                        [-0.0213, -0.0185, -0.0568],\n",
              "                        [-0.0247, -0.0104,  0.0082]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0086,  0.0096, -0.0080],\n",
              "                        [ 0.0156,  0.0086, -0.0060],\n",
              "                        [ 0.0061, -0.0004, -0.0016]],\n",
              "              \n",
              "                       [[ 0.0063,  0.0091,  0.0017],\n",
              "                        [-0.0125, -0.0161, -0.0154],\n",
              "                        [-0.0126,  0.0065,  0.0028]],\n",
              "              \n",
              "                       [[ 0.0102, -0.0287, -0.0146],\n",
              "                        [ 0.0249,  0.0245, -0.0239],\n",
              "                        [ 0.0145,  0.0017, -0.0085]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0199,  0.0245,  0.0006],\n",
              "                        [-0.0133, -0.0114,  0.0339],\n",
              "                        [ 0.0005,  0.0251,  0.0134]],\n",
              "              \n",
              "                       [[-0.0125, -0.0261, -0.0170],\n",
              "                        [-0.0109,  0.0381,  0.0050],\n",
              "                        [ 0.0222,  0.0112,  0.0121]],\n",
              "              \n",
              "                       [[-0.0198, -0.0228,  0.0214],\n",
              "                        [-0.0284, -0.0559, -0.0722],\n",
              "                        [ 0.0164,  0.0529,  0.0254]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0225, -0.0335, -0.0362],\n",
              "                        [-0.0550, -0.0695, -0.0949],\n",
              "                        [-0.0561, -0.0725, -0.0719]],\n",
              "              \n",
              "                       [[ 0.0318,  0.0326,  0.0287],\n",
              "                        [ 0.0113,  0.0493,  0.0136],\n",
              "                        [-0.0023,  0.0243,  0.0057]],\n",
              "              \n",
              "                       [[ 0.0009, -0.0158, -0.0056],\n",
              "                        [-0.0003, -0.0263, -0.0556],\n",
              "                        [-0.0052, -0.0013, -0.0407]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0064,  0.0075, -0.0060],\n",
              "                        [ 0.0205, -0.0898, -0.0789],\n",
              "                        [-0.0064, -0.0448, -0.0066]],\n",
              "              \n",
              "                       [[ 0.0188,  0.0173, -0.0499],\n",
              "                        [ 0.0094,  0.0109, -0.0429],\n",
              "                        [ 0.0919,  0.0651,  0.0441]],\n",
              "              \n",
              "                       [[-0.0109, -0.0012,  0.0144],\n",
              "                        [ 0.0148, -0.0099,  0.0114],\n",
              "                        [ 0.0218, -0.0004,  0.0109]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0023,  0.0213, -0.0293],\n",
              "                        [-0.0128,  0.0047, -0.0463],\n",
              "                        [-0.0292, -0.0315, -0.0438]],\n",
              "              \n",
              "                       [[-0.0020,  0.0053, -0.0041],\n",
              "                        [-0.0061, -0.0502,  0.0425],\n",
              "                        [-0.0746, -0.0035, -0.0078]],\n",
              "              \n",
              "                       [[ 0.0109, -0.0144,  0.0373],\n",
              "                        [ 0.0132,  0.0473,  0.0256],\n",
              "                        [ 0.0212, -0.0082,  0.0383]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0274,  0.0054,  0.0026],\n",
              "                        [ 0.0615, -0.0384, -0.0003],\n",
              "                        [ 0.0277,  0.0103,  0.0554]],\n",
              "              \n",
              "                       [[-0.0320, -0.0254, -0.0518],\n",
              "                        [-0.0304, -0.0506, -0.0165],\n",
              "                        [-0.0204, -0.0456, -0.0146]],\n",
              "              \n",
              "                       [[-0.0351,  0.0202,  0.0261],\n",
              "                        [ 0.0198,  0.0374, -0.0335],\n",
              "                        [ 0.0210,  0.0438,  0.0060]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0075, -0.0215,  0.0003],\n",
              "                        [-0.0216,  0.0789,  0.0136],\n",
              "                        [-0.0270, -0.0029,  0.0480]],\n",
              "              \n",
              "                       [[-0.0254, -0.0283, -0.0347],\n",
              "                        [-0.0303, -0.0985, -0.0557],\n",
              "                        [-0.0165,  0.0027, -0.0200]],\n",
              "              \n",
              "                       [[ 0.0101, -0.0353, -0.0243],\n",
              "                        [-0.0155, -0.0255, -0.0078],\n",
              "                        [ 0.0045,  0.0125, -0.0177]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0347,  0.0281,  0.0125],\n",
              "                        [ 0.0406, -0.0089,  0.0214],\n",
              "                        [ 0.0087, -0.0285, -0.0235]],\n",
              "              \n",
              "                       [[ 0.0121,  0.0223, -0.0172],\n",
              "                        [ 0.0010,  0.0112,  0.0085],\n",
              "                        [ 0.0198,  0.0422,  0.0094]],\n",
              "              \n",
              "                       [[-0.0204,  0.0281,  0.0050],\n",
              "                        [-0.0314,  0.0604,  0.0167],\n",
              "                        [-0.0882, -0.0859, -0.0398]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0071, -0.0180,  0.0057],\n",
              "                        [ 0.0085, -0.0317, -0.0207],\n",
              "                        [-0.0107, -0.0578, -0.0548]],\n",
              "              \n",
              "                       [[ 0.0030,  0.0019,  0.0165],\n",
              "                        [-0.0137, -0.0073,  0.0100],\n",
              "                        [ 0.0193,  0.0119,  0.0062]],\n",
              "              \n",
              "                       [[ 0.0016,  0.0042,  0.0128],\n",
              "                        [ 0.0003, -0.0118,  0.0124],\n",
              "                        [-0.0056, -0.0085, -0.0123]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0052,  0.0107, -0.0446],\n",
              "                        [ 0.0007, -0.0517, -0.1422],\n",
              "                        [-0.0016, -0.0051, -0.0472]],\n",
              "              \n",
              "                       [[ 0.0097,  0.0559,  0.0387],\n",
              "                        [-0.0106,  0.0864,  0.0045],\n",
              "                        [ 0.0050, -0.0164, -0.0800]],\n",
              "              \n",
              "                       [[-0.0249,  0.0179,  0.0194],\n",
              "                        [ 0.0049,  0.0196,  0.0105],\n",
              "                        [-0.0034,  0.0307,  0.0109]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0014,  0.0240, -0.0177],\n",
              "                        [-0.0068, -0.0248, -0.0067],\n",
              "                        [ 0.0156, -0.0208, -0.0051]],\n",
              "              \n",
              "                       [[ 0.0372, -0.0032, -0.0670],\n",
              "                        [-0.0232, -0.0947, -0.0506],\n",
              "                        [-0.0105, -0.0070,  0.0034]],\n",
              "              \n",
              "                       [[-0.0228, -0.0844,  0.0296],\n",
              "                        [ 0.0129,  0.0502,  0.1449],\n",
              "                        [ 0.0108, -0.0109,  0.0040]]]], device='cuda:0')),\n",
              "             ('layer2.0.bn2.weight',\n",
              "              tensor([0.1655, 0.3256, 0.3110, 0.2656, 0.4340, 0.4082, 0.4364, 0.3238, 0.3571,\n",
              "                      0.2087, 0.2132, 0.3794, 0.1936, 0.2754, 0.1917, 0.2607, 0.3040, 0.3522,\n",
              "                      0.3728, 0.2939, 0.3973, 0.4536, 0.1728, 0.4935, 0.1858, 0.3776, 0.2850,\n",
              "                      0.1992, 0.2002, 0.2103, 0.4151, 0.3754, 0.2471, 0.2088, 0.2990, 0.3496,\n",
              "                      0.2496, 0.3835, 0.2551, 0.4355, 0.4887, 0.3503, 0.2577, 0.1753, 0.0622,\n",
              "                      0.2900, 0.2111, 0.2849, 0.4081, 0.4119, 0.1948, 0.4700, 0.3477, 0.1712,\n",
              "                      0.3391, 0.1716, 0.2787, 0.0875, 0.4399, 0.2853, 0.5003, 0.3203, 0.4752,\n",
              "                      0.3221, 0.6243, 0.4941, 0.5527, 0.2967, 0.3026, 0.4663, 0.2635, 0.4287,\n",
              "                      0.4571, 0.4494, 0.3466, 0.2638, 0.4207, 0.3855, 0.1848, 0.4091, 0.2798,\n",
              "                      0.4040, 0.3353, 0.2188, 0.3228, 0.1115, 0.2896, 0.4899, 0.2993, 0.4415,\n",
              "                      0.1799, 0.4571, 0.3097, 0.3401, 0.1585, 0.4834, 0.2593, 0.1649, 0.3285,\n",
              "                      0.4339, 0.4015, 0.1550, 0.3778, 0.3628, 0.1536, 0.3619, 0.2694, 0.2771,\n",
              "                      0.4427, 0.2831, 0.4001, 0.6260, 0.2684, 0.4979, 0.2165, 0.6388, 0.3276,\n",
              "                      0.4541, 0.3676, 0.2434, 0.4947, 0.1604, 0.3007, 0.4256, 0.3186, 0.4141,\n",
              "                      0.1551, 0.3755], device='cuda:0')),\n",
              "             ('layer2.0.bn2.bias',\n",
              "              tensor([ 0.0345,  0.0459,  0.1420, -0.1059, -0.0441, -0.1307, -0.0563,  0.0470,\n",
              "                      -0.0728,  0.0630, -0.0041, -0.0413, -0.0400,  0.0067,  0.0553,  0.0097,\n",
              "                       0.0600, -0.0390, -0.0416,  0.0117, -0.1907, -0.1277,  0.0483, -0.1170,\n",
              "                       0.1072,  0.0190,  0.0083,  0.0095,  0.0627,  0.1294, -0.0038,  0.0338,\n",
              "                       0.0824,  0.0395, -0.1113, -0.1013,  0.0917, -0.1427,  0.0101,  0.1245,\n",
              "                       0.0644,  0.0914, -0.0630,  0.1051,  0.0481,  0.0317,  0.0368,  0.0217,\n",
              "                      -0.0085, -0.0566, -0.0112, -0.1669,  0.1365,  0.0818,  0.0680,  0.0921,\n",
              "                       0.0337,  0.0779, -0.1275,  0.0296, -0.2066, -0.0286, -0.2026,  0.0595,\n",
              "                      -0.0636,  0.0702, -0.0159,  0.0571,  0.0487, -0.1619,  0.0145, -0.0308,\n",
              "                      -0.1371,  0.0378,  0.0578,  0.1040, -0.1264,  0.0656,  0.0799, -0.0586,\n",
              "                      -0.0153,  0.0050,  0.0780,  0.1087, -0.0359,  0.0646,  0.1079, -0.0635,\n",
              "                      -0.0006, -0.0002,  0.1221, -0.2781,  0.0119, -0.0635,  0.0383, -0.0847,\n",
              "                       0.1017,  0.1825, -0.1128,  0.0902, -0.0284,  0.0752, -0.0755, -0.0704,\n",
              "                       0.0095,  0.0693,  0.1505,  0.1163, -0.0687, -0.0590, -0.0749, -0.1032,\n",
              "                       0.0503, -0.1609,  0.0516, -0.2638, -0.1335, -0.0789, -0.0804,  0.0434,\n",
              "                      -0.0435,  0.0854, -0.0305,  0.0016,  0.0291, -0.0568,  0.0480, -0.1339],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.0.bn2.running_mean',\n",
              "              tensor([-0.4679, -0.1870, -0.3546, -0.1056, -0.2250, -0.1431, -0.5624, -0.1812,\n",
              "                      -0.2882, -0.0366, -0.0226, -0.2027,  0.0020, -0.1601, -0.2504, -0.3645,\n",
              "                      -0.4883, -0.1462,  0.4627, -0.0454, -0.2903, -0.0944, -0.2805, -0.0467,\n",
              "                       0.0115, -0.2492, -0.1915,  0.0383,  0.0630, -0.3805, -0.2403, -0.1735,\n",
              "                      -0.3524, -0.1162, -0.3364, -0.0197,  0.3446, -0.1218, -0.1912, -0.1246,\n",
              "                      -1.0222, -1.0634, -0.0280,  0.0211,  0.1639, -0.3979,  0.0513, -0.4341,\n",
              "                      -0.1917, -0.1781, -0.2775, -0.0609,  0.0232, -0.4040, -0.5183, -0.2030,\n",
              "                      -0.0911, -0.2013, -0.1421,  0.1305, -0.3453, -0.2453, -0.1466, -0.0187,\n",
              "                      -0.5178, -0.2480, -0.4852, -0.0056, -0.4896, -0.0310,  0.0869, -0.0903,\n",
              "                      -0.0484, -0.0920, -0.4757,  0.0124, -0.1120, -0.1762, -0.1474, -0.1210,\n",
              "                      -0.5346, -0.2970, -0.0362, -0.7984, -0.1794, -0.2853, -0.0738, -0.1119,\n",
              "                      -0.2416, -0.3625, -0.5397,  0.2269, -0.2977, -0.2635, -0.1969, -0.3617,\n",
              "                      -0.0018, -0.2115, -0.0544, -0.6580, -0.0574, -0.2291, -0.3159, -0.2280,\n",
              "                      -0.0962, -0.3726,  0.1161, -0.1183, -0.2063, -0.0809,  0.0023, -1.0231,\n",
              "                      -0.0147, -0.0640, -0.4270, -0.8916, -0.0562, -0.0271,  0.1254, -0.3889,\n",
              "                      -0.4783,  0.0433, -0.2094, -0.2720, -0.0835, -0.1557,  0.0037, -0.0785],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.0.bn2.running_var',\n",
              "              tensor([0.0488, 0.0596, 0.0665, 0.0344, 0.0929, 0.0609, 0.0592, 0.1049, 0.0475,\n",
              "                      0.0908, 0.0509, 0.0810, 0.0346, 0.0469, 0.0544, 0.0513, 0.0958, 0.0862,\n",
              "                      0.1609, 0.0594, 0.0558, 0.0831, 0.0499, 0.0732, 0.0418, 0.1023, 0.0586,\n",
              "                      0.0475, 0.0437, 0.0703, 0.0946, 0.0919, 0.0666, 0.0601, 0.0545, 0.0355,\n",
              "                      0.1100, 0.0392, 0.0496, 0.2244, 0.2003, 0.1373, 0.0325, 0.0495, 0.0271,\n",
              "                      0.1081, 0.0409, 0.0989, 0.0889, 0.0683, 0.0362, 0.0626, 0.1170, 0.0511,\n",
              "                      0.0923, 0.0585, 0.0520, 0.0331, 0.0635, 0.0619, 0.0449, 0.0632, 0.0619,\n",
              "                      0.0767, 0.1766, 0.1103, 0.2217, 0.0677, 0.0655, 0.0564, 0.0639, 0.0532,\n",
              "                      0.0747, 0.1143, 0.1220, 0.0745, 0.0690, 0.0962, 0.0363, 0.0797, 0.0299,\n",
              "                      0.0805, 0.0730, 0.0696, 0.0701, 0.0641, 0.0841, 0.1025, 0.0524, 0.0815,\n",
              "                      0.0358, 0.0475, 0.0519, 0.0697, 0.0224, 0.0951, 0.0720, 0.0478, 0.0396,\n",
              "                      0.2304, 0.0909, 0.0728, 0.0612, 0.0683, 0.0268, 0.0828, 0.1316, 0.0590,\n",
              "                      0.0865, 0.0478, 0.0620, 0.1514, 0.0712, 0.0781, 0.0616, 0.1094, 0.0575,\n",
              "                      0.0637, 0.0481, 0.0526, 0.1446, 0.0752, 0.0460, 0.1076, 0.0460, 0.0584,\n",
              "                      0.0518, 0.0397], device='cuda:0')),\n",
              "             ('layer2.0.bn2.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer2.0.downsample.0.weight', tensor([[[[ 0.0094]],\n",
              "              \n",
              "                       [[-0.3157]],\n",
              "              \n",
              "                       [[ 0.0290]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.1745]],\n",
              "              \n",
              "                       [[ 0.0098]],\n",
              "              \n",
              "                       [[ 0.0084]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0024]],\n",
              "              \n",
              "                       [[ 0.0063]],\n",
              "              \n",
              "                       [[-0.0099]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0307]],\n",
              "              \n",
              "                       [[-0.0775]],\n",
              "              \n",
              "                       [[-0.0104]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0442]],\n",
              "              \n",
              "                       [[ 0.0186]],\n",
              "              \n",
              "                       [[-0.1683]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0333]],\n",
              "              \n",
              "                       [[-0.0249]],\n",
              "              \n",
              "                       [[ 0.0590]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0241]],\n",
              "              \n",
              "                       [[ 0.0394]],\n",
              "              \n",
              "                       [[-0.0492]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0556]],\n",
              "              \n",
              "                       [[ 0.0659]],\n",
              "              \n",
              "                       [[ 0.0592]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0070]],\n",
              "              \n",
              "                       [[-0.0132]],\n",
              "              \n",
              "                       [[ 0.0814]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.7869]],\n",
              "              \n",
              "                       [[-0.0041]],\n",
              "              \n",
              "                       [[-0.0400]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0322]],\n",
              "              \n",
              "                       [[-0.0232]],\n",
              "              \n",
              "                       [[-0.0502]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0239]],\n",
              "              \n",
              "                       [[-0.0627]],\n",
              "              \n",
              "                       [[ 0.0242]]]], device='cuda:0')),\n",
              "             ('layer2.0.downsample.1.weight',\n",
              "              tensor([ 0.3720,  0.0453,  0.1054,  0.3622,  0.1899,  0.1663,  0.1826,  0.3219,\n",
              "                       0.1935,  0.1242,  0.3279,  0.2132,  0.3768,  0.1624,  0.3143,  0.2692,\n",
              "                       0.1536,  0.2144,  0.2020,  0.1431,  0.6289,  0.0583,  0.2329,  0.0919,\n",
              "                       0.1880,  0.0321,  0.2444,  0.3221,  0.2756,  0.2844,  0.1478,  0.0603,\n",
              "                       0.2180,  0.3486,  0.3690,  0.3350,  0.1154,  0.3317,  0.2327,  0.1130,\n",
              "                       0.1642,  0.2316,  0.2925,  0.1958,  0.2352,  0.2748,  0.2544,  0.1547,\n",
              "                       0.0737,  0.2554,  0.3947,  0.1963,  0.0954,  0.2635,  0.1184,  0.2560,\n",
              "                       0.2564,  0.2763,  0.0618,  0.2860,  0.1420,  0.2237,  0.1795,  0.0861,\n",
              "                       0.0399,  0.0591,  0.1037,  0.0936,  0.1160,  0.0974,  0.2124,  0.1743,\n",
              "                       0.1341,  0.0987,  0.1500,  0.1006,  0.0995,  0.0272,  0.3462,  0.2362,\n",
              "                       0.2917,  0.1065,  0.0564,  0.2575,  0.2193,  0.3742,  0.0853,  0.1822,\n",
              "                       0.1272,  0.1239,  0.3171,  0.2363,  0.1755,  0.1415,  0.2608,  0.1559,\n",
              "                       0.0814,  0.1908,  0.1712,  0.1467,  0.2650,  0.3813,  0.2246,  0.2087,\n",
              "                       0.4633,  0.1841,  0.0163,  0.0661,  0.0742,  0.1984,  0.1623,  0.1051,\n",
              "                       0.2949,  0.1358,  0.4088,  0.1946,  0.3472,  0.1485,  0.0829,  0.2281,\n",
              "                       0.0567,  0.2557,  0.1544, -0.0207,  0.1837,  0.1210,  0.3149,  0.1732],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.0.downsample.1.bias',\n",
              "              tensor([ 0.0345,  0.0459,  0.1420, -0.1059, -0.0441, -0.1307, -0.0563,  0.0470,\n",
              "                      -0.0728,  0.0630, -0.0041, -0.0413, -0.0400,  0.0067,  0.0553,  0.0097,\n",
              "                       0.0600, -0.0390, -0.0416,  0.0117, -0.1907, -0.1277,  0.0483, -0.1170,\n",
              "                       0.1072,  0.0190,  0.0083,  0.0095,  0.0627,  0.1294, -0.0038,  0.0338,\n",
              "                       0.0824,  0.0395, -0.1113, -0.1013,  0.0917, -0.1427,  0.0101,  0.1245,\n",
              "                       0.0644,  0.0914, -0.0630,  0.1051,  0.0481,  0.0317,  0.0368,  0.0217,\n",
              "                      -0.0085, -0.0566, -0.0112, -0.1669,  0.1365,  0.0818,  0.0680,  0.0921,\n",
              "                       0.0337,  0.0779, -0.1275,  0.0296, -0.2066, -0.0286, -0.2026,  0.0595,\n",
              "                      -0.0636,  0.0702, -0.0159,  0.0571,  0.0487, -0.1619,  0.0145, -0.0308,\n",
              "                      -0.1371,  0.0378,  0.0578,  0.1040, -0.1264,  0.0656,  0.0799, -0.0586,\n",
              "                      -0.0153,  0.0050,  0.0780,  0.1087, -0.0359,  0.0646,  0.1079, -0.0635,\n",
              "                      -0.0006, -0.0002,  0.1221, -0.2781,  0.0119, -0.0635,  0.0383, -0.0847,\n",
              "                       0.1017,  0.1825, -0.1128,  0.0902, -0.0284,  0.0752, -0.0755, -0.0704,\n",
              "                       0.0095,  0.0693,  0.1505,  0.1163, -0.0687, -0.0590, -0.0749, -0.1032,\n",
              "                       0.0503, -0.1609,  0.0516, -0.2638, -0.1335, -0.0789, -0.0804,  0.0434,\n",
              "                      -0.0435,  0.0854, -0.0305,  0.0016,  0.0291, -0.0568,  0.0480, -0.1339],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.0.downsample.1.running_mean',\n",
              "              tensor([-0.1388,  0.1549,  0.0674,  0.1026, -0.0724, -0.2602,  0.2564, -0.2177,\n",
              "                       0.0371, -0.2186, -0.2253, -0.4517, -0.3033, -0.1668,  0.1244, -0.1602,\n",
              "                      -0.0535,  0.2898,  0.1151, -0.0029, -0.1960, -0.1665, -0.6652, -0.2003,\n",
              "                       0.2366,  0.1413, -0.3132, -0.1494,  0.2585, -0.7819, -0.1244, -0.1196,\n",
              "                      -0.9605, -0.2025, -0.0279, -0.4017,  0.2328,  0.2419, -0.0253,  0.3275,\n",
              "                      -0.4225,  0.1601, -0.2173, -0.4020, -0.1433,  0.0013, -0.2444, -0.2151,\n",
              "                       0.0435, -0.3846,  0.2532, -0.5622,  0.0581,  0.2219, -0.0363, -0.2158,\n",
              "                       0.1272,  0.5734,  0.0120,  0.0072,  0.1732, -0.3385, -0.1237,  0.0631,\n",
              "                      -0.0591,  0.1916, -0.3211, -0.1391, -0.1603,  0.2371, -0.2504,  0.3630,\n",
              "                       0.1959, -0.0792, -0.5840, -0.1184, -0.3077,  0.3184,  0.1901, -0.1409,\n",
              "                       0.3885, -0.2468, -0.2505, -0.1445, -0.1335, -0.1088,  0.0403, -0.0477,\n",
              "                       0.4335,  0.0966, -0.4269,  0.1863,  0.1969,  0.0842, -0.1765, -0.0851,\n",
              "                      -0.2234, -0.4862, -0.0933,  0.0889, -0.0607, -0.2533,  0.2649, -0.2180,\n",
              "                      -0.2909, -0.4965,  0.1960,  0.1161, -0.1638, -0.2065, -0.0463, -0.3694,\n",
              "                      -0.4638, -0.0851, -0.0378,  0.7338, -0.1856,  0.0222,  0.0726,  0.0848,\n",
              "                       0.0444,  1.0016,  0.1473,  0.0888, -0.8679, -0.1732,  1.3208, -0.2681],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.0.downsample.1.running_var',\n",
              "              tensor([0.2862, 0.0187, 0.0239, 0.0770, 0.0819, 0.0440, 0.0369, 0.2404, 0.0549,\n",
              "                      0.0679, 0.1261, 0.1204, 0.1637, 0.0728, 0.1513, 0.0900, 0.0710, 0.1113,\n",
              "                      0.0784, 0.0361, 0.2558, 0.0159, 0.0789, 0.0233, 0.1010, 0.0098, 0.1576,\n",
              "                      0.1156, 0.0984, 0.1591, 0.0796, 0.0212, 0.0576, 0.1636, 0.0890, 0.0654,\n",
              "                      0.0480, 0.0464, 0.1384, 0.1005, 0.0987, 0.0901, 0.0628, 0.1015, 0.1032,\n",
              "                      0.1761, 0.0919, 0.0839, 0.0179, 0.1105, 0.1366, 0.0663, 0.0276, 0.1100,\n",
              "                      0.0408, 0.1191, 0.0778, 0.0745, 0.0153, 0.1363, 0.0116, 0.0529, 0.0526,\n",
              "                      0.0265, 0.0143, 0.0131, 0.0415, 0.0265, 0.0664, 0.0195, 0.0770, 0.0611,\n",
              "                      0.0381, 0.0292, 0.0648, 0.0351, 0.0175, 0.0175, 0.1453, 0.0886, 0.0942,\n",
              "                      0.0383, 0.0308, 0.1144, 0.0712, 0.2025, 0.0280, 0.0750, 0.0400, 0.0387,\n",
              "                      0.1206, 0.0520, 0.0331, 0.0558, 0.0799, 0.0467, 0.0315, 0.0724, 0.0425,\n",
              "                      0.1205, 0.1325, 0.2155, 0.0614, 0.0576, 0.1909, 0.0772, 0.0368, 0.0499,\n",
              "                      0.0244, 0.0692, 0.0333, 0.0470, 0.1964, 0.0284, 0.2607, 0.0321, 0.1186,\n",
              "                      0.0361, 0.0200, 0.0828, 0.0154, 0.2902, 0.0287, 0.0071, 0.0455, 0.0400,\n",
              "                      0.1356, 0.0433], device='cuda:0')),\n",
              "             ('layer2.0.downsample.1.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer2.1.conv1.weight', tensor([[[[-0.0002, -0.0100, -0.0173],\n",
              "                        [ 0.0318,  0.0028,  0.0032],\n",
              "                        [ 0.0051, -0.0251,  0.0007]],\n",
              "              \n",
              "                       [[-0.0241, -0.0009, -0.0154],\n",
              "                        [-0.0208,  0.0044, -0.0010],\n",
              "                        [ 0.0071, -0.0136, -0.0197]],\n",
              "              \n",
              "                       [[ 0.0029,  0.0350,  0.0251],\n",
              "                        [-0.0583, -0.0186,  0.0027],\n",
              "                        [ 0.0429, -0.1029, -0.0622]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0054,  0.0136,  0.0292],\n",
              "                        [-0.0102, -0.0357,  0.0184],\n",
              "                        [ 0.0025,  0.0012,  0.0410]],\n",
              "              \n",
              "                       [[-0.0183, -0.0295, -0.0172],\n",
              "                        [ 0.0295,  0.0230,  0.0033],\n",
              "                        [-0.0098, -0.0060, -0.0004]],\n",
              "              \n",
              "                       [[ 0.0078,  0.0202,  0.0388],\n",
              "                        [ 0.0038,  0.0437,  0.0219],\n",
              "                        [-0.0134, -0.0283, -0.0014]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0864,  0.0855, -0.0557],\n",
              "                        [ 0.0398, -0.0035, -0.1059],\n",
              "                        [-0.0628, -0.1306, -0.1339]],\n",
              "              \n",
              "                       [[ 0.0030, -0.0133,  0.0043],\n",
              "                        [-0.0167, -0.0285,  0.0084],\n",
              "                        [ 0.0168,  0.0193,  0.0583]],\n",
              "              \n",
              "                       [[ 0.0204,  0.0074,  0.0135],\n",
              "                        [-0.0202, -0.0063,  0.0278],\n",
              "                        [-0.0176, -0.0103,  0.0167]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0376, -0.0261, -0.0093],\n",
              "                        [-0.0360,  0.0083,  0.0138],\n",
              "                        [-0.0036,  0.0081,  0.0075]],\n",
              "              \n",
              "                       [[-0.0453, -0.0154,  0.0121],\n",
              "                        [-0.0376, -0.0141,  0.0296],\n",
              "                        [-0.0076, -0.0115,  0.0037]],\n",
              "              \n",
              "                       [[ 0.0050,  0.0144,  0.0020],\n",
              "                        [ 0.0106, -0.0133, -0.0111],\n",
              "                        [-0.0228,  0.0005,  0.0010]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0216, -0.0121, -0.0069],\n",
              "                        [-0.0066,  0.0071,  0.0109],\n",
              "                        [-0.0134,  0.0299,  0.0083]],\n",
              "              \n",
              "                       [[ 0.0030,  0.0072,  0.0275],\n",
              "                        [-0.0082,  0.0035, -0.0073],\n",
              "                        [ 0.0273,  0.0001, -0.0057]],\n",
              "              \n",
              "                       [[-0.0381,  0.0082,  0.1422],\n",
              "                        [-0.0433,  0.0060,  0.0787],\n",
              "                        [-0.0498, -0.0022,  0.0278]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0361,  0.0075, -0.0435],\n",
              "                        [-0.0063, -0.0909, -0.0030],\n",
              "                        [-0.0227,  0.0042,  0.0781]],\n",
              "              \n",
              "                       [[ 0.0156,  0.0041, -0.0132],\n",
              "                        [-0.0174, -0.0319, -0.0280],\n",
              "                        [-0.0186, -0.0053,  0.0034]],\n",
              "              \n",
              "                       [[-0.0064,  0.0009, -0.0167],\n",
              "                        [-0.0311, -0.0461, -0.0306],\n",
              "                        [-0.0188, -0.0043, -0.0049]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0280,  0.0188,  0.0043],\n",
              "                        [-0.0147, -0.0070, -0.0013],\n",
              "                        [-0.0153, -0.0084,  0.0109]],\n",
              "              \n",
              "                       [[ 0.0067, -0.0059,  0.0012],\n",
              "                        [ 0.0275,  0.0274,  0.0088],\n",
              "                        [-0.0526, -0.0393, -0.0423]],\n",
              "              \n",
              "                       [[ 0.0057,  0.0102,  0.0130],\n",
              "                        [-0.0111,  0.0072, -0.0216],\n",
              "                        [ 0.0770,  0.0637, -0.0066]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0148,  0.0137,  0.0423],\n",
              "                        [ 0.0099,  0.0017,  0.0146],\n",
              "                        [ 0.0152,  0.0567, -0.0286]],\n",
              "              \n",
              "                       [[-0.0335, -0.0397, -0.0290],\n",
              "                        [ 0.0058, -0.0287, -0.0172],\n",
              "                        [ 0.0030,  0.0677, -0.0166]],\n",
              "              \n",
              "                       [[ 0.0025, -0.0449, -0.0164],\n",
              "                        [ 0.0291, -0.0687, -0.0628],\n",
              "                        [ 0.0496,  0.0348, -0.0155]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0249,  0.0340,  0.0065],\n",
              "                        [-0.0076,  0.0359, -0.0025],\n",
              "                        [ 0.0155,  0.0036, -0.0064]],\n",
              "              \n",
              "                       [[-0.0461, -0.0731, -0.0523],\n",
              "                        [-0.0082,  0.0081, -0.0301],\n",
              "                        [-0.0273, -0.0200, -0.0062]],\n",
              "              \n",
              "                       [[-0.0721, -0.0668,  0.0261],\n",
              "                        [ 0.0532,  0.0248,  0.0524],\n",
              "                        [ 0.0020,  0.0024, -0.0108]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0305,  0.0085, -0.0299],\n",
              "                        [ 0.0024,  0.0529,  0.0167],\n",
              "                        [-0.0202, -0.0097, -0.0358]],\n",
              "              \n",
              "                       [[-0.0327,  0.0197, -0.0376],\n",
              "                        [-0.0025, -0.0430,  0.0016],\n",
              "                        [ 0.0404,  0.0290,  0.0717]],\n",
              "              \n",
              "                       [[-0.0294,  0.0480,  0.0114],\n",
              "                        [-0.0536, -0.0067,  0.0107],\n",
              "                        [-0.0202, -0.0338, -0.0210]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0329,  0.0451,  0.0314],\n",
              "                        [ 0.0189, -0.0027, -0.0025],\n",
              "                        [ 0.0108,  0.0014,  0.0301]],\n",
              "              \n",
              "                       [[ 0.0094,  0.0207,  0.0401],\n",
              "                        [ 0.0216,  0.0430,  0.0087],\n",
              "                        [ 0.0088,  0.0517,  0.0094]],\n",
              "              \n",
              "                       [[ 0.0120,  0.0116,  0.0372],\n",
              "                        [-0.0477,  0.0153, -0.0118],\n",
              "                        [ 0.0298,  0.0584, -0.0071]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0035,  0.0105, -0.0016],\n",
              "                        [ 0.0116,  0.0262,  0.0131],\n",
              "                        [-0.0182, -0.0451, -0.0061]],\n",
              "              \n",
              "                       [[-0.0134, -0.0106, -0.0264],\n",
              "                        [-0.0092,  0.0646, -0.0029],\n",
              "                        [-0.0083, -0.0037, -0.0105]],\n",
              "              \n",
              "                       [[ 0.0201,  0.0088,  0.0016],\n",
              "                        [-0.0055,  0.0220,  0.0158],\n",
              "                        [ 0.0150, -0.0105, -0.0130]]]], device='cuda:0')),\n",
              "             ('layer2.1.bn1.weight',\n",
              "              tensor([0.3288, 0.3046, 0.3221, 0.3468, 0.2983, 0.2999, 0.3221, 0.3732, 0.3046,\n",
              "                      0.3543, 0.2661, 0.3754, 0.2323, 0.3462, 0.2998, 0.4486, 0.3412, 0.4222,\n",
              "                      0.3382, 0.2676, 0.3089, 0.3502, 0.3348, 0.2748, 0.2788, 0.3987, 0.3024,\n",
              "                      0.3331, 0.3517, 0.3977, 0.3004, 0.3765, 0.1487, 0.2509, 0.3110, 0.3033,\n",
              "                      0.2534, 0.3694, 0.2986, 0.2810, 0.3698, 0.3491, 0.3586, 0.3246, 0.2976,\n",
              "                      0.3099, 0.3739, 0.2565, 0.3583, 0.3224, 0.3216, 0.3658, 0.3166, 0.3489,\n",
              "                      0.3898, 0.4026, 0.4499, 0.3330, 0.3106, 0.3632, 0.3623, 0.3098, 0.2494,\n",
              "                      0.3427, 0.2787, 0.2805, 0.3400, 0.3571, 0.3543, 0.2611, 0.3442, 0.3006,\n",
              "                      0.3306, 0.3849, 0.2501, 0.3645, 0.3134, 0.3780, 0.2785, 0.3629, 0.2529,\n",
              "                      0.2826, 0.2997, 0.3068, 0.2709, 0.2798, 0.2843, 0.5046, 0.3380, 0.2456,\n",
              "                      0.3274, 0.3300, 0.2483, 0.3199, 0.3399, 0.3164, 0.3226, 0.2814, 0.3577,\n",
              "                      0.2837, 0.2365, 0.3360, 0.2909, 0.3428, 0.3076, 0.3591, 0.3061, 0.2790,\n",
              "                      0.3252, 0.2844, 0.3375, 0.2311, 0.3070, 0.2335, 0.2934, 0.3258, 0.3987,\n",
              "                      0.2771, 0.2638, 0.2893, 0.3610, 0.4178, 0.3493, 0.2803, 0.2247, 0.4158,\n",
              "                      0.3136, 0.2381], device='cuda:0')),\n",
              "             ('layer2.1.bn1.bias',\n",
              "              tensor([-0.1819, -0.2263, -0.3542, -0.0776, -0.1917, -0.0716, -0.1801, -0.2726,\n",
              "                      -0.1658, -0.1867, -0.2848, -0.1765, -0.1341, -0.2340, -0.1690, -0.2953,\n",
              "                      -0.2622, -0.3971, -0.1638, -0.1531, -0.2644, -0.1102, -0.2014, -0.1865,\n",
              "                      -0.1040, -0.3575, -0.2379, -0.3337, -0.3092, -0.3202, -0.1600, -0.1963,\n",
              "                      -0.0962, -0.3324, -0.1592, -0.1481, -0.0870, -0.3233, -0.2611, -0.3717,\n",
              "                      -0.2135, -0.2276, -0.1922, -0.1759, -0.1783, -0.1628, -0.3010, -0.1540,\n",
              "                      -0.2034, -0.1537, -0.2168, -0.2185, -0.0728, -0.1451, -0.2621, -0.5016,\n",
              "                      -0.4378, -0.0610, -0.1606, -0.2101, -0.2169, -0.1973, -0.0391, -0.1507,\n",
              "                      -0.1410, -0.4946, -0.1824, -0.2346, -0.1780, -0.1774, -0.1954, -0.2132,\n",
              "                      -0.2060, -0.2840, -0.0579, -0.2031, -0.2960, -0.2571, -0.1067, -0.3169,\n",
              "                      -0.1603, -0.1487, -0.2153, -0.1405, -0.1818, -0.1078, -0.1239, -0.4025,\n",
              "                      -0.2310, -0.1491, -0.1152, -0.2118, -0.1104, -0.1611, -0.3850, -0.2528,\n",
              "                      -0.1783, -0.1869, -0.2450, -0.1857, -0.1214, -0.1349, -0.1381, -0.2307,\n",
              "                      -0.2005, -0.3835, -0.1417, -0.1152, -0.1355, -0.2166, -0.1763, -0.2245,\n",
              "                      -0.1242, -0.2725, -0.0963, -0.0772, -0.2122, -0.1496, -0.3075, -0.1274,\n",
              "                      -0.2223, -0.4919, -0.3770, -0.1499, -0.1599, -0.3902, -0.7114, -0.1772],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.1.bn1.running_mean',\n",
              "              tensor([-0.5284, -0.5198,  0.4076, -0.7125, -0.7822, -0.5798, -0.3141, -0.5378,\n",
              "                      -0.1654, -0.3928, -0.3590, -0.4136, -0.2531, -0.4996, -0.4086, -0.6279,\n",
              "                      -0.3508, -0.5250,  0.3326, -0.2265, -0.3459, -0.6148, -0.3782, -0.1670,\n",
              "                      -0.8905, -0.2543, -0.4493, -0.1617, -0.6440, -0.5081, -0.4849, -0.6545,\n",
              "                       0.4852, -0.3933, -0.0099, -0.5185, -0.6606, -0.3545, -0.2662,  0.5868,\n",
              "                      -0.3223, -0.5152, -0.3393, -0.4199, -0.2412, -0.2627, -0.3454,  0.0182,\n",
              "                      -0.5588, -0.5026, -0.5039, -0.5525, -0.0320, -0.1614, -0.7888, -0.5918,\n",
              "                      -1.2974, -0.0767, -0.1274, -0.6671, -0.4031, -0.3647,  0.0129, -0.3126,\n",
              "                       0.0362,  0.1832, -0.4764, -0.2508, -0.2977,  0.5350, -0.4003, -0.2933,\n",
              "                      -0.7126, -0.3831,  0.0088, -0.5659,  0.0518, -0.3747,  0.0516, -0.2688,\n",
              "                      -0.1694,  0.0642, -0.1125, -0.7912, -0.0502, -0.4326, -0.1123, -0.3222,\n",
              "                      -0.2403,  1.1197, -0.3564,  0.0763, -0.2115, -0.0607,  0.1838, -0.5456,\n",
              "                      -0.2304, -0.0414, -0.5291, -0.0449, -0.2928, -0.4351, -0.2397, -0.3434,\n",
              "                      -0.4659, -0.1217, -0.2209,  0.1837, -0.7474, -0.2189, -0.5477, -0.2303,\n",
              "                      -0.7156,  0.3823,  0.2970, -0.6034, -0.3858, -0.2865, -0.3616,  0.0713,\n",
              "                      -0.4812, -0.8317, -0.7775, -0.4574,  0.2123, -0.8611, -1.3359,  0.0674],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.1.bn1.running_var',\n",
              "              tensor([0.3037, 0.1637, 0.3174, 0.5090, 0.1782, 0.3105, 0.1883, 0.1840, 0.2750,\n",
              "                      0.4797, 0.1255, 0.3603, 0.2255, 0.1723, 0.2420, 0.2442, 0.2975, 0.2212,\n",
              "                      0.2497, 0.2043, 0.1851, 0.2693, 0.3714, 0.1707, 0.2485, 0.2767, 0.1783,\n",
              "                      0.1556, 0.2621, 0.3389, 0.1862, 0.2948, 0.1515, 0.1193, 0.3433, 0.1582,\n",
              "                      0.1547, 0.2892, 0.1937, 0.1593, 0.3287, 0.2831, 0.3520, 0.2444, 0.3338,\n",
              "                      0.2856, 0.2310, 0.1302, 0.2966, 0.2564, 0.2496, 0.3736, 0.2731, 0.3162,\n",
              "                      0.5445, 0.2047, 0.2996, 0.4258, 0.2195, 0.1893, 0.2777, 0.2521, 0.1995,\n",
              "                      0.3472, 0.2028, 0.1122, 0.2090, 0.2347, 0.3871, 0.4016, 0.1510, 0.2373,\n",
              "                      0.2060, 0.2615, 0.2827, 0.3301, 0.2982, 0.2120, 0.1951, 0.2538, 0.1844,\n",
              "                      0.2461, 0.2689, 0.3791, 0.1802, 0.1764, 0.3172, 0.3345, 0.2256, 0.2302,\n",
              "                      0.2278, 0.1944, 0.1331, 0.2589, 0.3813, 0.2225, 0.3590, 0.1384, 0.2372,\n",
              "                      0.1969, 0.1443, 0.2540, 0.3594, 0.2851, 0.1531, 0.2361, 0.3438, 0.2001,\n",
              "                      0.3421, 0.1411, 0.3427, 0.1157, 0.2939, 0.1866, 0.2274, 0.3305, 0.2967,\n",
              "                      0.2138, 0.1226, 0.2713, 0.2224, 0.1783, 0.1844, 0.4042, 0.2340, 0.2292,\n",
              "                      0.1318, 0.1691], device='cuda:0')),\n",
              "             ('layer2.1.bn1.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer2.1.conv2.weight', tensor([[[[-0.0192,  0.0011, -0.0050],\n",
              "                        [-0.0146, -0.0249, -0.0261],\n",
              "                        [ 0.0040,  0.0064, -0.0179]],\n",
              "              \n",
              "                       [[-0.0102,  0.0028,  0.0226],\n",
              "                        [-0.0174,  0.0197,  0.0636],\n",
              "                        [ 0.0051,  0.0750,  0.1002]],\n",
              "              \n",
              "                       [[-0.0079,  0.0067,  0.0237],\n",
              "                        [-0.0084,  0.0093,  0.0063],\n",
              "                        [ 0.0088,  0.0133,  0.0062]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0194,  0.0094,  0.0244],\n",
              "                        [-0.0136, -0.0855, -0.0213],\n",
              "                        [-0.0150, -0.0487, -0.0008]],\n",
              "              \n",
              "                       [[ 0.0299,  0.0393,  0.0312],\n",
              "                        [-0.0198, -0.0679, -0.0278],\n",
              "                        [ 0.0293,  0.0329,  0.0106]],\n",
              "              \n",
              "                       [[-0.0154, -0.0116, -0.0071],\n",
              "                        [-0.0251, -0.0259, -0.0076],\n",
              "                        [-0.0123, -0.0066, -0.0224]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0003,  0.0272,  0.0422],\n",
              "                        [ 0.0447,  0.0482,  0.0028],\n",
              "                        [ 0.0198,  0.0151, -0.0157]],\n",
              "              \n",
              "                       [[-0.0115, -0.0025, -0.0185],\n",
              "                        [-0.0145,  0.0037, -0.0163],\n",
              "                        [-0.0265, -0.0042, -0.0154]],\n",
              "              \n",
              "                       [[ 0.0108, -0.0153, -0.0311],\n",
              "                        [-0.0295, -0.0025,  0.0017],\n",
              "                        [-0.0395,  0.0062,  0.0164]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0492, -0.0470, -0.0607],\n",
              "                        [-0.0253, -0.0174, -0.0292],\n",
              "                        [-0.0026,  0.0229,  0.0089]],\n",
              "              \n",
              "                       [[ 0.0144,  0.0152,  0.0012],\n",
              "                        [ 0.0049,  0.0069, -0.0032],\n",
              "                        [-0.0140, -0.0098, -0.0022]],\n",
              "              \n",
              "                       [[-0.0314, -0.0182, -0.0190],\n",
              "                        [-0.0076, -0.0219, -0.0004],\n",
              "                        [-0.0167, -0.0275, -0.0157]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0427, -0.0212,  0.0915],\n",
              "                        [ 0.0090,  0.0468,  0.0900],\n",
              "                        [ 0.0746,  0.0457, -0.0522]],\n",
              "              \n",
              "                       [[ 0.0070,  0.0230,  0.0004],\n",
              "                        [ 0.0183,  0.0120, -0.0023],\n",
              "                        [ 0.0308, -0.0011, -0.0267]],\n",
              "              \n",
              "                       [[ 0.0589, -0.0308, -0.0599],\n",
              "                        [-0.0209, -0.0846, -0.0219],\n",
              "                        [ 0.0074,  0.0213,  0.0133]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0024, -0.0261,  0.0069],\n",
              "                        [-0.0463, -0.0270,  0.0177],\n",
              "                        [-0.0402, -0.0451, -0.0279]],\n",
              "              \n",
              "                       [[ 0.0324,  0.0612,  0.0428],\n",
              "                        [ 0.0015,  0.0187, -0.0026],\n",
              "                        [-0.0108, -0.0530, -0.0093]],\n",
              "              \n",
              "                       [[-0.0013, -0.0279, -0.0164],\n",
              "                        [-0.0064,  0.0074,  0.0015],\n",
              "                        [-0.0264, -0.0374, -0.0396]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0016, -0.0230, -0.0048],\n",
              "                        [-0.0069, -0.0330, -0.0141],\n",
              "                        [-0.0156, -0.0131,  0.0173]],\n",
              "              \n",
              "                       [[ 0.0119,  0.0133,  0.0213],\n",
              "                        [ 0.0086, -0.0186,  0.0092],\n",
              "                        [-0.0162, -0.0229,  0.0217]],\n",
              "              \n",
              "                       [[-0.0039,  0.0350, -0.0095],\n",
              "                        [-0.0232,  0.0057,  0.0351],\n",
              "                        [-0.0308, -0.0041,  0.0202]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0301, -0.1007, -0.0392],\n",
              "                        [ 0.0030,  0.0434, -0.0045],\n",
              "                        [-0.0146, -0.0068,  0.0226]],\n",
              "              \n",
              "                       [[-0.0228, -0.0297, -0.0002],\n",
              "                        [ 0.0023, -0.0335, -0.0238],\n",
              "                        [-0.0082, -0.0784, -0.0392]],\n",
              "              \n",
              "                       [[ 0.0249,  0.0151,  0.0177],\n",
              "                        [-0.0162, -0.0065,  0.0021],\n",
              "                        [-0.0133, -0.0126, -0.0068]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0244, -0.0331, -0.0151],\n",
              "                        [-0.0428, -0.0370, -0.0098],\n",
              "                        [-0.0333, -0.0334, -0.0004]],\n",
              "              \n",
              "                       [[-0.0151,  0.0002,  0.0131],\n",
              "                        [-0.0267, -0.0021,  0.0020],\n",
              "                        [ 0.0028,  0.0077,  0.0101]],\n",
              "              \n",
              "                       [[-0.0168, -0.0121,  0.0227],\n",
              "                        [ 0.0081,  0.0104,  0.0255],\n",
              "                        [ 0.0265,  0.0173, -0.0057]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0215, -0.0012,  0.0061],\n",
              "                        [-0.0076,  0.0108,  0.0320],\n",
              "                        [-0.0052, -0.0023,  0.0092]],\n",
              "              \n",
              "                       [[ 0.0054, -0.0130, -0.0090],\n",
              "                        [ 0.0125,  0.0177,  0.0145],\n",
              "                        [ 0.0024,  0.0049,  0.0188]],\n",
              "              \n",
              "                       [[-0.0003,  0.0069, -0.0027],\n",
              "                        [ 0.0039, -0.0067, -0.0099],\n",
              "                        [ 0.0189,  0.0202,  0.0063]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0307,  0.0266, -0.0060],\n",
              "                        [-0.0342, -0.0259, -0.0295],\n",
              "                        [-0.0302,  0.0379,  0.0391]],\n",
              "              \n",
              "                       [[-0.0240, -0.0174,  0.0111],\n",
              "                        [-0.0061, -0.0247,  0.0177],\n",
              "                        [-0.0055,  0.0141,  0.0126]],\n",
              "              \n",
              "                       [[-0.0312,  0.0068, -0.0064],\n",
              "                        [-0.0247, -0.0030,  0.0171],\n",
              "                        [ 0.0075, -0.0239, -0.0312]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0311, -0.0273, -0.0401],\n",
              "                        [ 0.0019, -0.0189,  0.0148],\n",
              "                        [ 0.0167, -0.0545, -0.0509]],\n",
              "              \n",
              "                       [[-0.0091,  0.0212,  0.0215],\n",
              "                        [-0.0195, -0.0265,  0.0038],\n",
              "                        [-0.0478, -0.0258, -0.0198]],\n",
              "              \n",
              "                       [[-0.0501, -0.0240,  0.0163],\n",
              "                        [-0.0343,  0.0041, -0.0307],\n",
              "                        [-0.0220, -0.0230, -0.0462]]]], device='cuda:0')),\n",
              "             ('layer2.1.bn2.weight',\n",
              "              tensor([0.0864, 0.1678, 0.3218, 0.2841, 0.2797, 0.5454, 0.4022, 0.1716, 0.3193,\n",
              "                      0.2019, 0.2420, 0.2082, 0.1847, 0.2685, 0.2456, 0.2319, 0.2520, 0.2267,\n",
              "                      0.2186, 0.3508, 0.2021, 0.4820, 0.2508, 0.4097, 0.3284, 0.3829, 0.2578,\n",
              "                      0.1589, 0.2198, 0.2271, 0.2534, 0.3543, 0.2223, 0.1824, 0.2134, 0.6424,\n",
              "                      0.3652, 0.4301, 0.1733, 0.1380, 0.1747, 0.4081, 0.2776, 0.0834, 0.2005,\n",
              "                      0.1665, 0.2036, 0.1612, 0.4198, 0.3010, 0.1868, 0.4779, 0.4021, 0.1913,\n",
              "                      0.1943, 0.1354, 0.3008, 0.0870, 0.3459, 0.1792, 0.5666, 0.2472, 0.4246,\n",
              "                      0.1874, 0.1810, 0.2357, 0.2167, 0.4031, 0.2897, 0.5909, 0.2057, 0.2755,\n",
              "                      0.4673, 0.4439, 0.1767, 0.3920, 0.5782, 0.2673, 0.1322, 0.3322, 0.2238,\n",
              "                      0.3431, 0.1070, 0.2631, 0.1904, 0.0596, 0.3234, 0.2407, 0.3010, 0.1549,\n",
              "                      0.2803, 0.4223, 0.5128, 0.2094, 0.1882, 0.3193, 0.2476, 0.1196, 0.5961,\n",
              "                      0.1431, 0.2043, 0.1413, 0.1612, 0.2757, 0.1729, 0.3696, 0.3642, 0.1484,\n",
              "                      0.3367, 0.4364, 0.4171, 0.2911, 0.2376, 0.5174, 0.1407, 0.4846, 0.3432,\n",
              "                      0.2462, 0.5598, 0.2291, 0.1291, 0.0795, 0.3323, 0.1440, 0.4783, 0.2702,\n",
              "                      0.1230, 0.4047], device='cuda:0')),\n",
              "             ('layer2.1.bn2.bias',\n",
              "              tensor([-0.1513, -0.0874, -0.4013, -0.2289, -0.0728, -0.3553, -0.3395, -0.0716,\n",
              "                      -0.1951,  0.0440, -0.2955, -0.1945, -0.1451, -0.0719, -0.1381, -0.1088,\n",
              "                      -0.2145, -0.0996, -0.1044, -0.0355, -0.1879, -0.2129, -0.2742, -0.1845,\n",
              "                      -0.3655, -0.1377, -0.1649, -0.0214, -0.1763, -0.2135, -0.1857, -0.0940,\n",
              "                      -0.2441, -0.2184, -0.3388, -0.4526, -0.0309, -0.0488,  0.0401, -0.0524,\n",
              "                      -0.0294, -0.1299, -0.0255,  0.0378, -0.2350, -0.1009, -0.0513, -0.1190,\n",
              "                      -0.0829, -0.2069, -0.1354, -0.3257, -0.3239, -0.2330, -0.0321, -0.1933,\n",
              "                      -0.1828, -0.0508,  0.2829, -0.0698, -0.0729, -0.2890, -0.2563, -0.0065,\n",
              "                      -0.1092, -0.3044,  0.1650, -0.0043, -0.2404, -0.4241, -0.1240, -0.3207,\n",
              "                      -0.2601, -0.5280,  0.1057, -0.2653, -0.4352, -0.0230, -0.0740, -0.2203,\n",
              "                      -0.2039,  0.0001, -0.1081, -0.2272,  0.1052, -0.0565, -0.1018, -0.1777,\n",
              "                      -0.1696, -0.1559, -0.3878, -0.3471, -0.3370,  0.0404, -0.2080, -0.1015,\n",
              "                       0.0214, -0.0276, -0.2327, -0.1316, -0.1772, -0.2243,  0.0951,  0.0000,\n",
              "                      -0.1015, -0.2907,  0.0421, -0.1230, -0.1489, -0.1727, -0.1723, -0.1835,\n",
              "                      -0.2341, -0.3560, -0.1712, -0.3460, -0.1767, -0.2887, -0.2685,  0.0115,\n",
              "                      -0.0301,  0.0058, -0.0990,  0.0388, -0.4847, -0.2925,  0.1406, -0.1256],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.1.bn2.running_mean',\n",
              "              tensor([-0.0048,  0.0178,  0.0454, -0.0892, -0.1375, -0.0078, -0.2054, -0.1049,\n",
              "                      -0.1579,  0.1328, -0.0960, -0.0363, -0.0622, -0.1875,  0.0390,  0.0379,\n",
              "                      -0.0644, -0.0166,  0.0555, -0.0808, -0.0482, -0.0353,  0.1176, -0.1542,\n",
              "                       0.0656, -0.1191, -0.0082, -0.0796,  0.0564,  0.0186, -0.1716, -0.0168,\n",
              "                      -0.0629,  0.0258,  0.0895, -0.2538, -0.2858, -0.2650, -0.0116, -0.0330,\n",
              "                       0.0799, -0.3198,  0.1273, -0.0436, -0.0078, -0.0095, -0.1429,  0.0266,\n",
              "                      -0.4090, -0.0582, -0.0923, -0.1060, -0.0776,  0.0688, -0.0921,  0.0224,\n",
              "                      -0.0738, -0.0876, -0.2380,  0.0795, -0.5847,  0.0726, -0.0646, -0.0007,\n",
              "                       0.0435, -0.1126, -0.0383, -0.2648, -0.1151, -0.0009, -0.0700, -0.0953,\n",
              "                      -0.0738, -0.0767, -0.1017, -0.1169,  0.0442,  0.0568, -0.0204, -0.0024,\n",
              "                       0.2283, -0.2521,  0.0916,  0.0658, -0.0860, -0.0497, -0.0132, -0.0824,\n",
              "                      -0.2631, -0.0026,  0.0941, -0.1668, -0.1998, -0.1046, -0.0467, -0.0633,\n",
              "                      -0.0010,  0.0258, -0.5811,  0.0021,  0.0568, -0.0141, -0.1306, -0.1476,\n",
              "                       0.0027, -0.1798, -0.2228,  0.1754, -0.0168,  0.5970, -0.0401,  0.0130,\n",
              "                       0.0632, -0.0816, -0.0162,  0.1793, -0.0038,  0.0130, -0.2648,  0.0474,\n",
              "                       0.0831,  0.0577, -0.2743, -0.0615, -0.1545, -0.0379, -0.1370, -0.0665],\n",
              "                     device='cuda:0')),\n",
              "             ('layer2.1.bn2.running_var',\n",
              "              tensor([0.0205, 0.0239, 0.0327, 0.0214, 0.0307, 0.0584, 0.0433, 0.0303, 0.0283,\n",
              "                      0.0474, 0.0276, 0.0250, 0.0217, 0.0314, 0.0363, 0.0286, 0.0229, 0.0259,\n",
              "                      0.0335, 0.0383, 0.0182, 0.0511, 0.0273, 0.0478, 0.0348, 0.0571, 0.0355,\n",
              "                      0.0191, 0.0311, 0.0347, 0.0391, 0.0520, 0.0320, 0.0306, 0.0187, 0.0565,\n",
              "                      0.0560, 0.0455, 0.0292, 0.0399, 0.0397, 0.0954, 0.0308, 0.0200, 0.0278,\n",
              "                      0.0233, 0.0208, 0.0172, 0.0584, 0.0397, 0.0191, 0.0450, 0.0348, 0.0241,\n",
              "                      0.0339, 0.0210, 0.0244, 0.0197, 0.0700, 0.0296, 0.0752, 0.0251, 0.0580,\n",
              "                      0.0346, 0.0259, 0.0152, 0.0472, 0.0687, 0.0363, 0.0541, 0.0222, 0.0374,\n",
              "                      0.0613, 0.0358, 0.0358, 0.0359, 0.0495, 0.0367, 0.0185, 0.0420, 0.0199,\n",
              "                      0.0547, 0.0144, 0.0365, 0.0323, 0.0176, 0.0484, 0.0361, 0.0343, 0.0193,\n",
              "                      0.0349, 0.0456, 0.0396, 0.0258, 0.0171, 0.0438, 0.0409, 0.0210, 0.0558,\n",
              "                      0.0429, 0.0360, 0.0244, 0.0332, 0.0333, 0.0256, 0.0507, 0.0638, 0.0257,\n",
              "                      0.0449, 0.0546, 0.0609, 0.0419, 0.0312, 0.0411, 0.0233, 0.0404, 0.0525,\n",
              "                      0.0181, 0.0673, 0.0383, 0.0259, 0.0186, 0.0394, 0.0166, 0.0351, 0.0309,\n",
              "                      0.0323, 0.0504], device='cuda:0')),\n",
              "             ('layer2.1.bn2.num_batches_tracked',\n",
              "              tensor(12041, device='cuda:0')),\n",
              "             ('layer3.0.conv1.weight', tensor([[[[-0.0171, -0.0165, -0.0167],\n",
              "                        [-0.0077,  0.0131,  0.0109],\n",
              "                        [-0.0173,  0.0021, -0.0120]],\n",
              "              \n",
              "                       [[-0.0112, -0.0190, -0.0049],\n",
              "                        [ 0.0117, -0.0125, -0.0037],\n",
              "                        [ 0.0071, -0.0148, -0.0060]],\n",
              "              \n",
              "                       [[-0.0239, -0.0369, -0.0369],\n",
              "                        [-0.0343, -0.0585, -0.0406],\n",
              "                        [-0.0386, -0.0376, -0.0163]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0060,  0.0076,  0.0159],\n",
              "                        [-0.0000,  0.0253,  0.0081],\n",
              "                        [-0.0047,  0.0053,  0.0080]],\n",
              "              \n",
              "                       [[ 0.0162, -0.0105, -0.0019],\n",
              "                        [ 0.0103,  0.0086, -0.0002],\n",
              "                        [-0.0113, -0.0144, -0.0075]],\n",
              "              \n",
              "                       [[ 0.0578,  0.0508,  0.0267],\n",
              "                        [ 0.0330, -0.0011, -0.0044],\n",
              "                        [-0.0143, -0.0030, -0.0147]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0064, -0.0103, -0.0298],\n",
              "                        [ 0.0160, -0.0038, -0.0240],\n",
              "                        [ 0.0156, -0.0066, -0.0072]],\n",
              "              \n",
              "                       [[ 0.0138,  0.0200, -0.0139],\n",
              "                        [ 0.0051,  0.0164,  0.0107],\n",
              "                        [-0.0132, -0.0118,  0.0042]],\n",
              "              \n",
              "                       [[-0.0212,  0.0087,  0.0188],\n",
              "                        [-0.0002,  0.0068,  0.0368],\n",
              "                        [ 0.0091,  0.0066,  0.0265]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0170, -0.0110,  0.0069],\n",
              "                        [-0.0017, -0.0131, -0.0111],\n",
              "                        [ 0.0009, -0.0001,  0.0126]],\n",
              "              \n",
              "                       [[ 0.0048, -0.0216,  0.0024],\n",
              "                        [ 0.0181, -0.0164, -0.0045],\n",
              "                        [-0.0059, -0.0321, -0.0337]],\n",
              "              \n",
              "                       [[ 0.0075,  0.0122,  0.0080],\n",
              "                        [-0.0052,  0.0127,  0.0143],\n",
              "                        [ 0.0231,  0.0345,  0.0296]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0354, -0.0234, -0.0150],\n",
              "                        [-0.0164, -0.0313,  0.0087],\n",
              "                        [-0.0084, -0.0171, -0.0164]],\n",
              "              \n",
              "                       [[-0.0187, -0.0324, -0.0212],\n",
              "                        [-0.0308, -0.0469, -0.0565],\n",
              "                        [ 0.0294, -0.0126, -0.0224]],\n",
              "              \n",
              "                       [[ 0.0199,  0.0212, -0.0052],\n",
              "                        [ 0.0193,  0.0247,  0.0150],\n",
              "                        [ 0.0336,  0.0472,  0.0197]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0085, -0.0137, -0.0149],\n",
              "                        [-0.0125, -0.0308, -0.0065],\n",
              "                        [-0.0048, -0.0205, -0.0297]],\n",
              "              \n",
              "                       [[-0.0077, -0.0095, -0.0123],\n",
              "                        [-0.0286, -0.0028,  0.0282],\n",
              "                        [-0.0103,  0.0015,  0.0136]],\n",
              "              \n",
              "                       [[ 0.0134, -0.0322, -0.0202],\n",
              "                        [-0.0171, -0.0220,  0.0001],\n",
              "                        [ 0.0106,  0.0048, -0.0083]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0025,  0.0235,  0.0090],\n",
              "                        [ 0.0184,  0.0256,  0.0420],\n",
              "                        [ 0.0427,  0.0224,  0.0380]],\n",
              "              \n",
              "                       [[ 0.0076,  0.0101,  0.0126],\n",
              "                        [ 0.0101,  0.0271,  0.0141],\n",
              "                        [ 0.0204,  0.0034, -0.0159]],\n",
              "              \n",
              "                       [[-0.0041,  0.0255,  0.0034],\n",
              "                        [-0.0168,  0.0272,  0.0068],\n",
              "                        [-0.0033,  0.0311,  0.0032]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0097,  0.0008,  0.0198],\n",
              "                        [ 0.0126,  0.0042,  0.0103],\n",
              "                        [ 0.0105,  0.0132,  0.0229]],\n",
              "              \n",
              "                       [[-0.0210,  0.0081, -0.0132],\n",
              "                        [-0.0158,  0.0066, -0.0141],\n",
              "                        [ 0.0048,  0.0423,  0.0324]],\n",
              "              \n",
              "                       [[ 0.0091,  0.0159, -0.0152],\n",
              "                        [ 0.0085, -0.0049, -0.0086],\n",
              "                        [ 0.0030, -0.0088, -0.0406]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0298,  0.0755,  0.0422],\n",
              "                        [ 0.1014,  0.1538,  0.1552],\n",
              "                        [ 0.0662,  0.1397,  0.1123]],\n",
              "              \n",
              "                       [[-0.0272, -0.0060, -0.0209],\n",
              "                        [-0.0170, -0.0010,  0.0099],\n",
              "                        [-0.0169, -0.0028,  0.0034]],\n",
              "              \n",
              "                       [[-0.0156, -0.0327, -0.0158],\n",
              "                        [-0.0003, -0.0103, -0.0058],\n",
              "                        [-0.0196, -0.0122, -0.0225]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0050,  0.0061, -0.0021],\n",
              "                        [ 0.0163, -0.0165,  0.0130],\n",
              "                        [ 0.0219,  0.0112,  0.0065]],\n",
              "              \n",
              "                       [[ 0.0071, -0.0167,  0.0133],\n",
              "                        [-0.0203, -0.0342, -0.0408],\n",
              "                        [-0.0322, -0.0949, -0.0659]],\n",
              "              \n",
              "                       [[-0.0113, -0.0018, -0.0013],\n",
              "                        [ 0.0051,  0.0222,  0.0051],\n",
              "                        [ 0.0072,  0.0051,  0.0105]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0151, -0.0121,  0.0018],\n",
              "                        [-0.0253, -0.0223, -0.0105],\n",
              "                        [ 0.0069, -0.0009,  0.0066]],\n",
              "              \n",
              "                       [[-0.0047, -0.0145, -0.0290],\n",
              "                        [-0.0042,  0.0013, -0.0236],\n",
              "                        [ 0.0099,  0.0006,  0.0035]],\n",
              "              \n",
              "                       [[-0.0510, -0.0439, -0.0573],\n",
              "                        [-0.0378, -0.0363, -0.0456],\n",
              "                        [-0.0429, -0.0358, -0.0144]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0144, -0.0040, -0.0147],\n",
              "                        [-0.0253, -0.0235,  0.0106],\n",
              "                        [-0.0255,  0.0129,  0.0064]],\n",
              "              \n",
              "                       [[-0.0267,  0.0191,  0.0229],\n",
              "                        [-0.0379,  0.0213,  0.0182],\n",
              "                        [-0.0489, -0.0074, -0.0201]],\n",
              "              \n",
              "                       [[ 0.0183,  0.0260,  0.0121],\n",
              "                        [ 0.0246,  0.0238,  0.0040],\n",
              "                        [ 0.0021, -0.0083, -0.0201]]]], device='cuda:0')),\n",
              "             ('layer3.0.bn1.weight',\n",
              "              tensor([0.2718, 0.2844, 0.3078, 0.3058, 0.2792, 0.3732, 0.3121, 0.2833, 0.3846,\n",
              "                      0.3005, 0.2175, 0.3144, 0.2972, 0.3320, 0.2783, 0.3566, 0.2755, 0.3372,\n",
              "                      0.3107, 0.3100, 0.3147, 0.2936, 0.2687, 0.2961, 0.3588, 0.3744, 0.3488,\n",
              "                      0.3172, 0.2767, 0.2891, 0.3348, 0.3253, 0.3237, 0.2587, 0.3718, 0.3792,\n",
              "                      0.2674, 0.3642, 0.3125, 0.3316, 0.3507, 0.3343, 0.3180, 0.3190, 0.3233,\n",
              "                      0.3354, 0.3273, 0.3062, 0.3322, 0.2998, 0.3230, 0.3283, 0.2938, 0.2723,\n",
              "                      0.2994, 0.3471, 0.2774, 0.2696, 0.3367, 0.3435, 0.2986, 0.3522, 0.3082,\n",
              "                      0.3153, 0.3855, 0.2826, 0.2596, 0.3680, 0.2251, 0.3022, 0.2576, 0.3306,\n",
              "                      0.3028, 0.3812, 0.3578, 0.2462, 0.2821, 0.3592, 0.2797, 0.3259, 0.3615,\n",
              "                      0.4021, 0.3645, 0.3483, 0.2643, 0.3375, 0.3078, 0.2456, 0.2719, 0.3393,\n",
              "                      0.3898, 0.3388, 0.3361, 0.3592, 0.3167, 0.3653, 0.3108, 0.2325, 0.1961,\n",
              "                      0.3284, 0.3137, 0.3056, 0.3148, 0.3077, 0.3045, 0.3157, 0.2111, 0.3076,\n",
              "                      0.3214, 0.3378, 0.3459, 0.2808, 0.3767, 0.3442, 0.2958, 0.2238, 0.5128,\n",
              "                      0.3074, 0.3526, 0.3272, 0.3218, 0.2500, 0.3353, 0.3355, 0.2949, 0.2683,\n",
              "                      0.2484, 0.3290, 0.3380, 0.3220, 0.2715, 0.3327, 0.4005, 0.2910, 0.2747,\n",
              "                      0.2842, 0.3148, 0.2955, 0.2799, 0.4419, 0.2702, 0.3707, 0.2690, 0.3220,\n",
              "                      0.2752, 0.2857, 0.2877, 0.3598, 0.4241, 0.3215, 0.2372, 0.2646, 0.3254,\n",
              "                      0.3460, 0.2441, 0.3366, 0.3249, 0.3471, 0.2267, 0.3195, 0.3165, 0.3258,\n",
              "                      0.2721, 0.2742, 0.2624, 0.3026, 0.3148, 0.3219, 0.3487, 0.3132, 0.2177,\n",
              "                      0.3112, 0.3268, 0.3347, 0.3278, 0.3078, 0.2636, 0.3668, 0.3031, 0.2763,\n",
              "                      0.2178, 0.2924, 0.3583, 0.3128, 0.3343, 0.3266, 0.3035, 0.3569, 0.3067,\n",
              "                      0.2912, 0.3191, 0.2634, 0.3527, 0.3641, 0.2872, 0.2256, 0.3240, 0.2760,\n",
              "                      0.3540, 0.3130, 0.2767, 0.2469, 0.4565, 0.3367, 0.2813, 0.2474, 0.3594,\n",
              "                      0.3424, 0.2470, 0.2532, 0.3698, 0.3395, 0.2122, 0.3001, 0.3235, 0.3498,\n",
              "                      0.3031, 0.3615, 0.2489, 0.2765, 0.2905, 0.3291, 0.3174, 0.3614, 0.3627,\n",
              "                      0.3935, 0.2964, 0.3535, 0.2570, 0.3327, 0.2697, 0.2948, 0.2747, 0.2920,\n",
              "                      0.3177, 0.2559, 0.3175, 0.2664, 0.2535, 0.2812, 0.2890, 0.3087, 0.3646,\n",
              "                      0.3458, 0.3154, 0.3379, 0.3959, 0.3348, 0.3785, 0.3472, 0.3000, 0.3861,\n",
              "                      0.3128, 0.2930, 0.2405, 0.3292], device='cuda:0')),\n",
              "             ('layer3.0.bn1.bias',\n",
              "              tensor([-0.1116,  0.0330, -0.1190, -0.0490, -0.1010, -0.1286, -0.1462, -0.1206,\n",
              "                      -0.2334, -0.1382,  0.1404, -0.1651,  0.0700, -0.0758,  0.0145, -0.1832,\n",
              "                      -0.1275, -0.1775, -0.0829, -0.1100, -0.3568, -0.1935, -0.0939, -0.1429,\n",
              "                      -0.2120, -0.1399, -0.2144, -0.2427, -0.0998, -0.0857, -0.0784, -0.0886,\n",
              "                      -0.0477,  0.0700, -0.0189, -0.1965,  0.0178, -0.1437, -0.0246, -0.1986,\n",
              "                      -0.2385, -0.1534, -0.2020, -0.1225, -0.2969, -0.1127, -0.0418, -0.1239,\n",
              "                      -0.0709,  0.0045, -0.1621, -0.1489, -0.1785, -0.0011, -0.1044, -0.1771,\n",
              "                      -0.1327, -0.0631, -0.3317, -0.1618, -0.0254, -0.2322, -0.0950, -0.1051,\n",
              "                      -0.2730, -0.2125, -0.0586, -0.0873,  0.1747, -0.2385, -0.1115, -0.1386,\n",
              "                      -0.1436, -0.3093, -0.2070,  0.0402, -0.0882, -0.0972, -0.0680, -0.1619,\n",
              "                      -0.4088,  0.0360, -0.1655, -0.0835, -0.0644, -0.2248, -0.0824, -0.0972,\n",
              "                      -0.0801, -0.1467, -0.2057, -0.1929, -0.0892, -0.2554, -0.0511, -0.0587,\n",
              "                      -0.0517, -0.0429,  0.0983, -0.1031, -0.1681, -0.3211, -0.0810, -0.1126,\n",
              "                      -0.1856, -0.0547,  0.0873, -0.0434, -0.1279, -0.0451, -0.1796,  0.0387,\n",
              "                      -0.1266, -0.2431, -0.0798, -0.0976, -0.1659, -0.0803, -0.1935, -0.1004,\n",
              "                      -0.1376, -0.1025, -0.1045, -0.1919, -0.1342, -0.0698, -0.0593, -0.1633,\n",
              "                      -0.1402, -0.1685, -0.0882, -0.2534, -0.0741, -0.1538, -0.0869, -0.0661,\n",
              "                      -0.1789,  0.0477, -0.0173, -0.2930, -0.1520, -0.0781, -0.0573, -0.0449,\n",
              "                      -0.1498, -0.1078,  0.0212, -0.1410, -0.1799, -0.0955,  0.1705, -0.1151,\n",
              "                      -0.2459, -0.1015,  0.0683, -0.1890, -0.0063, -0.1202,  0.1304, -0.1999,\n",
              "                      -0.1246,  0.0265,  0.0990, -0.0558, -0.0735, -0.1478, -0.1607, -0.0580,\n",
              "                      -0.1825, -0.1899,  0.0212, -0.1238, -0.1475, -0.2119, -0.0635, -0.1351,\n",
              "                      -0.0840, -0.1747, -0.1318, -0.1084, -0.0981, -0.1933, -0.2532, -0.0553,\n",
              "                      -0.1354, -0.1420, -0.0955, -0.2293, -0.2281, -0.2995, -0.1332, -0.0936,\n",
              "                      -0.1454, -0.2495, -0.1356,  0.0513, -0.1045,  0.0320, -0.1881, -0.0653,\n",
              "                      -0.1135,  0.0049, -0.3526, -0.1171, -0.1026,  0.0158, -0.2704, -0.1155,\n",
              "                       0.0371, -0.1000, -0.2479, -0.1706,  0.1139, -0.0403, -0.1036, -0.4519,\n",
              "                      -0.0634, -0.3289, -0.0338, -0.0782, -0.0583, -0.0259, -0.0528, -0.1254,\n",
              "                      -0.1610, -0.1551, -0.1953, -0.1719, -0.0672, -0.1265, -0.0388, -0.0794,\n",
              "                      -0.0317, -0.0922, -0.1211, -0.0188, -0.0968, -0.0318,  0.0383, -0.0897,\n",
              "                      -0.1575, -0.0808, -0.2018, -0.0700, -0.1163, -0.1996, -0.2135, -0.2160,\n",
              "                      -0.2184, -0.1700, -0.1481, -0.1759, -0.0822, -0.0906, -0.1139, -0.0433],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.0.bn1.running_mean',\n",
              "              tensor([-0.1184, -0.1637, -0.5095, -0.0385, -0.7001,  0.0977,  0.0201,  0.0747,\n",
              "                      -0.0565, -0.1304, -0.2633, -0.6212, -1.4568, -0.4501, -1.6562, -0.4703,\n",
              "                       0.3212, -0.8155,  0.4179, -0.2770, -0.5088, -0.7223, -0.0510, -0.1894,\n",
              "                      -0.6615, -0.8620, -0.5570,  0.3406, -0.1369,  0.0557, -0.7312, -0.4454,\n",
              "                       0.6370, -0.1531, -0.0277, -0.8191, -0.6086,  0.0547, -0.6784, -0.3904,\n",
              "                      -0.2165, -0.4620, -0.3388, -0.3451, -0.1775, -0.6362, -0.2331, -0.6902,\n",
              "                      -0.5455, -0.5228, -0.2765, -0.7955,  0.2999, -0.6363, -0.3696, -0.1589,\n",
              "                      -0.0763, -0.4198,  0.2023,  0.1371, -0.8566, -0.6746, -0.1429, -0.1868,\n",
              "                      -0.8617,  0.4677, -0.4359, -0.1887,  0.3470, -0.3187, -0.5967, -0.4552,\n",
              "                      -0.4368, -0.6958, -0.4268,  0.4590, -0.4162,  0.0169, -0.0043, -0.6543,\n",
              "                       0.3024, -0.4238, -0.6358, -0.2973, -0.0834, -0.6086, -0.3938,  0.2609,\n",
              "                      -0.7800,  0.0862, -0.4018, -0.6868,  0.1627, -0.5879, -0.1208, -0.8760,\n",
              "                      -0.1276,  0.0267, -1.1050, -0.1459, -0.5566, -0.5711,  0.3813, -0.0762,\n",
              "                       0.1858, -0.8993, -0.0014, -0.7847, -0.4021, -0.1012, -0.5593, -0.1872,\n",
              "                      -0.3114, -0.9813,  0.1788,  0.4081, -0.5098, -0.4445,  0.2340, -0.1552,\n",
              "                      -0.5528, -0.6532, -0.0343, -0.1186, -0.4349, -0.6802,  0.0111,  0.7199,\n",
              "                      -0.3372, -0.2774, -0.1733, -0.6206,  0.0551, -0.3834, -0.7799, -0.4138,\n",
              "                      -0.8948, -0.0735,  0.1684, -0.2300, -0.1497, -0.6030, -0.0587, -0.8501,\n",
              "                      -0.2119, -0.4130, -0.2022, -0.4420, -0.1343, -0.1797, -0.3812,  0.5637,\n",
              "                       0.1640, -0.3302, -0.1149, -0.6206, -0.1384, -0.1057,  0.0247, -0.6667,\n",
              "                       0.0829, -0.3565, -0.5102, -0.1366, -1.4127, -0.3897, -0.2006, -0.5493,\n",
              "                      -0.4507, -0.6703,  0.2263, -0.6633, -0.6810,  0.1436, -0.7561, -0.2771,\n",
              "                      -0.2693, -0.2407, -0.1441, -0.3676, -0.4252, -0.9398, -0.8353, -0.3444,\n",
              "                      -0.4629, -0.1613, -0.2466, -0.0851, -0.4274, -0.5862, -0.2988, -0.3558,\n",
              "                      -0.1431, -0.5144, -0.6016, -0.0046, -0.5151, -0.5657, -0.1366, -0.0497,\n",
              "                      -0.4351, -0.1973, -0.2103, -0.2837, -0.4303,  0.0640, -0.3198, -0.4897,\n",
              "                      -0.0080,  0.1753, -0.0720, -0.3702, -0.5570, -0.4338, -0.4552, -0.6717,\n",
              "                      -0.2060,  0.0309,  0.0184, -0.0757, -0.9551, -0.8434, -0.3319, -0.1669,\n",
              "                      -0.4771, -0.2843, -0.5258, -0.5155,  0.2488, -1.0118, -0.5566, -0.1536,\n",
              "                      -0.2860, -0.1120, -0.0549,  0.0911, -0.1095, -0.2621, -0.0998, -0.2909,\n",
              "                      -0.4701, -0.0790, -0.8342, -0.3487,  0.0791, -0.4768, -0.6897, -0.3190,\n",
              "                      -0.3993, -0.3324, -0.1053, -0.2818, -0.7926, -0.2728, -0.2675, -0.8764],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.0.bn1.running_var',\n",
              "              tensor([0.2636, 0.3915, 0.3557, 0.2254, 0.2530, 0.3979, 0.1875, 0.2425, 0.2963,\n",
              "                      0.2798, 0.3383, 0.2253, 0.3935, 0.3122, 0.5621, 0.1944, 0.2116, 0.2415,\n",
              "                      0.2842, 0.2489, 0.2084, 0.2337, 0.2401, 0.1911, 0.2391, 0.4303, 0.2379,\n",
              "                      0.1649, 0.1532, 0.2122, 0.2704, 0.2689, 0.3428, 0.3019, 0.9059, 0.3082,\n",
              "                      0.2458, 0.2762, 0.3825, 0.2892, 0.2215, 0.2747, 0.2056, 0.1976, 0.2142,\n",
              "                      0.2440, 0.2175, 0.2493, 0.2648, 0.2638, 0.1860, 0.2639, 0.1403, 0.5554,\n",
              "                      0.1942, 0.3649, 0.2071, 0.2940, 0.1772, 0.2473, 0.2644, 0.2121, 0.2811,\n",
              "                      0.3014, 0.2810, 0.1694, 0.1943, 0.3108, 0.3202, 0.1588, 0.2370, 0.2294,\n",
              "                      0.1825, 0.2600, 0.1767, 0.2639, 0.2195, 0.2566, 0.2099, 0.3348, 0.1752,\n",
              "                      1.0849, 0.2546, 0.2365, 0.3009, 0.2146, 0.2505, 0.2124, 0.3756, 0.2806,\n",
              "                      0.2935, 0.2667, 0.2482, 0.2162, 0.2576, 0.4121, 0.2685, 0.2148, 0.5037,\n",
              "                      0.2528, 0.2003, 0.1543, 0.2441, 0.3142, 0.2127, 0.3189, 0.2393, 0.2966,\n",
              "                      0.3052, 0.2745, 0.2690, 0.3554, 0.3266, 0.1792, 0.2220, 0.2559, 0.3593,\n",
              "                      0.2254, 0.2732, 0.2001, 0.2889, 0.1951, 0.4298, 0.2429, 0.1816, 0.3117,\n",
              "                      0.1684, 0.3424, 0.2619, 0.2084, 0.1925, 0.2199, 0.4706, 0.1828, 0.2667,\n",
              "                      0.2338, 0.1596, 0.3682, 0.2826, 0.3909, 0.1385, 0.6994, 0.2402, 0.2897,\n",
              "                      0.3148, 0.1940, 0.3960, 0.2696, 0.3303, 0.3305, 0.3723, 0.2283, 0.1930,\n",
              "                      0.2566, 0.5541, 0.1995, 0.4871, 0.2569, 0.4341, 0.2665, 0.2571, 0.3761,\n",
              "                      0.4498, 0.2363, 0.2478, 0.1933, 0.2743, 0.2027, 0.2429, 0.1976, 0.4877,\n",
              "                      0.3384, 0.2964, 0.1758, 0.2597, 0.2142, 0.1857, 0.3985, 0.1897, 0.2445,\n",
              "                      0.2718, 0.1655, 0.2127, 0.2289, 0.3441, 0.3182, 0.2943, 0.1768, 0.1579,\n",
              "                      0.1273, 0.1982, 0.2176, 0.2050, 0.2302, 0.1886, 0.2547, 0.2434, 0.2659,\n",
              "                      0.2908, 0.2808, 0.2752, 0.3443, 0.5486, 0.2630, 0.2310, 0.4347, 0.2130,\n",
              "                      0.2515, 0.2735, 0.1649, 0.2969, 0.4132, 0.2685, 0.3508, 0.2502, 0.1391,\n",
              "                      0.3243, 0.2337, 0.2065, 0.2545, 0.3215, 0.2716, 0.2116, 0.3087, 0.2771,\n",
              "                      0.4892, 0.2059, 0.2972, 0.2535, 0.3082, 0.4651, 0.2515, 0.3554, 0.2505,\n",
              "                      0.2404, 0.1550, 0.3905, 0.2990, 0.2533, 0.1691, 0.2089, 0.2400, 0.2225,\n",
              "                      0.2360, 0.2734, 0.1769, 0.3017, 0.1693, 0.1971, 0.1850, 0.2421, 0.2370,\n",
              "                      0.2448, 0.3424, 0.2558, 0.3422], device='cuda:0')),\n",
              "             ('layer3.0.bn1.num_batches_tracked',\n",
              "              tensor(12040, device='cuda:0')),\n",
              "             ('layer3.0.conv2.weight', tensor([[[[-0.0081, -0.0345, -0.0116],\n",
              "                        [-0.0216, -0.0778, -0.0473],\n",
              "                        [-0.0414, -0.0782, -0.0632]],\n",
              "              \n",
              "                       [[-0.0349, -0.0037, -0.0287],\n",
              "                        [ 0.0023,  0.0013, -0.0239],\n",
              "                        [-0.0159, -0.0061, -0.0233]],\n",
              "              \n",
              "                       [[-0.0165,  0.0222,  0.0028],\n",
              "                        [ 0.0136,  0.0085, -0.0050],\n",
              "                        [-0.0216, -0.0147, -0.0160]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0006, -0.0047, -0.0008],\n",
              "                        [-0.0248, -0.0240, -0.0315],\n",
              "                        [ 0.0110,  0.0017, -0.0137]],\n",
              "              \n",
              "                       [[ 0.0094,  0.0162,  0.0351],\n",
              "                        [ 0.0029,  0.0066,  0.0121],\n",
              "                        [ 0.0077,  0.0168,  0.0297]],\n",
              "              \n",
              "                       [[ 0.0071,  0.0149,  0.0100],\n",
              "                        [ 0.0316,  0.0457,  0.0558],\n",
              "                        [ 0.0181,  0.0622,  0.0577]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0169,  0.0225,  0.0113],\n",
              "                        [ 0.0332,  0.0250,  0.0247],\n",
              "                        [ 0.0062,  0.0131,  0.0128]],\n",
              "              \n",
              "                       [[-0.0204, -0.0240, -0.0081],\n",
              "                        [-0.0321, -0.0543, -0.0441],\n",
              "                        [-0.0050, -0.0386, -0.0442]],\n",
              "              \n",
              "                       [[-0.0015,  0.0419,  0.0028],\n",
              "                        [ 0.0122,  0.0340,  0.0164],\n",
              "                        [-0.0087, -0.0053, -0.0179]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0470,  0.0079,  0.0156],\n",
              "                        [-0.0045, -0.0360, -0.0058],\n",
              "                        [-0.0224, -0.0603, -0.0279]],\n",
              "              \n",
              "                       [[ 0.0007, -0.0362, -0.0154],\n",
              "                        [-0.0179, -0.0241, -0.0527],\n",
              "                        [-0.0176, -0.0504, -0.0459]],\n",
              "              \n",
              "                       [[ 0.0055,  0.0027,  0.0087],\n",
              "                        [ 0.0003, -0.0035, -0.0084],\n",
              "                        [-0.0164, -0.0080, -0.0124]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0088, -0.0090, -0.0095],\n",
              "                        [-0.0080, -0.0120, -0.0181],\n",
              "                        [-0.0136, -0.0209, -0.0278]],\n",
              "              \n",
              "                       [[ 0.0393,  0.0148,  0.0186],\n",
              "                        [ 0.0156, -0.0271, -0.0142],\n",
              "                        [ 0.0030, -0.0215, -0.0187]],\n",
              "              \n",
              "                       [[ 0.0082,  0.0232,  0.0194],\n",
              "                        [ 0.0026, -0.0095,  0.0097],\n",
              "                        [ 0.0081, -0.0290, -0.0115]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0140, -0.0058, -0.0135],\n",
              "                        [-0.0036,  0.0387,  0.0353],\n",
              "                        [ 0.0040,  0.0447,  0.0400]],\n",
              "              \n",
              "                       [[ 0.0099,  0.0048,  0.0195],\n",
              "                        [ 0.0036,  0.0248,  0.0143],\n",
              "                        [ 0.0007, -0.0054,  0.0030]],\n",
              "              \n",
              "                       [[-0.0145, -0.0161, -0.0220],\n",
              "                        [-0.0197, -0.0194, -0.0186],\n",
              "                        [-0.0285, -0.0143, -0.0215]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0056,  0.0059,  0.0256],\n",
              "                        [-0.0125, -0.0505, -0.0219],\n",
              "                        [-0.0180, -0.0151, -0.0173]],\n",
              "              \n",
              "                       [[ 0.0137,  0.0336,  0.0240],\n",
              "                        [-0.0027, -0.0194,  0.0021],\n",
              "                        [ 0.0053, -0.0192, -0.0001]],\n",
              "              \n",
              "                       [[-0.0144,  0.0097, -0.0145],\n",
              "                        [ 0.0040,  0.0247,  0.0376],\n",
              "                        [-0.0023, -0.0011,  0.0182]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0011,  0.0274,  0.0135],\n",
              "                        [-0.0147, -0.0074, -0.0073],\n",
              "                        [ 0.0036, -0.0054, -0.0099]],\n",
              "              \n",
              "                       [[-0.0090,  0.0049,  0.0044],\n",
              "                        [ 0.0054,  0.0543, -0.0022],\n",
              "                        [-0.0084, -0.0297, -0.0180]],\n",
              "              \n",
              "                       [[-0.0049,  0.0071,  0.0012],\n",
              "                        [ 0.0020, -0.0214, -0.0144],\n",
              "                        [-0.0013,  0.0104,  0.0193]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0185,  0.0178,  0.0100],\n",
              "                        [-0.0106, -0.0147, -0.0169],\n",
              "                        [-0.0073, -0.0205, -0.0186]],\n",
              "              \n",
              "                       [[-0.0066,  0.0507,  0.0112],\n",
              "                        [-0.0006,  0.0192,  0.0128],\n",
              "                        [-0.0241, -0.0243, -0.0265]],\n",
              "              \n",
              "                       [[ 0.0069,  0.0250, -0.0025],\n",
              "                        [ 0.0028,  0.0232, -0.0138],\n",
              "                        [-0.0036, -0.0200, -0.0158]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0207,  0.0310,  0.0319],\n",
              "                        [-0.0030,  0.0016,  0.0167],\n",
              "                        [-0.0184, -0.0363, -0.0185]],\n",
              "              \n",
              "                       [[ 0.0135,  0.0503,  0.0467],\n",
              "                        [ 0.0037,  0.0198,  0.0343],\n",
              "                        [-0.0059, -0.0172, -0.0134]],\n",
              "              \n",
              "                       [[-0.0133, -0.0334, -0.0342],\n",
              "                        [ 0.0034, -0.0135,  0.0008],\n",
              "                        [ 0.0385,  0.0206,  0.0365]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0145, -0.0042,  0.0081],\n",
              "                        [-0.0098, -0.0035, -0.0097],\n",
              "                        [ 0.0218, -0.0015, -0.0053]],\n",
              "              \n",
              "                       [[-0.0207, -0.0047, -0.0126],\n",
              "                        [ 0.0120,  0.0530,  0.0133],\n",
              "                        [-0.0133,  0.0168,  0.0115]],\n",
              "              \n",
              "                       [[ 0.0215,  0.0318,  0.0162],\n",
              "                        [-0.0061, -0.0199,  0.0184],\n",
              "                        [ 0.0056, -0.0005,  0.0151]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0048, -0.0055,  0.0025],\n",
              "                        [-0.0049, -0.0116,  0.0139],\n",
              "                        [-0.0117, -0.0008,  0.0162]],\n",
              "              \n",
              "                       [[-0.0038, -0.0323,  0.0061],\n",
              "                        [ 0.0112,  0.0324,  0.0038],\n",
              "                        [ 0.0121,  0.0612,  0.0295]],\n",
              "              \n",
              "                       [[-0.0144, -0.0230,  0.0003],\n",
              "                        [-0.0343, -0.0326, -0.0182],\n",
              "                        [-0.0147, -0.0137, -0.0262]]]], device='cuda:0')),\n",
              "             ('layer3.0.bn2.weight',\n",
              "              tensor([0.3134, 0.2000, 0.2523, 0.3814, 0.2840, 0.2774, 0.3004, 0.2929, 0.3186,\n",
              "                      0.2674, 0.2586, 0.2403, 0.3068, 0.4297, 0.2963, 0.3018, 0.2844, 0.4006,\n",
              "                      0.3745, 0.3014, 0.2796, 0.3216, 0.2602, 0.4163, 0.3218, 0.3152, 0.3028,\n",
              "                      0.5619, 0.4142, 0.3691, 0.3054, 0.2648, 0.2818, 0.1953, 0.2949, 0.2864,\n",
              "                      0.3890, 0.3809, 0.2059, 0.3817, 0.2676, 0.2827, 0.2362, 0.2645, 0.2947,\n",
              "                      0.2059, 0.2574, 0.2851, 0.3260, 0.4068, 0.2338, 0.3791, 0.2971, 0.3462,\n",
              "                      0.3030, 0.2729, 0.3299, 0.2300, 0.3186, 0.3178, 0.2887, 0.2419, 0.3307,\n",
              "                      0.3316, 0.4041, 0.3156, 0.4845, 0.3046, 0.3400, 0.4436, 0.2702, 0.2282,\n",
              "                      0.2691, 0.3289, 0.3478, 0.3036, 0.3181, 0.3358, 0.3139, 0.2896, 0.2975,\n",
              "                      0.2352, 0.3602, 0.2954, 0.3069, 0.2320, 0.4358, 0.3207, 0.3729, 0.2747,\n",
              "                      0.3094, 0.3199, 0.4072, 0.2339, 0.2701, 0.2625, 0.3523, 0.3072, 0.2475,\n",
              "                      0.3624, 0.5101, 0.3459, 0.2550, 0.2411, 0.2451, 0.3505, 0.2869, 0.4079,\n",
              "                      0.4820, 0.1920, 0.2703, 0.2449, 0.4231, 0.4026, 0.4163, 0.2076, 0.3529,\n",
              "                      0.7477, 0.4313, 0.2726, 0.3558, 0.3011, 0.3728, 0.2790, 0.3866, 0.2548,\n",
              "                      0.3143, 0.3934, 0.4270, 0.2968, 0.2329, 0.3618, 0.2098, 0.2943, 0.2988,\n",
              "                      0.3982, 0.3111, 0.6725, 0.3162, 0.3025, 0.3011, 0.4692, 0.2127, 0.3018,\n",
              "                      0.2854, 0.4141, 0.3073, 0.3194, 0.3408, 0.4847, 0.3949, 0.2472, 0.3258,\n",
              "                      0.4704, 0.3210, 0.3663, 0.2911, 0.2577, 0.2469, 0.2908, 0.4025, 0.2565,\n",
              "                      0.3044, 0.2113, 0.3037, 0.3385, 0.4076, 0.3884, 0.3411, 0.2813, 0.4339,\n",
              "                      0.2762, 0.2685, 0.4208, 0.3420, 0.3517, 0.3353, 0.4447, 0.4302, 0.3692,\n",
              "                      0.3406, 0.3453, 0.3010, 0.4277, 0.2994, 0.2775, 0.2718, 0.3961, 0.2160,\n",
              "                      0.3713, 0.2291, 0.2075, 0.2927, 0.3613, 0.2614, 0.3515, 0.3211, 0.2551,\n",
              "                      0.4269, 0.4728, 0.3414, 0.3662, 0.2674, 0.3388, 0.4525, 0.4056, 0.2040,\n",
              "                      0.3758, 0.2516, 0.2382, 0.2430, 0.3326, 0.2050, 0.3772, 0.4650, 0.3703,\n",
              "                      0.2778, 0.1850, 0.3166, 0.3785, 0.3048, 0.2903, 0.2407, 0.3987, 0.3798,\n",
              "                      0.4511, 0.3496, 0.3654, 0.2688, 0.3806, 0.2525, 0.2727, 0.2865, 0.3157,\n",
              "                      0.2990, 0.2426, 0.2857, 0.3142, 0.2268, 0.2543, 0.2511, 0.3737, 0.3578,\n",
              "                      0.2356, 0.1869, 0.3360, 0.4251, 0.3530, 0.4299, 0.2441, 0.3453, 0.3120,\n",
              "                      0.4167, 0.3585, 0.2912, 0.3448], device='cuda:0')),\n",
              "             ('layer3.0.bn2.bias',\n",
              "              tensor([-0.0234,  0.0973, -0.0019, -0.0563,  0.0083,  0.0784, -0.0380, -0.0057,\n",
              "                      -0.0001,  0.0773,  0.0911,  0.0633, -0.0455,  0.0202,  0.0100, -0.0336,\n",
              "                      -0.0434, -0.2182, -0.0719,  0.0674, -0.0403, -0.0749,  0.1540, -0.1118,\n",
              "                      -0.0402, -0.0506, -0.1230, -0.1681, -0.0079, -0.1166,  0.0143, -0.0320,\n",
              "                      -0.0362,  0.1414,  0.0135, -0.0076, -0.0444,  0.0888,  0.0818, -0.0334,\n",
              "                      -0.0648,  0.0072,  0.1053,  0.0232, -0.0351,  0.0918,  0.0296, -0.0587,\n",
              "                      -0.0056, -0.1039,  0.0164, -0.1014, -0.0163, -0.0145, -0.0374,  0.0023,\n",
              "                      -0.1371,  0.0399,  0.0202, -0.0238, -0.0284,  0.0822, -0.0644, -0.0112,\n",
              "                      -0.0246, -0.0145, -0.1366,  0.1159,  0.0916, -0.2172,  0.0753,  0.0638,\n",
              "                       0.0544,  0.0097, -0.1549, -0.0365, -0.0856, -0.0691, -0.0293,  0.0089,\n",
              "                      -0.0552,  0.0259, -0.0541, -0.0473,  0.0020,  0.0197, -0.2610,  0.0305,\n",
              "                      -0.0977,  0.0459,  0.0633, -0.0499, -0.1500,  0.0986,  0.0652,  0.0706,\n",
              "                      -0.0437, -0.0058,  0.0969, -0.0082, -0.2347, -0.0632,  0.0360,  0.1357,\n",
              "                       0.1008, -0.0351,  0.0825, -0.1429, -0.1421,  0.1343,  0.0669,  0.0703,\n",
              "                      -0.0328, -0.0632, -0.1865,  0.0938, -0.0505, -0.2970, -0.0412, -0.0828,\n",
              "                      -0.2778,  0.0335, -0.1373,  0.0102, -0.0597,  0.0383, -0.0283, -0.1317,\n",
              "                      -0.2202,  0.1065,  0.0540, -0.0718,  0.1013, -0.0356, -0.0607, -0.0311,\n",
              "                       0.0470, -0.3853,  0.0238,  0.0156, -0.0505, -0.3016,  0.0921,  0.0310,\n",
              "                       0.0785, -0.0839, -0.0870, -0.0215,  0.0431, -0.2706, -0.1605,  0.0717,\n",
              "                       0.0312, -0.0979, -0.0343, -0.0806,  0.0268,  0.0202,  0.0930,  0.0517,\n",
              "                      -0.0224,  0.0127, -0.1078, -0.0132,  0.0114, -0.0469, -0.1549, -0.0899,\n",
              "                      -0.0318,  0.0549, -0.3095,  0.0343,  0.0096, -0.2722, -0.0619, -0.1014,\n",
              "                      -0.0046, -0.0617, -0.0749, -0.0533, -0.1523, -0.0586, -0.0701, -0.0442,\n",
              "                      -0.0205, -0.0208,  0.0235, -0.0770, -0.0635, -0.1484,  0.0306,  0.1013,\n",
              "                      -0.0189, -0.0290,  0.0306, -0.0396, -0.0445,  0.1058, -0.1730, -0.1731,\n",
              "                      -0.0587, -0.1132,  0.0115, -0.0414, -0.1751, -0.1061,  0.0464, -0.0728,\n",
              "                       0.0580,  0.0093,  0.1028, -0.0694,  0.1260, -0.0182, -0.1995,  0.0453,\n",
              "                       0.0737,  0.1188, -0.0259,  0.0200, -0.0308,  0.0882,  0.0075,  0.0037,\n",
              "                       0.0047, -0.2011, -0.1555, -0.0077,  0.0077, -0.0563,  0.0574, -0.0755,\n",
              "                       0.0059, -0.0356,  0.0676,  0.0614,  0.0177,  0.0419,  0.0853,  0.0089,\n",
              "                       0.0665, -0.2065, -0.0592,  0.0419,  0.0876,  0.1144, -0.1557, -0.0885,\n",
              "                      -0.1667, -0.0052, -0.0539,  0.0425, -0.0740, -0.0186,  0.0413, -0.0967],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.0.bn2.running_mean',\n",
              "              tensor([-0.1420, -0.5068, -0.0575, -0.0489, -0.3493, -0.0711, -0.1484, -0.2010,\n",
              "                      -0.0328, -0.3028,  0.1343, -0.2259, -0.1025, -0.3570, -0.1075, -0.0299,\n",
              "                      -0.3718, -0.0561, -0.1117, -0.1810, -0.2023, -0.3476, -0.1656, -0.1417,\n",
              "                      -0.1770,  0.0003, -0.1224, -0.2839, -0.6220, -0.1750, -0.1872, -0.2631,\n",
              "                      -0.1761, -0.4221,  0.0531,  0.0050,  0.0575, -0.2801,  0.0062, -0.1295,\n",
              "                       0.1134, -0.1131, -0.1191, -0.2729, -0.1026,  0.0432,  0.1500, -0.1855,\n",
              "                      -0.1963, -0.0709, -0.1749, -0.2105,  0.0580, -0.3278, -0.2348, -0.5835,\n",
              "                      -0.1992,  0.0204, -0.2623, -0.1839,  0.2768, -0.0835, -0.1876, -0.3851,\n",
              "                      -0.3449,  0.1236, -0.3264, -0.0787, -0.0434, -0.3317,  0.0730, -0.2751,\n",
              "                       0.0570, -0.5301, -0.1203, -0.2154, -0.3809, -0.1614,  0.0223, -0.0760,\n",
              "                       0.1717,  0.1627,  0.1721, -0.1222,  0.0311, -0.1852, -0.4274, -0.1700,\n",
              "                      -0.1276,  0.1764, -0.2326, -0.1592, -0.1398, -0.1550, -0.1245, -0.2564,\n",
              "                      -0.2871, -0.0445, -0.2388, -0.1261, -0.3148, -0.1712,  0.0054, -0.0121,\n",
              "                      -0.1299,  0.0009, -0.4018, -0.3603, -0.2752, -0.1577, -0.2227,  0.1160,\n",
              "                      -0.5753, -0.2334, -0.2413, -0.0163, -0.3497, -0.1080, -0.2049,  0.0106,\n",
              "                      -0.0411, -0.2781, -0.3408, -0.1560, -0.0324, -0.2196, -0.0310, -0.2442,\n",
              "                      -0.2314, -0.2068,  0.0476,  0.2319, -0.0138,  0.0339,  0.1608, -0.1797,\n",
              "                       0.0337, -0.1815, -0.2274,  0.1389, -0.0729, -0.3736, -0.1243,  0.1967,\n",
              "                      -0.0784, -0.1149, -0.2084, -0.3905, -0.0784, -0.3579, -0.1516,  0.0159,\n",
              "                      -0.0797, -0.2133, -0.3118, -0.1519, -0.0421,  0.0099, -0.2872,  0.0269,\n",
              "                       0.0223, -0.4279, -0.3209,  0.0437, -0.0999, -0.3308, -0.0648, -0.2163,\n",
              "                      -0.1108, -0.1748, -0.2135,  0.0687, -0.1366, -0.3062, -0.1234, -0.0891,\n",
              "                      -0.1603, -0.3174, -0.1893, -0.1000, -0.0542, -0.3982, -0.1294, -0.1257,\n",
              "                      -0.1789, -0.2509, -0.1224,  0.0031,  0.2577, -0.2303, -0.0676, -0.1037,\n",
              "                      -0.3216, -0.1114,  0.0756, -0.0034,  0.2183, -0.0409, -0.1956, -0.1602,\n",
              "                       0.1186,  0.2806,  0.0888, -0.1678, -0.1723,  0.0729,  0.0613, -0.2145,\n",
              "                      -0.0690, -0.2493, -0.1192,  0.0863,  0.0509, -0.2663, -0.2556, -0.3190,\n",
              "                      -0.0464, -0.0429, -0.3062, -0.0367, -0.0016, -0.1328,  0.1057, -0.0716,\n",
              "                      -0.0453, -0.4254,  0.0406,  0.0139, -0.2590, -0.5839, -0.2332,  0.1123,\n",
              "                      -0.1005, -0.1682,  0.0002,  0.2009, -0.1842, -0.3049,  0.0664,  0.2828,\n",
              "                       0.1355, -0.0031, -0.1180, -0.0342,  0.0744, -0.0689, -0.1711, -0.1395,\n",
              "                      -0.1135,  0.1280, -0.2058,  0.0471,  0.2059, -0.2459, -0.1107, -0.1250],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.0.bn2.running_var',\n",
              "              tensor([0.0898, 0.0965, 0.0814, 0.0836, 0.0952, 0.1294, 0.0734, 0.1021, 0.0921,\n",
              "                      0.1079, 0.1328, 0.1363, 0.1073, 0.3291, 0.0912, 0.0856, 0.0863, 0.0640,\n",
              "                      0.0753, 0.1103, 0.0724, 0.0665, 0.1781, 0.0894, 0.0680, 0.1256, 0.0752,\n",
              "                      0.1052, 0.2148, 0.1572, 0.0643, 0.0921, 0.0839, 0.1225, 0.0849, 0.0834,\n",
              "                      0.0857, 0.2731, 0.0800, 0.0877, 0.0580, 0.1402, 0.1208, 0.0838, 0.0600,\n",
              "                      0.1080, 0.0662, 0.0883, 0.0757, 0.0824, 0.0990, 0.0981, 0.1266, 0.1286,\n",
              "                      0.1102, 0.1253, 0.0595, 0.0916, 0.1331, 0.1480, 0.0807, 0.1222, 0.0732,\n",
              "                      0.1230, 0.2086, 0.1038, 0.1316, 0.1654, 0.2308, 0.0916, 0.1394, 0.1909,\n",
              "                      0.1199, 0.1285, 0.0432, 0.0890, 0.0597, 0.0605, 0.0855, 0.0974, 0.0797,\n",
              "                      0.0858, 0.0561, 0.0734, 0.1020, 0.1258, 0.0509, 0.0908, 0.0783, 0.1216,\n",
              "                      0.2209, 0.0760, 0.0574, 0.0941, 0.0985, 0.1990, 0.0740, 0.1488, 0.1373,\n",
              "                      0.1475, 0.0916, 0.0910, 0.0731, 0.1202, 0.1315, 0.0702, 0.1661, 0.0763,\n",
              "                      0.1065, 0.1135, 0.2118, 0.1163, 0.1411, 0.1108, 0.0755, 0.1215, 0.1063,\n",
              "                      0.1320, 0.1320, 0.0588, 0.0350, 0.1281, 0.0681, 0.0888, 0.1943, 0.0971,\n",
              "                      0.0595, 0.0639, 0.0840, 0.2169, 0.0783, 0.0844, 0.1114, 0.0720, 0.0728,\n",
              "                      0.0911, 0.1958, 0.1209, 0.1250, 0.0795, 0.0805, 0.0611, 0.0820, 0.1118,\n",
              "                      0.0920, 0.1283, 0.0604, 0.1314, 0.0993, 0.0553, 0.0892, 0.1049, 0.1404,\n",
              "                      0.1333, 0.0953, 0.0993, 0.0905, 0.0985, 0.1310, 0.1679, 0.1152, 0.1101,\n",
              "                      0.0741, 0.0466, 0.0910, 0.0824, 0.0632, 0.0642, 0.0742, 0.1152, 0.0480,\n",
              "                      0.1123, 0.0675, 0.0577, 0.0733, 0.0886, 0.0778, 0.1651, 0.1262, 0.1280,\n",
              "                      0.0502, 0.0590, 0.0655, 0.1219, 0.0606, 0.1055, 0.1426, 0.1774, 0.0542,\n",
              "                      0.0738, 0.0870, 0.1058, 0.0971, 0.0717, 0.1105, 0.0674, 0.0755, 0.1345,\n",
              "                      0.0538, 0.0960, 0.1250, 0.0646, 0.1715, 0.0620, 0.0770, 0.0663, 0.0862,\n",
              "                      0.1277, 0.1282, 0.0972, 0.1644, 0.0616, 0.1392, 0.1805, 0.0787, 0.1473,\n",
              "                      0.1838, 0.0952, 0.1001, 0.1229, 0.0533, 0.0873, 0.0762, 0.1311, 0.1520,\n",
              "                      0.0554, 0.0618, 0.1070, 0.0813, 0.1324, 0.0989, 0.0720, 0.0863, 0.0639,\n",
              "                      0.1148, 0.0952, 0.0894, 0.0989, 0.0788, 0.0795, 0.1093, 0.0401, 0.1206,\n",
              "                      0.1216, 0.0847, 0.1661, 0.0946, 0.0718, 0.0742, 0.0889, 0.0806, 0.1134,\n",
              "                      0.0872, 0.1109, 0.0976, 0.0599], device='cuda:0')),\n",
              "             ('layer3.0.bn2.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('layer3.0.downsample.0.weight', tensor([[[[ 0.0045]],\n",
              "              \n",
              "                       [[-0.0160]],\n",
              "              \n",
              "                       [[-0.0152]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0112]],\n",
              "              \n",
              "                       [[ 0.0028]],\n",
              "              \n",
              "                       [[ 0.0051]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0100]],\n",
              "              \n",
              "                       [[-0.0528]],\n",
              "              \n",
              "                       [[-0.0294]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0277]],\n",
              "              \n",
              "                       [[ 0.0357]],\n",
              "              \n",
              "                       [[ 0.0199]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0024]],\n",
              "              \n",
              "                       [[ 0.0236]],\n",
              "              \n",
              "                       [[-0.0086]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0279]],\n",
              "              \n",
              "                       [[ 0.0007]],\n",
              "              \n",
              "                       [[-0.0023]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0279]],\n",
              "              \n",
              "                       [[-0.0414]],\n",
              "              \n",
              "                       [[ 0.0225]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0330]],\n",
              "              \n",
              "                       [[ 0.0011]],\n",
              "              \n",
              "                       [[-0.0220]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0110]],\n",
              "              \n",
              "                       [[-0.0207]],\n",
              "              \n",
              "                       [[ 0.0067]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0180]],\n",
              "              \n",
              "                       [[ 0.0354]],\n",
              "              \n",
              "                       [[ 0.0022]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0090]],\n",
              "              \n",
              "                       [[-0.0207]],\n",
              "              \n",
              "                       [[-0.0005]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0164]],\n",
              "              \n",
              "                       [[ 0.0474]],\n",
              "              \n",
              "                       [[ 0.0137]]]], device='cuda:0')),\n",
              "             ('layer3.0.downsample.1.weight',\n",
              "              tensor([0.0568, 0.0689, 0.0178, 0.2028, 0.0655, 0.0495, 0.1138, 0.1141, 0.0366,\n",
              "                      0.0355, 0.0730, 0.1022, 0.0979, 0.1133, 0.1034, 0.0752, 0.0989, 0.2147,\n",
              "                      0.0377, 0.0331, 0.1562, 0.0657, 0.0408, 0.1053, 0.2005, 0.0803, 0.1226,\n",
              "                      0.0774, 0.0381, 0.0647, 0.1147, 0.1029, 0.0262, 0.0837, 0.1027, 0.1043,\n",
              "                      0.0919, 0.0714, 0.0449, 0.0926, 0.1498, 0.0966, 0.0921, 0.0776, 0.1502,\n",
              "                      0.0385, 0.0618, 0.1117, 0.0548, 0.1088, 0.1078, 0.1285, 0.1044, 0.1014,\n",
              "                      0.1109, 0.0516, 0.1294, 0.0463, 0.0980, 0.0417, 0.1485, 0.0567, 0.1066,\n",
              "                      0.1132, 0.1219, 0.1897, 0.0421, 0.0231, 0.0725, 0.1084, 0.0325, 0.0659,\n",
              "                      0.0873, 0.1209, 0.1648, 0.0559, 0.1258, 0.1023, 0.0416, 0.0674, 0.0993,\n",
              "                      0.0436, 0.1297, 0.1245, 0.1129, 0.0135, 0.0640, 0.1019, 0.0775, 0.0391,\n",
              "                      0.0557, 0.1773, 0.0954, 0.0139, 0.0687, 0.0569, 0.1112, 0.0999, 0.0670,\n",
              "                      0.0596, 0.1165, 0.1187, 0.0859, 0.0839, 0.0664, 0.0693, 0.0447, 0.1056,\n",
              "                      0.1355, 0.0294, 0.0846, 0.0520, 0.0585, 0.1507, 0.0781, 0.0264, 0.1049,\n",
              "                      0.1685, 0.1018, 0.0577, 0.0978, 0.0559, 0.0975, 0.1174, 0.1066, 0.0195,\n",
              "                      0.0855, 0.1056, 0.1137, 0.0336, 0.0108, 0.2007, 0.0663, 0.1378, 0.0785,\n",
              "                      0.0978, 0.0518, 0.2886, 0.0938, 0.0464, 0.1170, 0.1086, 0.0497, 0.0644,\n",
              "                      0.0569, 0.0764, 0.1079, 0.1110, 0.0380, 0.1013, 0.1443, 0.0323, 0.0461,\n",
              "                      0.1150, 0.0726, 0.0916, 0.1158, 0.0376, 0.0243, 0.0545, 0.1383, 0.0822,\n",
              "                      0.1618, 0.0191, 0.1144, 0.1010, 0.1688, 0.0835, 0.1496, 0.0682, 0.1268,\n",
              "                      0.0724, 0.1028, 0.1065, 0.1298, 0.0852, 0.0769, 0.0473, 0.1091, 0.0244,\n",
              "                      0.0563, 0.0640, 0.1437, 0.0589, 0.1401, 0.0493, 0.0784, 0.1140, 0.0444,\n",
              "                      0.0954, 0.0759, 0.0310, 0.0107, 0.1258, 0.0623, 0.0665, 0.1347, 0.0413,\n",
              "                      0.0708, 0.1256, 0.0889, 0.1592, 0.0737, 0.1254, 0.1424, 0.1069, 0.0368,\n",
              "                      0.0734, 0.0530, 0.1819, 0.0257, 0.0867, 0.1050, 0.0838, 0.0946, 0.0208,\n",
              "                      0.0221, 0.0655, 0.0634, 0.0592, 0.0290, 0.1221, 0.1126, 0.0686, 0.0384,\n",
              "                      0.1281, 0.2029, 0.0934, 0.1520, 0.1116, 0.0292, 0.0564, 0.0805, 0.1288,\n",
              "                      0.0369, 0.0519, 0.1212, 0.0314, 0.0298, 0.0932, 0.0612, 0.1669, 0.1089,\n",
              "                      0.1005, 0.0569, 0.0228, 0.1675, 0.1269, 0.0991, 0.0714, 0.0830, 0.0880,\n",
              "                      0.0985, 0.0776, 0.0728, 0.1251], device='cuda:0')),\n",
              "             ('layer3.0.downsample.1.bias',\n",
              "              tensor([-0.0234,  0.0973, -0.0019, -0.0563,  0.0083,  0.0784, -0.0380, -0.0057,\n",
              "                      -0.0001,  0.0773,  0.0911,  0.0633, -0.0455,  0.0202,  0.0100, -0.0336,\n",
              "                      -0.0434, -0.2182, -0.0719,  0.0674, -0.0403, -0.0749,  0.1540, -0.1118,\n",
              "                      -0.0402, -0.0506, -0.1230, -0.1681, -0.0079, -0.1166,  0.0143, -0.0320,\n",
              "                      -0.0362,  0.1414,  0.0135, -0.0076, -0.0444,  0.0888,  0.0818, -0.0334,\n",
              "                      -0.0648,  0.0072,  0.1053,  0.0232, -0.0351,  0.0918,  0.0296, -0.0587,\n",
              "                      -0.0056, -0.1039,  0.0164, -0.1014, -0.0163, -0.0145, -0.0374,  0.0023,\n",
              "                      -0.1371,  0.0399,  0.0202, -0.0238, -0.0284,  0.0822, -0.0644, -0.0112,\n",
              "                      -0.0246, -0.0145, -0.1366,  0.1159,  0.0916, -0.2172,  0.0753,  0.0638,\n",
              "                       0.0544,  0.0097, -0.1549, -0.0365, -0.0856, -0.0691, -0.0293,  0.0089,\n",
              "                      -0.0552,  0.0259, -0.0541, -0.0473,  0.0020,  0.0197, -0.2610,  0.0305,\n",
              "                      -0.0977,  0.0459,  0.0633, -0.0499, -0.1500,  0.0986,  0.0652,  0.0706,\n",
              "                      -0.0437, -0.0058,  0.0969, -0.0082, -0.2347, -0.0632,  0.0360,  0.1357,\n",
              "                       0.1008, -0.0351,  0.0825, -0.1429, -0.1421,  0.1343,  0.0669,  0.0703,\n",
              "                      -0.0328, -0.0632, -0.1865,  0.0938, -0.0505, -0.2970, -0.0412, -0.0828,\n",
              "                      -0.2778,  0.0335, -0.1373,  0.0102, -0.0597,  0.0383, -0.0283, -0.1317,\n",
              "                      -0.2202,  0.1065,  0.0540, -0.0718,  0.1013, -0.0356, -0.0607, -0.0311,\n",
              "                       0.0470, -0.3853,  0.0238,  0.0156, -0.0505, -0.3016,  0.0921,  0.0310,\n",
              "                       0.0785, -0.0839, -0.0870, -0.0215,  0.0431, -0.2706, -0.1605,  0.0717,\n",
              "                       0.0312, -0.0979, -0.0343, -0.0806,  0.0268,  0.0202,  0.0930,  0.0517,\n",
              "                      -0.0224,  0.0127, -0.1078, -0.0132,  0.0114, -0.0469, -0.1549, -0.0899,\n",
              "                      -0.0318,  0.0549, -0.3095,  0.0343,  0.0096, -0.2722, -0.0619, -0.1014,\n",
              "                      -0.0046, -0.0617, -0.0749, -0.0533, -0.1523, -0.0586, -0.0701, -0.0442,\n",
              "                      -0.0205, -0.0208,  0.0235, -0.0770, -0.0635, -0.1484,  0.0306,  0.1013,\n",
              "                      -0.0189, -0.0290,  0.0306, -0.0396, -0.0445,  0.1058, -0.1730, -0.1731,\n",
              "                      -0.0587, -0.1132,  0.0115, -0.0414, -0.1751, -0.1061,  0.0464, -0.0728,\n",
              "                       0.0580,  0.0093,  0.1028, -0.0694,  0.1260, -0.0182, -0.1995,  0.0453,\n",
              "                       0.0737,  0.1188, -0.0259,  0.0200, -0.0308,  0.0882,  0.0075,  0.0037,\n",
              "                       0.0047, -0.2011, -0.1555, -0.0077,  0.0077, -0.0563,  0.0574, -0.0755,\n",
              "                       0.0059, -0.0356,  0.0676,  0.0614,  0.0177,  0.0419,  0.0853,  0.0089,\n",
              "                       0.0665, -0.2065, -0.0592,  0.0419,  0.0876,  0.1144, -0.1557, -0.0885,\n",
              "                      -0.1667, -0.0052, -0.0539,  0.0425, -0.0740, -0.0186,  0.0413, -0.0967],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.0.downsample.1.running_mean',\n",
              "              tensor([-0.1149, -0.1465, -0.0842, -0.1776, -0.0304, -0.0148, -0.0691, -0.2464,\n",
              "                      -0.0658,  0.0564,  0.0123,  0.0408, -0.0953, -0.0618,  0.0590, -0.1095,\n",
              "                      -0.2178, -0.2045, -0.0305, -0.0657, -0.1987, -0.0145,  0.0522, -0.1501,\n",
              "                      -0.0498, -0.2124,  0.0218, -0.0910, -0.0615, -0.2195,  0.0022,  0.1926,\n",
              "                      -0.0698, -0.2044,  0.0062, -0.0224, -0.1376, -0.0539,  0.0739, -0.0216,\n",
              "                      -0.1117, -0.1123, -0.1813,  0.0059,  0.0090,  0.0999, -0.0894,  0.0423,\n",
              "                      -0.1491, -0.1598,  0.1301, -0.1335, -0.1720, -0.2142,  0.0145, -0.0310,\n",
              "                       0.1048, -0.1039, -0.1746,  0.0190, -0.2525, -0.1563, -0.0919, -0.1579,\n",
              "                       0.0119, -0.2281, -0.0432, -0.0697, -0.0527,  0.0117, -0.0012,  0.1624,\n",
              "                       0.0608, -0.1068, -0.0557, -0.0274, -0.1857,  0.0241,  0.0720, -0.0997,\n",
              "                      -0.0419, -0.0014,  0.0210,  0.0629, -0.0555, -0.0524, -0.0430, -0.0917,\n",
              "                      -0.0058,  0.0951,  0.0880, -0.3046, -0.2122,  0.0517, -0.0356,  0.0075,\n",
              "                      -0.0325, -0.1431, -0.0048,  0.0478,  0.0307, -0.1706, -0.0072, -0.0188,\n",
              "                      -0.0531, -0.0055, -0.0852, -0.0188,  0.0416, -0.1350, -0.0868,  0.0785,\n",
              "                      -0.0681, -0.0095, -0.0503,  0.0493, -0.1169, -0.0164, -0.0732, -0.1493,\n",
              "                      -0.0661, -0.0429,  0.1245, -0.0219, -0.1075, -0.1102, -0.0191, -0.1051,\n",
              "                      -0.0498, -0.0350, -0.0255, -0.0258, -0.1848,  0.0039,  0.0498, -0.0205,\n",
              "                      -0.0478, -0.1006, -0.0068,  0.1086, -0.1786,  0.0480, -0.0401,  0.0232,\n",
              "                       0.0377, -0.2091, -0.2249,  0.0234,  0.0251,  0.0000, -0.1332,  0.0164,\n",
              "                       0.0243, -0.1132,  0.0453, -0.1570, -0.0624,  0.0976, -0.0579, -0.0161,\n",
              "                      -0.0690, -0.1169, -0.2751, -0.0530,  0.0857, -0.1551, -0.1024, -0.0706,\n",
              "                       0.0545, -0.1180, -0.1819, -0.1244,  0.0531, -0.0721,  0.0434,  0.0739,\n",
              "                      -0.1006, -0.0293,  0.0604, -0.0101, -0.1284, -0.1074, -0.2965, -0.1254,\n",
              "                      -0.0670, -0.0427, -0.0387, -0.0712, -0.0885, -0.0480,  0.0841, -0.0591,\n",
              "                      -0.0504,  0.0430, -0.0605, -0.0326,  0.0489, -0.0535,  0.0137, -0.1431,\n",
              "                      -0.1021,  0.0357, -0.0092, -0.0289, -0.0884, -0.0405,  0.0810, -0.1642,\n",
              "                      -0.0436, -0.0623,  0.0674,  0.0974, -0.0209,  0.0286, -0.0286,  0.0699,\n",
              "                       0.0110,  0.1257, -0.0334,  0.0116, -0.0040, -0.0068, -0.0522, -0.0928,\n",
              "                       0.0529, -0.1302, -0.1727, -0.0300, -0.1624, -0.0322, -0.0467,  0.0136,\n",
              "                      -0.0335,  0.0330, -0.1173, -0.1671,  0.0503, -0.1861,  0.0724,  0.0192,\n",
              "                      -0.1009,  0.0927, -0.0137,  0.0285,  0.0301, -0.0086, -0.1949, -0.1319,\n",
              "                      -0.1175,  0.0303, -0.1520,  0.0168, -0.0886, -0.0147,  0.0355, -0.1022],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.0.downsample.1.running_var',\n",
              "              tensor([0.0124, 0.0136, 0.0062, 0.0277, 0.0104, 0.0127, 0.0203, 0.0238, 0.0065,\n",
              "                      0.0077, 0.0098, 0.0216, 0.0153, 0.0532, 0.0168, 0.0088, 0.0192, 0.0301,\n",
              "                      0.0085, 0.0057, 0.0245, 0.0043, 0.0079, 0.0162, 0.0257, 0.0218, 0.0223,\n",
              "                      0.0075, 0.0131, 0.0141, 0.0146, 0.0185, 0.0124, 0.0164, 0.0168, 0.0227,\n",
              "                      0.0097, 0.0175, 0.0143, 0.0133, 0.0212, 0.0197, 0.0152, 0.0128, 0.0120,\n",
              "                      0.0105, 0.0071, 0.0271, 0.0103, 0.0145, 0.0203, 0.0245, 0.0248, 0.0176,\n",
              "                      0.0168, 0.0183, 0.0195, 0.0131, 0.0190, 0.0202, 0.0199, 0.0122, 0.0179,\n",
              "                      0.0282, 0.0322, 0.0274, 0.0089, 0.0067, 0.0129, 0.0107, 0.0092, 0.0224,\n",
              "                      0.0236, 0.0230, 0.0170, 0.0120, 0.0168, 0.0089, 0.0126, 0.0118, 0.0184,\n",
              "                      0.0163, 0.0152, 0.0187, 0.0224, 0.0113, 0.0045, 0.0131, 0.0091, 0.0123,\n",
              "                      0.0157, 0.0357, 0.0147, 0.0055, 0.0081, 0.0091, 0.0120, 0.0182, 0.0164,\n",
              "                      0.0105, 0.0122, 0.0141, 0.0218, 0.0131, 0.0140, 0.0115, 0.0117, 0.0181,\n",
              "                      0.0183, 0.0099, 0.0197, 0.0103, 0.0102, 0.0163, 0.0089, 0.0066, 0.0202,\n",
              "                      0.0114, 0.0126, 0.0080, 0.0105, 0.0102, 0.0151, 0.0243, 0.0281, 0.0107,\n",
              "                      0.0105, 0.0091, 0.0136, 0.0155, 0.0070, 0.0335, 0.0206, 0.0226, 0.0080,\n",
              "                      0.0133, 0.0148, 0.0252, 0.0150, 0.0078, 0.0185, 0.0079, 0.0180, 0.0116,\n",
              "                      0.0073, 0.0139, 0.0151, 0.0230, 0.0072, 0.0092, 0.0244, 0.0076, 0.0108,\n",
              "                      0.0127, 0.0162, 0.0124, 0.0153, 0.0061, 0.0065, 0.0126, 0.0178, 0.0135,\n",
              "                      0.0275, 0.0036, 0.0144, 0.0132, 0.0204, 0.0102, 0.0175, 0.0138, 0.0134,\n",
              "                      0.0072, 0.0141, 0.0102, 0.0209, 0.0134, 0.0126, 0.0077, 0.0165, 0.0070,\n",
              "                      0.0061, 0.0071, 0.0245, 0.0088, 0.0177, 0.0116, 0.0217, 0.0249, 0.0087,\n",
              "                      0.0109, 0.0317, 0.0060, 0.0080, 0.0141, 0.0126, 0.0102, 0.0121, 0.0155,\n",
              "                      0.0089, 0.0115, 0.0152, 0.0238, 0.0106, 0.0189, 0.0126, 0.0116, 0.0059,\n",
              "                      0.0188, 0.0140, 0.0291, 0.0132, 0.0143, 0.0148, 0.0241, 0.0109, 0.0102,\n",
              "                      0.0088, 0.0149, 0.0141, 0.0070, 0.0038, 0.0210, 0.0161, 0.0104, 0.0039,\n",
              "                      0.0110, 0.0267, 0.0096, 0.0351, 0.0180, 0.0081, 0.0078, 0.0083, 0.0198,\n",
              "                      0.0072, 0.0152, 0.0169, 0.0073, 0.0102, 0.0146, 0.0140, 0.0139, 0.0238,\n",
              "                      0.0183, 0.0090, 0.0064, 0.0283, 0.0160, 0.0106, 0.0109, 0.0162, 0.0111,\n",
              "                      0.0117, 0.0127, 0.0119, 0.0182], device='cuda:0')),\n",
              "             ('layer3.0.downsample.1.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('layer3.1.conv1.weight', tensor([[[[ 0.0517,  0.0484,  0.0359],\n",
              "                        [ 0.0545,  0.0577,  0.0559],\n",
              "                        [ 0.0273,  0.0148,  0.0245]],\n",
              "              \n",
              "                       [[-0.0094, -0.0077,  0.0003],\n",
              "                        [-0.0074, -0.0021,  0.0159],\n",
              "                        [-0.0258, -0.0254, -0.0060]],\n",
              "              \n",
              "                       [[-0.0111, -0.0197, -0.0234],\n",
              "                        [-0.0128, -0.0229, -0.0253],\n",
              "                        [ 0.0092,  0.0061, -0.0065]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0416, -0.0180, -0.0503],\n",
              "                        [ 0.0199,  0.0526,  0.0225],\n",
              "                        [-0.0196, -0.0087, -0.0221]],\n",
              "              \n",
              "                       [[-0.0078, -0.0129,  0.0028],\n",
              "                        [-0.0074, -0.0126,  0.0078],\n",
              "                        [-0.0080, -0.0011,  0.0017]],\n",
              "              \n",
              "                       [[-0.0072,  0.0058, -0.0004],\n",
              "                        [-0.0248, -0.0108, -0.0084],\n",
              "                        [-0.0174, -0.0084, -0.0072]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0250, -0.0110, -0.0121],\n",
              "                        [-0.0269, -0.0186, -0.0318],\n",
              "                        [-0.0039,  0.0099, -0.0055]],\n",
              "              \n",
              "                       [[-0.0285, -0.0379, -0.0200],\n",
              "                        [-0.0036, -0.0149, -0.0166],\n",
              "                        [ 0.0533,  0.0555,  0.0425]],\n",
              "              \n",
              "                       [[-0.0360, -0.0412, -0.0297],\n",
              "                        [-0.0048,  0.0039, -0.0086],\n",
              "                        [ 0.0397,  0.0556,  0.0244]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0276, -0.0434, -0.0377],\n",
              "                        [ 0.0089,  0.0166,  0.0122],\n",
              "                        [-0.0088, -0.0384, -0.0163]],\n",
              "              \n",
              "                       [[ 0.0222,  0.0197,  0.0140],\n",
              "                        [ 0.0094,  0.0127,  0.0075],\n",
              "                        [ 0.0223,  0.0416,  0.0200]],\n",
              "              \n",
              "                       [[-0.0011,  0.0035, -0.0038],\n",
              "                        [ 0.0223,  0.0261,  0.0002],\n",
              "                        [-0.0124, -0.0076, -0.0029]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0169, -0.0173, -0.0263],\n",
              "                        [-0.0132, -0.0104, -0.0140],\n",
              "                        [-0.0006, -0.0179, -0.0087]],\n",
              "              \n",
              "                       [[-0.0038, -0.0032,  0.0207],\n",
              "                        [-0.0063, -0.0124,  0.0068],\n",
              "                        [ 0.0136,  0.0140,  0.0076]],\n",
              "              \n",
              "                       [[-0.0097, -0.0102, -0.0172],\n",
              "                        [-0.0095, -0.0150, -0.0154],\n",
              "                        [-0.0153, -0.0285, -0.0178]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0178, -0.0014,  0.0102],\n",
              "                        [ 0.0008, -0.0122,  0.0105],\n",
              "                        [ 0.0004, -0.0123,  0.0176]],\n",
              "              \n",
              "                       [[ 0.0015,  0.0031,  0.0108],\n",
              "                        [-0.0036,  0.0005,  0.0074],\n",
              "                        [ 0.0116,  0.0181,  0.0065]],\n",
              "              \n",
              "                       [[ 0.0007, -0.0037,  0.0107],\n",
              "                        [ 0.0131,  0.0054,  0.0193],\n",
              "                        [ 0.0028,  0.0237,  0.0155]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0193,  0.0060, -0.0049],\n",
              "                        [-0.0158, -0.0094, -0.0008],\n",
              "                        [-0.0072,  0.0090,  0.0115]],\n",
              "              \n",
              "                       [[-0.0026, -0.0082,  0.0127],\n",
              "                        [-0.0036, -0.0080,  0.0097],\n",
              "                        [ 0.0073, -0.0086, -0.0080]],\n",
              "              \n",
              "                       [[-0.0069, -0.0104, -0.0112],\n",
              "                        [-0.0055, -0.0030,  0.0043],\n",
              "                        [-0.0135, -0.0167, -0.0041]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0145, -0.0007, -0.0015],\n",
              "                        [-0.0365, -0.0015, -0.0062],\n",
              "                        [-0.0112, -0.0310, -0.0490]],\n",
              "              \n",
              "                       [[ 0.0129,  0.0114, -0.0076],\n",
              "                        [-0.0235,  0.0035,  0.0019],\n",
              "                        [-0.0155,  0.0141,  0.0170]],\n",
              "              \n",
              "                       [[-0.0125, -0.0041,  0.0125],\n",
              "                        [ 0.0009,  0.0055, -0.0122],\n",
              "                        [-0.0002, -0.0145, -0.0311]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0230, -0.0649, -0.0433],\n",
              "                        [-0.0260, -0.0480, -0.0349],\n",
              "                        [ 0.0338,  0.0400,  0.0611]],\n",
              "              \n",
              "                       [[ 0.0007, -0.0147, -0.0243],\n",
              "                        [-0.0034,  0.0078, -0.0082],\n",
              "                        [ 0.0015, -0.0174, -0.0190]],\n",
              "              \n",
              "                       [[-0.0091,  0.0018,  0.0084],\n",
              "                        [-0.0175,  0.0052,  0.0033],\n",
              "                        [-0.0111, -0.0060, -0.0189]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0119,  0.0020,  0.0070],\n",
              "                        [ 0.0085, -0.0071, -0.0285],\n",
              "                        [ 0.0240,  0.0039, -0.0098]],\n",
              "              \n",
              "                       [[-0.0142, -0.0052,  0.0095],\n",
              "                        [-0.0110, -0.0246,  0.0004],\n",
              "                        [ 0.0014, -0.0056,  0.0037]],\n",
              "              \n",
              "                       [[-0.0167, -0.0123, -0.0288],\n",
              "                        [-0.0424, -0.0386, -0.0406],\n",
              "                        [-0.0205, -0.0319, -0.0195]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0161, -0.0105, -0.0288],\n",
              "                        [ 0.0299,  0.0518,  0.0319],\n",
              "                        [ 0.0397,  0.0320,  0.0256]],\n",
              "              \n",
              "                       [[ 0.0151,  0.0124,  0.0120],\n",
              "                        [ 0.0208,  0.0282,  0.0164],\n",
              "                        [-0.0004, -0.0070,  0.0005]],\n",
              "              \n",
              "                       [[-0.0065, -0.0019,  0.0029],\n",
              "                        [ 0.0022, -0.0075,  0.0064],\n",
              "                        [ 0.0121, -0.0056,  0.0142]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0036,  0.0297,  0.0094],\n",
              "                        [-0.0440, -0.0055, -0.0312],\n",
              "                        [-0.0161, -0.0145, -0.0399]],\n",
              "              \n",
              "                       [[ 0.0313,  0.0627,  0.0260],\n",
              "                        [-0.0019,  0.0218, -0.0156],\n",
              "                        [ 0.0162,  0.0179, -0.0178]],\n",
              "              \n",
              "                       [[-0.0034, -0.0496, -0.0226],\n",
              "                        [-0.0061, -0.0299, -0.0228],\n",
              "                        [ 0.0070,  0.0003,  0.0245]]]], device='cuda:0')),\n",
              "             ('layer3.1.bn1.weight',\n",
              "              tensor([0.2761, 0.2219, 0.2076, 0.3349, 0.3116, 0.2742, 0.2524, 0.3551, 0.2189,\n",
              "                      0.2977, 0.2752, 0.2827, 0.2625, 0.2578, 0.3028, 0.2229, 0.2887, 0.2408,\n",
              "                      0.2254, 0.3943, 0.2982, 0.2425, 0.2471, 0.3058, 0.2984, 0.2562, 0.2284,\n",
              "                      0.2847, 0.3015, 0.3427, 0.2225, 0.2099, 0.2930, 0.2833, 0.2796, 0.3110,\n",
              "                      0.3149, 0.2477, 0.2113, 0.2149, 0.3286, 0.3501, 0.2516, 0.2466, 0.2174,\n",
              "                      0.2593, 0.3024, 0.2360, 0.2523, 0.2068, 0.2661, 0.4015, 0.2440, 0.2061,\n",
              "                      0.2003, 0.2807, 0.2018, 0.2378, 0.1751, 0.3373, 0.2369, 0.3150, 0.2203,\n",
              "                      0.2562, 0.2961, 0.3917, 0.2869, 0.2048, 0.3884, 0.4672, 0.3308, 0.2548,\n",
              "                      0.3797, 0.2910, 0.2393, 0.1591, 0.2966, 0.3711, 0.2875, 0.1951, 0.2240,\n",
              "                      0.2350, 0.2545, 0.2856, 0.2985, 0.2575, 0.2177, 0.3084, 0.3547, 0.2517,\n",
              "                      0.2022, 0.2399, 0.3454, 0.3971, 0.3376, 0.2859, 0.3381, 0.2625, 0.2933,\n",
              "                      0.2204, 0.2183, 0.2834, 0.3278, 0.2273, 0.2354, 0.2440, 0.2031, 0.2571,\n",
              "                      0.2632, 0.2732, 0.3229, 0.2433, 0.2588, 0.2157, 0.3417, 0.2947, 0.2487,\n",
              "                      0.2660, 0.3658, 0.3032, 0.2776, 0.3125, 0.3036, 0.2661, 0.3186, 0.3007,\n",
              "                      0.1922, 0.2873, 0.3523, 0.2288, 0.1600, 0.2740, 0.2794, 0.2546, 0.2645,\n",
              "                      0.2373, 0.3676, 0.2717, 0.2946, 0.2756, 0.2214, 0.2249, 0.3435, 0.2416,\n",
              "                      0.4006, 0.3161, 0.2616, 0.4988, 0.3402, 0.2598, 0.3602, 0.3265, 0.1718,\n",
              "                      0.2518, 0.2979, 0.2574, 0.3022, 0.2022, 0.2249, 0.2411, 0.3477, 0.3221,\n",
              "                      0.2039, 0.2247, 0.2919, 0.2846, 0.2741, 0.3418, 0.2630, 0.3091, 0.2015,\n",
              "                      0.2037, 0.2162, 0.3127, 0.2719, 0.3847, 0.2524, 0.2531, 0.2529, 0.2369,\n",
              "                      0.2721, 0.2989, 0.3067, 0.3937, 0.1510, 0.3120, 0.2844, 0.2482, 0.2800,\n",
              "                      0.2413, 0.2099, 0.3498, 0.3919, 0.2494, 0.2384, 0.3080, 0.3626, 0.2655,\n",
              "                      0.3088, 0.4108, 0.2556, 0.2390, 0.2804, 0.2178, 0.2390, 0.4032, 0.2790,\n",
              "                      0.3036, 0.1748, 0.2595, 0.2438, 0.2958, 0.2616, 0.3096, 0.3495, 0.2586,\n",
              "                      0.3860, 0.3037, 0.2598, 0.3379, 0.2819, 0.3271, 0.2286, 0.2949, 0.3130,\n",
              "                      0.3127, 0.2422, 0.2564, 0.3612, 0.2017, 0.2228, 0.3521, 0.3156, 0.3265,\n",
              "                      0.2357, 0.3461, 0.2853, 0.2741, 0.2495, 0.2938, 0.2961, 0.2125, 0.3152,\n",
              "                      0.2571, 0.3729, 0.4279, 0.3449, 0.3337, 0.3268, 0.2806, 0.2671, 0.2069,\n",
              "                      0.2381, 0.2755, 0.2160, 0.2739], device='cuda:0')),\n",
              "             ('layer3.1.bn1.bias',\n",
              "              tensor([-0.1190, -0.0710, -0.3289, -0.2255, -0.3334, -0.1664, -0.2205, -0.3172,\n",
              "                      -0.1990, -0.2878, -0.2048, -0.2469, -0.1905, -0.2499, -0.2778, -0.1585,\n",
              "                      -0.2477, -0.2542, -0.1390, -0.4543, -0.2061, -0.1296, -0.2169, -0.1742,\n",
              "                      -0.2294, -0.1405, -0.1634, -0.3866, -0.2731, -0.3845, -0.1578, -0.0655,\n",
              "                      -0.3521, -0.2181, -0.2045, -0.2105, -0.3194, -0.1395, -0.2483, -0.1755,\n",
              "                      -0.4572, -0.3233, -0.1141, -0.1396, -0.2708, -0.1261, -0.4079, -0.1691,\n",
              "                      -0.2198, -0.1159, -0.1396, -0.5528, -0.2190, -0.1361,  0.0739, -0.1846,\n",
              "                      -0.1223, -0.0921, -0.1607, -0.3266, -0.2261, -0.3129, -0.1092, -0.1529,\n",
              "                      -0.2839, -0.3814, -0.1866, -0.1491, -0.5741, -0.4012, -0.2657, -0.2702,\n",
              "                      -0.3394, -0.2481, -0.1022, -0.0487, -0.1815, -0.5027, -0.3209, -0.0957,\n",
              "                      -0.2497, -0.2000, -0.1370, -0.1567, -0.1930, -0.2054, -0.1001, -0.3504,\n",
              "                      -0.5603, -0.2437, -0.2078, -0.1641, -0.2533, -0.3131, -0.4224, -0.2912,\n",
              "                      -0.2406, -0.2010, -0.2425, -0.0119, -0.0647, -0.3588, -0.3262, -0.1111,\n",
              "                      -0.1715, -0.1004, -0.1886, -0.2875, -0.2053, -0.1745, -0.2686, -0.0920,\n",
              "                      -0.1991, -0.2194, -0.3283, -0.2267, -0.1158, -0.3645, -0.2492, -0.2315,\n",
              "                      -0.2632, -0.4878, -0.2218, -0.2181, -0.3281, -0.1761, -0.1136, -0.2633,\n",
              "                      -0.4258, -0.1612, -0.0946, -0.3070, -0.1453, -0.1470, -0.1526, -0.1580,\n",
              "                      -0.3608, -0.2719, -0.2332, -0.2522, -0.1625, -0.1591, -0.4403, -0.1519,\n",
              "                      -0.2633, -0.2167, -0.2097, -0.4118, -0.3411, -0.1477, -0.3621, -0.2515,\n",
              "                      -0.2286, -0.0052, -0.1195, -0.2859, -0.3783,  0.0629, -0.2242, -0.1342,\n",
              "                      -0.3289, -0.3041, -0.1120, -0.0713, -0.2375, -0.2023, -0.1807, -0.4847,\n",
              "                      -0.2015, -0.3321, -0.0587, -0.1990, -0.3662, -0.1898, -0.3526, -0.3492,\n",
              "                      -0.1369, -0.1806, -0.2878, -0.1602, -0.2783, -0.1759, -0.2454, -0.4881,\n",
              "                       0.1246, -0.2253, -0.5388, -0.3978, -0.2405, -0.1168, -0.1010, -0.3935,\n",
              "                      -0.5667, -0.2279, -0.1661, -0.4049, -0.3025, -0.0669, -0.3130, -0.2773,\n",
              "                      -0.1512, -0.1405, -0.0818, -0.1644, -0.1673, -0.6380, -0.1327, -0.2275,\n",
              "                      -0.1145, -0.1412, -0.3086, -0.2464, -0.1472, -0.1683, -0.5362, -0.1617,\n",
              "                      -0.5455, -0.2419, -0.1237, -0.2073, -0.1812, -0.3883, -0.1068, -0.1597,\n",
              "                      -0.4017, -0.2853, -0.2965, -0.1864, -0.4785, -0.1213, -0.1632, -0.3321,\n",
              "                      -0.2937, -0.2991, -0.2982, -0.3152, -0.2469, -0.1978, -0.0917, -0.2031,\n",
              "                      -0.4516, -0.2205, -0.4333, -0.3257, -0.4740, -0.3295, -0.2326, -0.2676,\n",
              "                      -0.4103, -0.2165, -0.1934, -0.1108, -0.1183, -0.3140,  0.0878, -0.1824],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.1.bn1.running_mean',\n",
              "              tensor([-0.2955, -0.1856, -0.1506, -0.4476, -0.8840, -0.6354, -0.1931, -0.8310,\n",
              "                      -0.4053, -0.8453, -0.1759, -0.4691, -0.4483, -0.5919, -0.5822, -0.1787,\n",
              "                      -0.5705, -0.5695, -0.2790, -0.7800, -0.4064, -0.7159, -0.4124, -0.2860,\n",
              "                      -0.4493, -0.0944, -0.2808, -0.5171, -0.7114, -0.9658, -0.1888, -0.2941,\n",
              "                      -0.9084, -0.1226, -0.3739, -0.7114, -0.6467, -0.6855, -0.0031, -0.6386,\n",
              "                      -1.1166, -0.4892, -0.1075, -0.3612,  0.4530, -0.8979, -0.5594, -0.4921,\n",
              "                      -0.6830,  0.0549, -0.2645, -0.9238, -0.5540, -0.1100,  0.0956, -0.4493,\n",
              "                      -1.0531, -0.3170, -0.3130, -0.8640,  0.0953, -0.4042, -0.3564, -0.2626,\n",
              "                      -0.4785, -0.6976, -0.5426, -0.5002, -0.6840, -0.1160, -0.9204, -0.4270,\n",
              "                      -1.1701, -0.3975,  0.0387, -0.4828, -0.2446, -1.1517, -0.4536, -0.2230,\n",
              "                      -1.0905, -0.1557, -0.5727, -0.2963, -0.4680, -0.6329, -0.6969, -0.7378,\n",
              "                      -0.6779, -0.0476, -0.2113, -0.1331, -0.9072, -0.8454, -0.9010, -0.9466,\n",
              "                      -0.5922, -0.3785, -0.6897,  0.0510, -0.0788, -0.6405, -0.8503,  0.1368,\n",
              "                      -0.5487, -0.1524,  0.4530, -0.5042, -0.4065, -0.4566, -0.8763, -0.2418,\n",
              "                      -0.2625,  0.3802, -0.6373, -0.4160, -0.1295, -0.0107, -0.7737, -0.3400,\n",
              "                      -0.4196, -0.6483, -0.1264, -0.9008, -0.5670, -0.0715, -0.1409, -0.1741,\n",
              "                      -0.7416, -0.4009, -0.3854,  0.0050, -0.5551, -0.2923, -0.3627, -0.3933,\n",
              "                      -0.7157, -0.7223,  0.1100, -0.5311, -0.5978, -0.0543, -0.7915, -0.4387,\n",
              "                      -0.4350, -0.4519, -0.4243, -0.3105, -0.6264, -0.2977, -0.6897, -0.6073,\n",
              "                       0.1931, -0.3391, -0.6977, -0.3167, -0.2338, -0.7178,  0.2736,  0.2702,\n",
              "                      -0.1826, -0.7403, -0.2698,  0.1781, -0.6601, -0.2951, -0.4294, -0.9308,\n",
              "                       0.0539, -0.4388, -0.1756,  0.1746, -0.0869, -0.9381,  0.3599, -0.2479,\n",
              "                      -0.2977, -0.5010, -0.6652, -0.9127, -0.8629, -1.0521, -0.1470, -0.7490,\n",
              "                      -0.2636, -0.5923, -1.1748,  0.4500, -0.5444,  0.2480, -0.8930, -0.8592,\n",
              "                      -0.9878, -0.4853, -0.5536, -0.5430, -0.3185,  0.0025, -0.3815, -0.2928,\n",
              "                       0.1867, -0.0644,  0.1308, -0.3353, -0.0566, -0.8672, -0.5159, -0.3428,\n",
              "                       1.5162, -0.1699, -0.9169, -0.7312, -0.2190, -0.5368, -0.6994, -0.3764,\n",
              "                      -0.8428,  0.0449, -0.0043, -0.3826, -0.4356, -0.9061, -0.2797, -0.7501,\n",
              "                      -0.8236, -0.8111,  0.1913, -0.6292, -1.1866, -0.2538,  0.7384, -0.3672,\n",
              "                      -0.3387, -0.5781, -0.3131, -1.1182, -0.2897, -0.5464, -0.4673, -0.4802,\n",
              "                      -0.6526, -0.5033, -0.0969,  0.0949, -0.8794, -0.4351, -0.5002, -0.3628,\n",
              "                      -0.8229, -0.4735, -0.4620, -0.4580, -0.1348, -0.3477, -0.9010, -0.1569],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.1.bn1.running_var',\n",
              "              tensor([0.2424, 0.2924, 0.0699, 0.1624, 0.1400, 0.1505, 0.1895, 0.1472, 0.1406,\n",
              "                      0.1466, 0.1146, 0.1546, 0.0981, 0.1068, 0.1447, 0.1807, 0.0956, 0.1818,\n",
              "                      0.1827, 0.1544, 0.1215, 0.1927, 0.1492, 0.2634, 0.1827, 0.1215, 0.1582,\n",
              "                      0.0965, 0.1457, 0.1321, 0.1375, 0.2006, 0.1410, 0.1119, 0.1958, 0.1791,\n",
              "                      0.1842, 0.1930, 0.1723, 0.1149, 0.1020, 0.1441, 0.1898, 0.1701, 0.1266,\n",
              "                      0.1743, 0.1020, 0.2182, 0.1458, 0.1062, 0.1956, 0.1488, 0.1741, 0.1368,\n",
              "                      0.2819, 0.1702, 0.1812, 0.1867, 0.1126, 0.1675, 0.1460, 0.1188, 0.2417,\n",
              "                      0.1723, 0.2029, 0.2225, 0.1909, 0.1243, 0.0841, 0.2879, 0.1581, 0.1269,\n",
              "                      0.1467, 0.1740, 0.1673, 0.1344, 0.2026, 0.1530, 0.1480, 0.2203, 0.0950,\n",
              "                      0.1242, 0.1550, 0.1132, 0.2346, 0.1792, 0.2679, 0.1548, 0.0895, 0.1806,\n",
              "                      0.0910, 0.2017, 0.2217, 0.2461, 0.1691, 0.1365, 0.2360, 0.1518, 0.1882,\n",
              "                      0.1602, 0.1810, 0.1222, 0.2066, 0.1882, 0.1357, 0.2216, 0.1020, 0.1387,\n",
              "                      0.1628, 0.2445, 0.1325, 0.1592, 0.1662, 0.1176, 0.1785, 0.1432, 0.1221,\n",
              "                      0.1675, 0.1617, 0.1534, 0.1880, 0.1043, 0.1782, 0.1314, 0.1268, 0.2594,\n",
              "                      0.1345, 0.1638, 0.1151, 0.1362, 0.1410, 0.0932, 0.1345, 0.2020, 0.2042,\n",
              "                      0.2000, 0.2112, 0.1729, 0.1570, 0.1743, 0.1618, 0.1363, 0.1457, 0.1820,\n",
              "                      0.1770, 0.1732, 0.1712, 0.3440, 0.1278, 0.1870, 0.1578, 0.1906, 0.1281,\n",
              "                      0.2643, 0.1862, 0.1236, 0.1300, 0.2375, 0.1288, 0.1860, 0.1773, 0.1458,\n",
              "                      0.1887, 0.1689, 0.1496, 0.2310, 0.1498, 0.1604, 0.1813, 0.1409, 0.1431,\n",
              "                      0.0921, 0.1133, 0.2032, 0.1183, 0.1264, 0.2598, 0.1242, 0.1298, 0.1491,\n",
              "                      0.1235, 0.2040, 0.2534, 0.1384, 0.2293, 0.1876, 0.1013, 0.1006, 0.1376,\n",
              "                      0.1790, 0.3045, 0.1323, 0.1283, 0.1158, 0.1237, 0.1427, 0.1872, 0.2438,\n",
              "                      0.1497, 0.1543, 0.1836, 0.1259, 0.1911, 0.1377, 0.1346, 0.1361, 0.3336,\n",
              "                      0.1547, 0.2661, 0.1624, 0.1050, 0.2124, 0.2303, 0.1823, 0.0994, 0.2044,\n",
              "                      0.0912, 0.1513, 0.2975, 0.1957, 0.1905, 0.1633, 0.1832, 0.1730, 0.1199,\n",
              "                      0.1756, 0.1355, 0.2160, 0.1425, 0.1469, 0.1369, 0.1145, 0.1359, 0.1184,\n",
              "                      0.1015, 0.2215, 0.2200, 0.1423, 0.1875, 0.2177, 0.0988, 0.1374, 0.1395,\n",
              "                      0.1846, 0.1155, 0.2716, 0.2007, 0.1304, 0.1195, 0.1941, 0.2622, 0.1798,\n",
              "                      0.1642, 0.1665, 0.2994, 0.1580], device='cuda:0')),\n",
              "             ('layer3.1.bn1.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('layer3.1.conv2.weight', tensor([[[[-0.0463, -0.0277, -0.0239],\n",
              "                        [-0.0233, -0.0113, -0.0108],\n",
              "                        [-0.0081,  0.0183,  0.0111]],\n",
              "              \n",
              "                       [[ 0.0000, -0.0015, -0.0036],\n",
              "                        [ 0.0050,  0.0196,  0.0177],\n",
              "                        [ 0.0183,  0.0363,  0.0507]],\n",
              "              \n",
              "                       [[-0.0038, -0.0037,  0.0031],\n",
              "                        [ 0.0151,  0.0270,  0.0261],\n",
              "                        [ 0.0381,  0.0512,  0.0464]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0261,  0.0177, -0.0213],\n",
              "                        [ 0.0320,  0.0346,  0.0132],\n",
              "                        [-0.0028,  0.0056, -0.0069]],\n",
              "              \n",
              "                       [[-0.0213, -0.0353, -0.0158],\n",
              "                        [ 0.0202,  0.0170, -0.0066],\n",
              "                        [ 0.0242,  0.0335,  0.0095]],\n",
              "              \n",
              "                       [[ 0.0283,  0.0325,  0.0307],\n",
              "                        [-0.0176, -0.0197,  0.0061],\n",
              "                        [ 0.0029, -0.0047,  0.0110]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0284,  0.0091,  0.0067],\n",
              "                        [-0.0028, -0.0332, -0.0280],\n",
              "                        [ 0.0202,  0.0010,  0.0055]],\n",
              "              \n",
              "                       [[-0.0002,  0.0032, -0.0042],\n",
              "                        [ 0.0080,  0.0019, -0.0046],\n",
              "                        [-0.0107, -0.0225, -0.0416]],\n",
              "              \n",
              "                       [[ 0.0086,  0.0027, -0.0004],\n",
              "                        [ 0.0073,  0.0117, -0.0029],\n",
              "                        [-0.0095, -0.0013, -0.0201]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0036,  0.0069,  0.0064],\n",
              "                        [ 0.0001,  0.0068,  0.0040],\n",
              "                        [ 0.0088,  0.0058,  0.0009]],\n",
              "              \n",
              "                       [[-0.0662, -0.0603, -0.0344],\n",
              "                        [ 0.0232,  0.0305,  0.0352],\n",
              "                        [ 0.0080,  0.0352,  0.0144]],\n",
              "              \n",
              "                       [[-0.0022,  0.0139, -0.0021],\n",
              "                        [-0.0088,  0.0153, -0.0188],\n",
              "                        [-0.0194,  0.0139, -0.0218]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0021, -0.0036, -0.0001],\n",
              "                        [-0.0146, -0.0095, -0.0183],\n",
              "                        [-0.0013, -0.0031, -0.0145]],\n",
              "              \n",
              "                       [[-0.0275, -0.0338, -0.0253],\n",
              "                        [ 0.0003,  0.0159,  0.0351],\n",
              "                        [ 0.0376,  0.0719,  0.0752]],\n",
              "              \n",
              "                       [[ 0.0121,  0.0037, -0.0064],\n",
              "                        [ 0.0106, -0.0057, -0.0060],\n",
              "                        [-0.0021, -0.0100, -0.0158]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0183,  0.0110,  0.0024],\n",
              "                        [ 0.0159,  0.0051, -0.0118],\n",
              "                        [ 0.0082,  0.0050, -0.0046]],\n",
              "              \n",
              "                       [[-0.0053, -0.0043,  0.0119],\n",
              "                        [ 0.0157,  0.0272,  0.0503],\n",
              "                        [ 0.0208,  0.0363,  0.0421]],\n",
              "              \n",
              "                       [[ 0.0186,  0.0345,  0.0277],\n",
              "                        [ 0.0101,  0.0177,  0.0035],\n",
              "                        [ 0.0109,  0.0243,  0.0130]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0187, -0.0098, -0.0136],\n",
              "                        [ 0.0093,  0.0145,  0.0144],\n",
              "                        [ 0.0198,  0.0283,  0.0249]],\n",
              "              \n",
              "                       [[ 0.0082, -0.0045, -0.0027],\n",
              "                        [-0.0051, -0.0193, -0.0029],\n",
              "                        [ 0.0110,  0.0042, -0.0149]],\n",
              "              \n",
              "                       [[-0.0044, -0.0056, -0.0026],\n",
              "                        [-0.0163,  0.0049, -0.0028],\n",
              "                        [-0.0093,  0.0030,  0.0057]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0232, -0.0015,  0.0151],\n",
              "                        [ 0.0588,  0.0339,  0.0036],\n",
              "                        [ 0.0255, -0.0237, -0.0272]],\n",
              "              \n",
              "                       [[-0.0183, -0.0713, -0.0259],\n",
              "                        [ 0.0060,  0.0058,  0.0402],\n",
              "                        [-0.0173, -0.0078,  0.0214]],\n",
              "              \n",
              "                       [[-0.0092, -0.0012, -0.0077],\n",
              "                        [ 0.0309,  0.0545,  0.0246],\n",
              "                        [ 0.0356,  0.0619,  0.0457]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0124, -0.0101, -0.0093],\n",
              "                        [-0.0156, -0.0212, -0.0160],\n",
              "                        [-0.0007,  0.0025,  0.0124]],\n",
              "              \n",
              "                       [[ 0.0155,  0.0213,  0.0250],\n",
              "                        [-0.0260, -0.0234, -0.0211],\n",
              "                        [-0.0118, -0.0014, -0.0099]],\n",
              "              \n",
              "                       [[ 0.0170,  0.0391,  0.0245],\n",
              "                        [-0.0068,  0.0091,  0.0118],\n",
              "                        [-0.0150, -0.0073, -0.0042]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0052, -0.0117, -0.0062],\n",
              "                        [-0.0015,  0.0004,  0.0066],\n",
              "                        [-0.0079,  0.0021,  0.0168]],\n",
              "              \n",
              "                       [[-0.0079, -0.0218, -0.0326],\n",
              "                        [-0.0307, -0.0309, -0.0426],\n",
              "                        [-0.0509, -0.0335, -0.0485]],\n",
              "              \n",
              "                       [[ 0.0181,  0.0371,  0.0302],\n",
              "                        [ 0.0139,  0.0282,  0.0291],\n",
              "                        [ 0.0258,  0.0351,  0.0267]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0084,  0.0029,  0.0061],\n",
              "                        [ 0.0062, -0.0003,  0.0117],\n",
              "                        [ 0.0220,  0.0224,  0.0242]],\n",
              "              \n",
              "                       [[-0.0136,  0.0127,  0.0095],\n",
              "                        [-0.0013,  0.0085,  0.0063],\n",
              "                        [ 0.0044,  0.0163, -0.0077]],\n",
              "              \n",
              "                       [[-0.0383,  0.0194, -0.0241],\n",
              "                        [-0.0501, -0.0116, -0.0425],\n",
              "                        [-0.0048, -0.0051, -0.0182]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0085, -0.0144, -0.0142],\n",
              "                        [-0.0077, -0.0173,  0.0007],\n",
              "                        [-0.0109,  0.0034,  0.0057]],\n",
              "              \n",
              "                       [[-0.0252, -0.0141,  0.0206],\n",
              "                        [ 0.0348,  0.0523,  0.0599],\n",
              "                        [-0.0141, -0.0059, -0.0084]],\n",
              "              \n",
              "                       [[-0.0138, -0.0401,  0.0025],\n",
              "                        [-0.0185, -0.0434, -0.0139],\n",
              "                        [-0.0401, -0.0576, -0.0318]]]], device='cuda:0')),\n",
              "             ('layer3.1.bn2.weight',\n",
              "              tensor([0.1946, 0.1805, 0.1246, 0.1848, 0.1808, 0.1081, 0.2313, 0.1891, 0.1537,\n",
              "                      0.1008, 0.0626, 0.1124, 0.3253, 0.2058, 0.3334, 0.2275, 0.2839, 0.2810,\n",
              "                      0.3326, 0.3305, 0.3150, 0.5383, 0.2853, 0.3353, 0.2206, 0.2493, 0.2433,\n",
              "                      0.5223, 0.1001, 0.3391, 0.1686, 0.1700, 0.1894, 0.0728, 0.1955, 0.2397,\n",
              "                      0.2023, 0.0610, 0.1062, 0.1112, 0.2421, 0.2068, 0.0595, 0.1427, 0.2070,\n",
              "                      0.0548, 0.1144, 0.2112, 0.2291, 0.2710, 0.1419, 0.3581, 0.1585, 0.2265,\n",
              "                      0.1787, 0.2124, 0.1641, 0.1183, 0.2730, 0.1733, 0.1321, 0.0724, 0.2362,\n",
              "                      0.2311, 0.2524, 0.2435, 0.5105, 0.2155, 0.0636, 0.2848, 0.1948, 0.0882,\n",
              "                      0.1176, 0.2011, 0.2730, 0.1560, 0.1901, 0.3295, 0.1077, 0.1652, 0.2609,\n",
              "                      0.1215, 0.2859, 0.2985, 0.2284, 0.1090, 0.4557, 0.2088, 0.3473, 0.1252,\n",
              "                      0.0720, 0.2381, 0.3197, 0.1215, 0.2431, 0.0793, 0.2521, 0.1773, 0.1334,\n",
              "                      0.1895, 0.4843, 0.2968, 0.1417, 0.0870, 0.0725, 0.2097, 0.1156, 0.3114,\n",
              "                      0.5917, 0.0586, 0.0917, 0.0299, 0.4106, 0.3287, 0.3983, 0.1290, 0.2193,\n",
              "                      0.5465, 0.3232, 0.2959, 0.4274, 0.2169, 0.3537, 0.2127, 0.2722, 0.1143,\n",
              "                      0.2857, 0.2481, 0.4951, 0.0760, 0.1406, 0.1723, 0.1753, 0.2148, 0.1404,\n",
              "                      0.3738, 0.0836, 0.5119, 0.2105, 0.1945, 0.0903, 0.5038, 0.1517, 0.1640,\n",
              "                      0.4270, 0.3569, 0.2129, 0.2487, 0.1415, 0.4890, 0.3982, 0.0748, 0.0311,\n",
              "                      0.3995, 0.2756, 0.3944, 0.1465, 0.1329, 0.2575, 0.0764, 0.2106, 0.2245,\n",
              "                      0.2131, 0.4362, 0.2782, 0.2735, 0.3440, 0.4500, 0.2934, 0.3798, 0.5427,\n",
              "                      0.0326, 0.3047, 0.3099, 0.2124, 0.3708, 0.2163, 0.2577, 0.3496, 0.3048,\n",
              "                      0.3405, 0.4781, 0.3304, 0.3639, 0.2783, 0.2372, 0.1781, 0.3941, 0.5066,\n",
              "                      0.3654, 0.1676, 0.1496, 0.2335, 0.2128, 0.1288, 0.1313, 0.3820, 0.1016,\n",
              "                      0.3562, 0.4216, 0.4114, 0.2286, 0.1729, 0.3207, 0.3802, 0.5561, 0.1892,\n",
              "                      0.2632, 0.1217, 0.2188, 0.0930, 0.2199, 0.0565, 0.2702, 0.4967, 0.3449,\n",
              "                      0.2299, 0.0944, 0.2212, 0.2427, 0.2814, 0.2242, 0.1747, 0.3150, 0.2800,\n",
              "                      0.3727, 0.3809, 0.1783, 0.1906, 0.3859, 0.1477, 0.3720, 0.2507, 0.2573,\n",
              "                      0.2708, 0.0637, 0.1587, 0.1895, 0.0829, 0.1818, 0.1227, 0.2559, 0.2605,\n",
              "                      0.0727, 0.1188, 0.2046, 0.3860, 0.2418, 0.6236, 0.0986, 0.3209, 0.1899,\n",
              "                      0.3626, 0.2690, 0.1921, 0.2422], device='cuda:0')),\n",
              "             ('layer3.1.bn2.bias',\n",
              "              tensor([-0.0123, -0.2184,  0.0214, -0.1475, -0.1873, -0.0016, -0.2065, -0.1555,\n",
              "                      -0.0536, -0.0768, -0.0522, -0.0729, -0.0463, -0.2114, -0.2841,  0.1363,\n",
              "                      -0.3188, -0.1148, -0.1694, -0.1247, -0.2561, -0.2814, -0.1157, -0.2810,\n",
              "                      -0.2240, -0.3807, -0.0762, -0.3538,  0.0528, -0.1427, -0.1005, -0.1452,\n",
              "                       0.0147,  0.0090, -0.1708, -0.2555, -0.2387,  0.0683, -0.0069, -0.1062,\n",
              "                      -0.2712, -0.1855, -0.0066, -0.1220, -0.2030, -0.0059,  0.0059, -0.1532,\n",
              "                      -0.3390, -0.2338, -0.1481, -0.3574,  0.1996,  0.0926, -0.1615, -0.2238,\n",
              "                       0.0323,  0.0382, -0.1098,  0.1008,  0.1024, -0.0166, -0.2645, -0.1575,\n",
              "                      -0.1861, -0.2373, -0.4405, -0.3119, -0.0099, -0.2606, -0.1410,  0.0344,\n",
              "                      -0.0573, -0.1340, -0.2916,  0.0044, -0.2013, -0.2370, -0.1359, -0.1294,\n",
              "                      -0.1974, -0.0970, -0.1822, -0.1571, -0.2785,  0.1315, -0.4762, -0.2097,\n",
              "                      -0.2233,  0.1889,  0.0192, -0.3312, -0.3225, -0.1475, -0.0834,  0.0070,\n",
              "                      -0.2513, -0.0104, -0.0264, -0.1196, -0.4909, -0.2480, -0.1361, -0.0431,\n",
              "                      -0.0306, -0.2839, -0.0289, -0.1923, -0.3200, -0.0383, -0.0936,  0.0261,\n",
              "                      -0.2092, -0.2552, -0.3387, -0.0764, -0.1696, -0.1602, -0.3096, -0.0001,\n",
              "                      -0.1565, -0.1759, -0.3116, -0.2351, -0.1983, -0.0572, -0.0699, -0.1561,\n",
              "                      -0.5334, -0.1932, -0.1164, -0.2421, -0.0420, -0.1621, -0.1467, -0.2551,\n",
              "                      -0.0346, -0.6505, -0.1236, -0.2041,  0.0242, -0.5247, -0.2081, -0.1427,\n",
              "                      -0.1671, -0.3143,  0.0950, -0.1404, -0.2227, -0.5339, -0.2644, -0.0388,\n",
              "                       0.0497, -0.3078, -0.1610, -0.2331, -0.1108, -0.0906,  0.0187,  0.0977,\n",
              "                      -0.2280, -0.2001,  0.1027,  0.0124, -0.2375, -0.3297, -0.1430, -0.4916,\n",
              "                      -0.3444, -0.1367, -0.6900,  0.0501, -0.2738, -0.0831, -0.2377, -0.1713,\n",
              "                      -0.1782, -0.0279, -0.2974, -0.1884, -0.1471, -0.3016, -0.2678, -0.4207,\n",
              "                      -0.2506, -0.1770, -0.1776, -0.2673, -0.0923, -0.2295, -0.1382, -0.1088,\n",
              "                       0.0645, -0.1401, -0.1250, -0.1559, -0.0085, -0.0183, -0.2044,  0.0619,\n",
              "                      -0.2070, -0.2791, -0.0906, -0.4088, -0.3326, -0.7383,  0.0198, -0.1897,\n",
              "                       0.0713, -0.2372,  0.0067, -0.3260,  0.0188, -0.2999, -0.5170, -0.2212,\n",
              "                      -0.0822, -0.0731, -0.1160, -0.2029,  0.0340, -0.1760, -0.2015, -0.2959,\n",
              "                      -0.3064, -0.2964, -0.4863, -0.1854, -0.1704, -0.3418, -0.0604, -0.0972,\n",
              "                      -0.2982, -0.0748, -0.3397, -0.0842, -0.1297, -0.1510,  0.0162, -0.0475,\n",
              "                      -0.0584, -0.2571, -0.1466,  0.0413, -0.0453, -0.1475, -0.3383, -0.1813,\n",
              "                      -0.6356, -0.0929, -0.2001, -0.1391, -0.0376, -0.2458, -0.0208, -0.2090],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.1.bn2.running_mean',\n",
              "              tensor([-0.0786, -0.0008, -0.0352, -0.0013, -0.0417, -0.1011, -0.0515, -0.0836,\n",
              "                       0.0614,  0.0122, -0.0407,  0.0394, -0.0480, -0.0659, -0.1425,  0.2073,\n",
              "                      -0.0665, -0.1125, -0.1828, -0.0614, -0.0882, -0.6599, -0.0799, -0.1754,\n",
              "                      -0.0417, -0.0952, -0.1998, -0.1762,  0.1419, -0.2512, -0.0186, -0.0721,\n",
              "                      -0.0147,  0.0615, -0.0915, -0.1138, -0.0512,  0.0828,  0.0718, -0.0399,\n",
              "                      -0.0643, -0.0585,  0.0133, -0.0350,  0.0096, -0.0394, -0.0394, -0.0984,\n",
              "                      -0.1276, -0.0836, -0.1066, -0.1893,  0.0256,  0.4732,  0.0534, -0.0655,\n",
              "                      -0.0843, -0.0154, -0.0119, -0.0150,  0.0451, -0.0331, -0.1473, -0.0677,\n",
              "                      -0.1193, -0.0339, -0.0988, -0.0470, -0.0348, -0.1511,  0.0699, -0.0432,\n",
              "                      -0.0040, -0.0600, -0.0519, -0.1284, -0.0589, -0.2081, -0.0841,  0.0349,\n",
              "                       0.1314,  0.0206, -0.0836, -0.2310, -0.1084,  0.0109, -0.2732, -0.1372,\n",
              "                      -0.1048,  0.1241, -0.0641, -0.0770, -0.0837,  0.0222, -0.1286,  0.0426,\n",
              "                      -0.1233, -0.0166, -0.0271, -0.1422, -0.2095,  0.0520, -0.0170, -0.0002,\n",
              "                      -0.0542, -0.0584, -0.0803, -0.0856, -0.0717, -0.0521, -0.0346, -0.0444,\n",
              "                      -0.1798, -0.1486, -0.1658, -0.1447, -0.1349, -0.2710, -0.0889, -0.3640,\n",
              "                      -0.2361, -0.0862, -0.3405, -0.1731, -0.1068, -0.1253, -0.0693, -0.1104,\n",
              "                      -0.2196,  0.0632, -0.0093, -0.0690, -0.0194, -0.0649, -0.0275, -0.1438,\n",
              "                       0.0032, -0.1730, -0.1347,  0.0292, -0.0682, -0.2668, -0.0867, -0.0169,\n",
              "                      -0.4570, -0.0746, -0.1000, -0.1248, -0.0581, -0.1968, -0.1254,  0.0165,\n",
              "                      -0.0459, -0.2078, -0.1359, -0.1595, -0.1305,  0.1214, -0.0808,  0.0633,\n",
              "                      -0.0533, -0.0524,  0.0067, -0.4850, -0.0502, -0.0815, -0.2358, -0.2091,\n",
              "                      -0.1322, -0.2666, -0.2172, -0.0424, -0.1632, -0.1927, -0.0103, -0.1195,\n",
              "                      -0.0735, -0.0041, -0.1430, -0.1036, -0.3922,  0.4496, -0.0090, -0.1776,\n",
              "                      -0.2019,  0.0574, -0.0245, -0.1168, -0.2986, -0.2022,  0.0702,  0.0378,\n",
              "                      -0.0394, -0.0745, -0.0203, -0.0550, -0.3405,  0.0130, -0.1602, -0.1622,\n",
              "                      -0.3481, -0.1175, -0.0094, -0.1743, -0.1154, -0.2893, -0.0444, -0.0538,\n",
              "                       0.0050, -0.0479, -0.0828, -0.0240,  0.0104, -0.1032, -0.1844, -0.2019,\n",
              "                      -0.1587,  0.0079, -0.1255, -0.0287, -0.3438, -0.0089, -0.0587, -0.1114,\n",
              "                      -0.1008, -0.2143, -0.1063, -0.0257, -0.0861, -0.1963, -0.0637, -0.4065,\n",
              "                      -0.1362, -0.1986, -0.1748,  0.0022, -0.0662, -0.0410, -0.0651, -0.0162,\n",
              "                       0.1139, -0.1443, -0.1298, -0.0556, -0.0295, -0.1760, -0.1059, -0.1590,\n",
              "                      -0.3272, -0.0287, -0.1091, -0.0850, -0.2852, -0.0487, -0.1243, -0.1369],\n",
              "                     device='cuda:0')),\n",
              "             ('layer3.1.bn2.running_var',\n",
              "              tensor([0.0174, 0.0325, 0.0143, 0.0161, 0.0188, 0.0157, 0.0171, 0.0230, 0.0184,\n",
              "                      0.0123, 0.0131, 0.0111, 0.0396, 0.0250, 0.0268, 0.0252, 0.0278, 0.0177,\n",
              "                      0.0276, 0.0438, 0.0227, 0.0806, 0.0419, 0.0267, 0.0125, 0.0229, 0.0192,\n",
              "                      0.0346, 0.0191, 0.0304, 0.0147, 0.0138, 0.0211, 0.0113, 0.0220, 0.0205,\n",
              "                      0.0153, 0.0163, 0.0123, 0.0107, 0.0285, 0.0192, 0.0095, 0.0154, 0.0134,\n",
              "                      0.0129, 0.0115, 0.0283, 0.0185, 0.0188, 0.0150, 0.0170, 0.0304, 0.0341,\n",
              "                      0.0177, 0.0238, 0.0169, 0.0124, 0.0257, 0.0397, 0.0192, 0.0161, 0.0149,\n",
              "                      0.0252, 0.0297, 0.0161, 0.0360, 0.0194, 0.0139, 0.0248, 0.0263, 0.0195,\n",
              "                      0.0111, 0.0217, 0.0161, 0.0299, 0.0135, 0.0314, 0.0134, 0.0137, 0.0262,\n",
              "                      0.0194, 0.0177, 0.0282, 0.0213, 0.0205, 0.0278, 0.0140, 0.0373, 0.0476,\n",
              "                      0.0112, 0.0161, 0.0237, 0.0187, 0.0267, 0.0200, 0.0203, 0.0233, 0.0232,\n",
              "                      0.0262, 0.0312, 0.0241, 0.0113, 0.0173, 0.0170, 0.0150, 0.0182, 0.0180,\n",
              "                      0.0546, 0.0135, 0.0163, 0.0058, 0.0340, 0.0196, 0.0263, 0.0158, 0.0188,\n",
              "                      0.0604, 0.0273, 0.0402, 0.0555, 0.0284, 0.0322, 0.0198, 0.0236, 0.0115,\n",
              "                      0.0367, 0.0202, 0.0312, 0.0117, 0.0108, 0.0115, 0.0240, 0.0202, 0.0101,\n",
              "                      0.0225, 0.0081, 0.0288, 0.0204, 0.0166, 0.0143, 0.0226, 0.0165, 0.0157,\n",
              "                      0.0470, 0.0361, 0.0268, 0.0214, 0.0099, 0.0234, 0.0401, 0.0096, 0.0103,\n",
              "                      0.0358, 0.0215, 0.0493, 0.0254, 0.0154, 0.0513, 0.0125, 0.0171, 0.0187,\n",
              "                      0.0233, 0.0750, 0.0200, 0.0204, 0.0263, 0.0294, 0.0195, 0.0465, 0.0322,\n",
              "                      0.0068, 0.0200, 0.0234, 0.0191, 0.0271, 0.0187, 0.0309, 0.0243, 0.0234,\n",
              "                      0.0361, 0.0599, 0.0206, 0.0234, 0.0158, 0.0189, 0.0353, 0.0497, 0.0793,\n",
              "                      0.0367, 0.0270, 0.0189, 0.0297, 0.0227, 0.0168, 0.0135, 0.0437, 0.0150,\n",
              "                      0.0253, 0.0605, 0.0564, 0.0138, 0.0216, 0.0169, 0.0213, 0.0358, 0.0250,\n",
              "                      0.0277, 0.0127, 0.0284, 0.0121, 0.0171, 0.0103, 0.0258, 0.0328, 0.0303,\n",
              "                      0.0402, 0.0184, 0.0200, 0.0153, 0.0326, 0.0324, 0.0215, 0.0237, 0.0138,\n",
              "                      0.0213, 0.0195, 0.0129, 0.0219, 0.0383, 0.0162, 0.0337, 0.0169, 0.0270,\n",
              "                      0.0224, 0.0204, 0.0131, 0.0124, 0.0129, 0.0205, 0.0136, 0.0129, 0.0261,\n",
              "                      0.0132, 0.0200, 0.0176, 0.0291, 0.0254, 0.0502, 0.0085, 0.0314, 0.0153,\n",
              "                      0.0418, 0.0191, 0.0210, 0.0197], device='cuda:0')),\n",
              "             ('layer3.1.bn2.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('layer4.0.conv1.weight', tensor([[[[-0.0107, -0.0176, -0.0198],\n",
              "                        [ 0.0239,  0.0290,  0.0351],\n",
              "                        [ 0.0447,  0.0397,  0.0543]],\n",
              "              \n",
              "                       [[-0.0078,  0.0024, -0.0044],\n",
              "                        [ 0.0059,  0.0135, -0.0052],\n",
              "                        [-0.0057,  0.0105,  0.0003]],\n",
              "              \n",
              "                       [[ 0.0174, -0.0081, -0.0127],\n",
              "                        [ 0.0077, -0.0004, -0.0101],\n",
              "                        [-0.0067, -0.0280, -0.0099]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0152,  0.0172,  0.0009],\n",
              "                        [ 0.0015,  0.0089,  0.0120],\n",
              "                        [ 0.0193,  0.0097,  0.0040]],\n",
              "              \n",
              "                       [[ 0.0220,  0.0185,  0.0224],\n",
              "                        [-0.0036,  0.0127,  0.0272],\n",
              "                        [-0.0070,  0.0228,  0.0341]],\n",
              "              \n",
              "                       [[ 0.0235,  0.0200,  0.0419],\n",
              "                        [ 0.0131,  0.0016,  0.0119],\n",
              "                        [-0.0091, -0.0018, -0.0108]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0013, -0.0055,  0.0073],\n",
              "                        [ 0.0165,  0.0156,  0.0317],\n",
              "                        [ 0.0238,  0.0209,  0.0237]],\n",
              "              \n",
              "                       [[-0.0177, -0.0285, -0.0069],\n",
              "                        [-0.0074, -0.0092, -0.0003],\n",
              "                        [-0.0139, -0.0202, -0.0166]],\n",
              "              \n",
              "                       [[-0.0072,  0.0050, -0.0026],\n",
              "                        [-0.0212,  0.0012, -0.0178],\n",
              "                        [-0.0169, -0.0042, -0.0027]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0139, -0.0257, -0.0154],\n",
              "                        [-0.0078, -0.0073, -0.0198],\n",
              "                        [-0.0171, -0.0266, -0.0201]],\n",
              "              \n",
              "                       [[ 0.0053,  0.0071,  0.0054],\n",
              "                        [-0.0071,  0.0047, -0.0063],\n",
              "                        [-0.0011, -0.0080, -0.0167]],\n",
              "              \n",
              "                       [[-0.0001,  0.0080,  0.0026],\n",
              "                        [ 0.0024,  0.0259,  0.0230],\n",
              "                        [ 0.0131,  0.0186,  0.0205]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0055,  0.0081, -0.0000],\n",
              "                        [ 0.0098,  0.0127,  0.0132],\n",
              "                        [ 0.0045,  0.0116,  0.0226]],\n",
              "              \n",
              "                       [[-0.0130,  0.0071,  0.0089],\n",
              "                        [-0.0216, -0.0144, -0.0086],\n",
              "                        [-0.0258, -0.0092, -0.0009]],\n",
              "              \n",
              "                       [[ 0.0290,  0.0172,  0.0079],\n",
              "                        [ 0.0256,  0.0224,  0.0123],\n",
              "                        [-0.0107, -0.0196, -0.0096]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0136,  0.0078,  0.0025],\n",
              "                        [ 0.0145, -0.0078, -0.0066],\n",
              "                        [ 0.0286,  0.0113,  0.0176]],\n",
              "              \n",
              "                       [[ 0.0329,  0.0377,  0.0388],\n",
              "                        [-0.0027,  0.0118,  0.0205],\n",
              "                        [-0.0220, -0.0060,  0.0017]],\n",
              "              \n",
              "                       [[-0.0010,  0.0032,  0.0092],\n",
              "                        [ 0.0063, -0.0005,  0.0139],\n",
              "                        [ 0.0141,  0.0108,  0.0212]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0171, -0.0057, -0.0088],\n",
              "                        [-0.0104,  0.0053,  0.0038],\n",
              "                        [ 0.0154,  0.0184,  0.0189]],\n",
              "              \n",
              "                       [[ 0.0198,  0.0383,  0.0284],\n",
              "                        [ 0.0358,  0.0500,  0.0344],\n",
              "                        [ 0.0299,  0.0459,  0.0406]],\n",
              "              \n",
              "                       [[-0.0045, -0.0074, -0.0019],\n",
              "                        [-0.0066,  0.0162,  0.0047],\n",
              "                        [-0.0072, -0.0038, -0.0128]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0158,  0.0021, -0.0128],\n",
              "                        [-0.0223, -0.0008, -0.0084],\n",
              "                        [-0.0192, -0.0096, -0.0158]],\n",
              "              \n",
              "                       [[-0.0001, -0.0008, -0.0171],\n",
              "                        [ 0.0001,  0.0115,  0.0022],\n",
              "                        [-0.0103, -0.0071, -0.0259]],\n",
              "              \n",
              "                       [[ 0.0182,  0.0127,  0.0174],\n",
              "                        [ 0.0167,  0.0420,  0.0228],\n",
              "                        [ 0.0234,  0.0339,  0.0198]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0116, -0.0125, -0.0220],\n",
              "                        [-0.0200,  0.0024, -0.0029],\n",
              "                        [-0.0179, -0.0012, -0.0058]],\n",
              "              \n",
              "                       [[-0.0071, -0.0019, -0.0018],\n",
              "                        [-0.0124,  0.0025, -0.0154],\n",
              "                        [-0.0082,  0.0012, -0.0029]],\n",
              "              \n",
              "                       [[-0.0142, -0.0233, -0.0022],\n",
              "                        [-0.0227, -0.0277, -0.0184],\n",
              "                        [-0.0101, -0.0152, -0.0081]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0040, -0.0006,  0.0081],\n",
              "                        [-0.0234, -0.0165, -0.0090],\n",
              "                        [-0.0024, -0.0361, -0.0289]],\n",
              "              \n",
              "                       [[ 0.0002,  0.0021,  0.0166],\n",
              "                        [-0.0141, -0.0163, -0.0132],\n",
              "                        [-0.0369, -0.0421, -0.0332]],\n",
              "              \n",
              "                       [[ 0.0213,  0.0020,  0.0006],\n",
              "                        [ 0.0093,  0.0304,  0.0269],\n",
              "                        [ 0.0141,  0.0313,  0.0117]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0152, -0.0325, -0.0296],\n",
              "                        [-0.0196, -0.0043, -0.0022],\n",
              "                        [-0.0224, -0.0141,  0.0043]],\n",
              "              \n",
              "                       [[-0.0157, -0.0364, -0.0269],\n",
              "                        [-0.0277, -0.0282, -0.0092],\n",
              "                        [-0.0245, -0.0077,  0.0233]],\n",
              "              \n",
              "                       [[-0.0129, -0.0049,  0.0030],\n",
              "                        [ 0.0011, -0.0039, -0.0252],\n",
              "                        [-0.0011, -0.0232, -0.0206]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0173,  0.0194, -0.0005],\n",
              "                        [-0.0183,  0.0051, -0.0099],\n",
              "                        [ 0.0054,  0.0242,  0.0198]],\n",
              "              \n",
              "                       [[-0.0257, -0.0127, -0.0382],\n",
              "                        [-0.0234, -0.0212, -0.0052],\n",
              "                        [-0.0537,  0.0021,  0.0558]],\n",
              "              \n",
              "                       [[ 0.0236,  0.0037,  0.0027],\n",
              "                        [ 0.0165,  0.0041,  0.0290],\n",
              "                        [ 0.0020,  0.0172,  0.0009]]]], device='cuda:0')),\n",
              "             ('layer4.0.bn1.weight',\n",
              "              tensor([0.2190, 0.2275, 0.2220, 0.2548, 0.1847, 0.3081, 0.2550, 0.2992, 0.2762,\n",
              "                      0.2979, 0.2494, 0.1377, 0.2553, 0.2901, 0.2295, 0.2789, 0.3226, 0.2882,\n",
              "                      0.2485, 0.2670, 0.2380, 0.2927, 0.3106, 0.2681, 0.2519, 0.2765, 0.3239,\n",
              "                      0.2593, 0.2585, 0.2707, 0.3004, 0.2935, 0.2273, 0.3358, 0.2628, 0.2959,\n",
              "                      0.3354, 0.2962, 0.1952, 0.2553, 0.1742, 0.2965, 0.2852, 0.2184, 0.2909,\n",
              "                      0.2579, 0.2693, 0.2632, 0.2676, 0.2717, 0.2465, 0.2860, 0.3008, 0.2613,\n",
              "                      0.2943, 0.2643, 0.2717, 0.3294, 0.2282, 0.2846, 0.2732, 0.1793, 0.2703,\n",
              "                      0.2598, 0.2147, 0.2561, 0.2706, 0.2569, 0.2032, 0.3154, 0.2852, 0.2864,\n",
              "                      0.2128, 0.2617, 0.2982, 0.2261, 0.3295, 0.3021, 0.2585, 0.3013, 0.1641,\n",
              "                      0.2694, 0.2566, 0.2666, 0.2279, 0.2711, 0.2858, 0.2843, 0.2772, 0.2865,\n",
              "                      0.2337, 0.2004, 0.2952, 0.3784, 0.2122, 0.2739, 0.2445, 0.2846, 0.2592,\n",
              "                      0.2510, 0.3247, 0.2629, 0.2639, 0.2678, 0.2284, 0.2559, 0.2618, 0.2653,\n",
              "                      0.2850, 0.2361, 0.2368, 0.2328, 0.2584, 0.2930, 0.3365, 0.2440, 0.1942,\n",
              "                      0.3153, 0.2776, 0.2795, 0.3091, 0.2562, 0.4028, 0.2858, 0.2153, 0.2199,\n",
              "                      0.3014, 0.3406, 0.3560, 0.2458, 0.2486, 0.2574, 0.2665, 0.2587, 0.2942,\n",
              "                      0.2648, 0.2591, 0.2640, 0.1965, 0.2773, 0.3090, 0.2858, 0.2554, 0.2450,\n",
              "                      0.2289, 0.2087, 0.3045, 0.2259, 0.2788, 0.2432, 0.2981, 0.3128, 0.2826,\n",
              "                      0.1819, 0.3077, 0.2478, 0.2945, 0.2528, 0.2971, 0.2480, 0.2583, 0.2829,\n",
              "                      0.2636, 0.2692, 0.3069, 0.2653, 0.2996, 0.3330, 0.2792, 0.2859, 0.1859,\n",
              "                      0.2717, 0.3131, 0.2819, 0.2792, 0.2858, 0.2420, 0.2473, 0.2744, 0.2491,\n",
              "                      0.2684, 0.3121, 0.2282, 0.2544, 0.2905, 0.2631, 0.2307, 0.2660, 0.2704,\n",
              "                      0.2930, 0.2569, 0.2589, 0.3074, 0.2136, 0.3050, 0.2983, 0.2607, 0.3142,\n",
              "                      0.3246, 0.2653, 0.2040, 0.1924, 0.2348, 0.2511, 0.2766, 0.2735, 0.2582,\n",
              "                      0.2620, 0.2666, 0.3311, 0.3254, 0.2874, 0.2515, 0.3060, 0.2520, 0.2959,\n",
              "                      0.2684, 0.2338, 0.2028, 0.1855, 0.2889, 0.2079, 0.2508, 0.2739, 0.2516,\n",
              "                      0.2958, 0.2993, 0.2366, 0.2766, 0.2490, 0.2997, 0.2404, 0.2667, 0.2851,\n",
              "                      0.2950, 0.2325, 0.2970, 0.2569, 0.2506, 0.2708, 0.2747, 0.2317, 0.2352,\n",
              "                      0.2982, 0.2605, 0.2792, 0.2817, 0.2752, 0.2691, 0.2496, 0.2989, 0.2199,\n",
              "                      0.3089, 0.2673, 0.2975, 0.2863, 0.2404, 0.2755, 0.3372, 0.3023, 0.2086,\n",
              "                      0.3276, 0.2997, 0.2535, 0.2607, 0.2740, 0.2483, 0.2327, 0.2369, 0.2409,\n",
              "                      0.2687, 0.2512, 0.2779, 0.2964, 0.3093, 0.3103, 0.2900, 0.2769, 0.2373,\n",
              "                      0.2560, 0.2291, 0.3538, 0.2672, 0.2578, 0.2952, 0.2274, 0.3021, 0.3067,\n",
              "                      0.2386, 0.2831, 0.2353, 0.2680, 0.2469, 0.2469, 0.2507, 0.2881, 0.2935,\n",
              "                      0.2731, 0.2847, 0.2375, 0.3723, 0.3148, 0.2632, 0.1986, 0.2563, 0.2900,\n",
              "                      0.2353, 0.2609, 0.2328, 0.2247, 0.3119, 0.1797, 0.2214, 0.2212, 0.2969,\n",
              "                      0.2508, 0.2693, 0.2965, 0.2600, 0.2659, 0.2600, 0.3185, 0.2202, 0.3115,\n",
              "                      0.2788, 0.2860, 0.3329, 0.3255, 0.2733, 0.3057, 0.3074, 0.2454, 0.2923,\n",
              "                      0.3524, 0.3403, 0.2277, 0.2248, 0.2456, 0.2574, 0.2998, 0.2765, 0.2943,\n",
              "                      0.2935, 0.2757, 0.3290, 0.2645, 0.2420, 0.2562, 0.3243, 0.3241, 0.3089,\n",
              "                      0.2901, 0.3334, 0.2672, 0.3116, 0.2740, 0.2936, 0.3171, 0.2162, 0.1905,\n",
              "                      0.2543, 0.3277, 0.2903, 0.2997, 0.2847, 0.2448, 0.2847, 0.1528, 0.3025,\n",
              "                      0.3312, 0.2343, 0.2319, 0.2210, 0.2623, 0.2684, 0.2365, 0.2961, 0.2274,\n",
              "                      0.2828, 0.2618, 0.2147, 0.2547, 0.2366, 0.2880, 0.2465, 0.2432, 0.2248,\n",
              "                      0.3127, 0.2707, 0.3179, 0.2071, 0.3167, 0.2631, 0.3357, 0.3628, 0.2902,\n",
              "                      0.2152, 0.2153, 0.2730, 0.3348, 0.2518, 0.2610, 0.2393, 0.2452, 0.2552,\n",
              "                      0.2400, 0.3273, 0.2099, 0.2505, 0.2539, 0.2605, 0.2732, 0.2276, 0.2739,\n",
              "                      0.2780, 0.2704, 0.3074, 0.2767, 0.3821, 0.2475, 0.3316, 0.3078, 0.2211,\n",
              "                      0.2355, 0.2312, 0.2589, 0.2355, 0.2550, 0.2967, 0.2295, 0.2735, 0.2807,\n",
              "                      0.2912, 0.2005, 0.2630, 0.2353, 0.2791, 0.2507, 0.3150, 0.2864, 0.2802,\n",
              "                      0.2395, 0.3002, 0.2855, 0.2910, 0.2385, 0.3139, 0.3385, 0.2468, 0.2762,\n",
              "                      0.3063, 0.3233, 0.3426, 0.2415, 0.2516, 0.2041, 0.2335, 0.2525, 0.2920,\n",
              "                      0.3561, 0.3229, 0.2769, 0.4535, 0.2820, 0.2888, 0.2518, 0.2870, 0.2735,\n",
              "                      0.3554, 0.2149, 0.2629, 0.2253, 0.1832, 0.2067, 0.2361, 0.2458, 0.3829,\n",
              "                      0.2711, 0.2884, 0.2096, 0.2429, 0.1636, 0.2817, 0.2629, 0.2695, 0.2412,\n",
              "                      0.2657, 0.2683, 0.2089, 0.2830, 0.2646, 0.2810, 0.2442, 0.2639, 0.2878,\n",
              "                      0.2645, 0.2390, 0.2398, 0.2604, 0.1767, 0.2779, 0.3731, 0.2511, 0.2722,\n",
              "                      0.1844, 0.3262, 0.2363, 0.3603, 0.2569, 0.2970, 0.2646, 0.2734],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.bn1.bias',\n",
              "              tensor([-0.2143, -0.1544, -0.2248, -0.1453, -0.1365, -0.3049, -0.1572, -0.3497,\n",
              "                      -0.2403, -0.2687, -0.2178, -0.0342, -0.1890, -0.2745, -0.1799, -0.2243,\n",
              "                      -0.3794, -0.2701, -0.2311, -0.2637, -0.1535, -0.2691, -0.3488, -0.2470,\n",
              "                      -0.1658, -0.2160, -0.3329, -0.2143, -0.1556, -0.2908, -0.1562, -0.3505,\n",
              "                      -0.2188, -0.2693, -0.2589, -0.1951, -0.2329, -0.2285, -0.0880, -0.3674,\n",
              "                      -0.1479, -0.2376, -0.2411, -0.1714, -0.3153, -0.1249, -0.2493, -0.1948,\n",
              "                      -0.1650, -0.0735, -0.1592, -0.1875, -0.2192, -0.1133, -0.2396, -0.1977,\n",
              "                      -0.2873, -0.3391, -0.1455, -0.2273, -0.2455,  0.0076, -0.2092, -0.1491,\n",
              "                      -0.1455, -0.1959, -0.2034, -0.0561, -0.2277, -0.3728, -0.2438, -0.3795,\n",
              "                      -0.1747, -0.2274, -0.2813, -0.1784, -0.3959, -0.0984, -0.2678, -0.2334,\n",
              "                      -0.1049, -0.3112, -0.2716, -0.3447, -0.2622, -0.1734, -0.2819, -0.2169,\n",
              "                      -0.3762, -0.2798, -0.2648, -0.1180, -0.3328, -0.2443, -0.1686, -0.2606,\n",
              "                      -0.2031, -0.2553, -0.1939, -0.1211, -0.4103, -0.1558, -0.2561, -0.3046,\n",
              "                      -0.2254, -0.1859, -0.1870, -0.3180, -0.3448, -0.1856, -0.2009, -0.0315,\n",
              "                      -0.2246, -0.3469, -0.1988, -0.3457, -0.1526, -0.1862, -0.1409, -0.1921,\n",
              "                      -0.3135, -0.0792, -0.4193, -0.2207, -0.1450, -0.1533, -0.3515, -0.3433,\n",
              "                      -0.2968, -0.2336, -0.2844, -0.1860, -0.1908, -0.1314, -0.2384, -0.2323,\n",
              "                      -0.1021, -0.2198, -0.1253, -0.2372, -0.2381, -0.2531, -0.1869, -0.0994,\n",
              "                      -0.1722, -0.1355, -0.2757, -0.0283, -0.2205, -0.1108, -0.2246, -0.2428,\n",
              "                      -0.2028, -0.1976, -0.2887, -0.2700, -0.3364, -0.1713, -0.2373, -0.1336,\n",
              "                      -0.2807, -0.1843, -0.2734, -0.1909, -0.3474, -0.1761, -0.2716, -0.3193,\n",
              "                      -0.3062, -0.2125, -0.1219, -0.2461, -0.2288, -0.2489, -0.3223, -0.2184,\n",
              "                      -0.2287, -0.2057, -0.1992, -0.1167, -0.1121, -0.2355, -0.1717, -0.2511,\n",
              "                      -0.2455, -0.2238, -0.1708, -0.1751, -0.2393, -0.1803, -0.2239, -0.2916,\n",
              "                      -0.2860, -0.1414, -0.0682, -0.2090, -0.2400, -0.3279, -0.2449, -0.1426,\n",
              "                      -0.1496, -0.2793, -0.1858, -0.2787, -0.3198, -0.2940, -0.2624, -0.2045,\n",
              "                      -0.1964, -0.4444, -0.2817, -0.3055, -0.2358, -0.3069, -0.2706, -0.2633,\n",
              "                      -0.1017, -0.1705, -0.1811, -0.1411, -0.2193, -0.2096, -0.1452, -0.2614,\n",
              "                      -0.1977, -0.1536, -0.2260, -0.1961, -0.2114, -0.1890, -0.2914, -0.1614,\n",
              "                      -0.2078, -0.2648, -0.2626, -0.2525, -0.1034, -0.2504, -0.2765, -0.2363,\n",
              "                      -0.1557, -0.0807, -0.1602, -0.2182, -0.2083, -0.3409, -0.1163, -0.2348,\n",
              "                      -0.1474, -0.1555, -0.1469, -0.1803, -0.2205, -0.2726, -0.2156, -0.1846,\n",
              "                      -0.2235, -0.2196, -0.2647, -0.3253,  0.1799, -0.4957, -0.2403, -0.1477,\n",
              "                      -0.1195, -0.3114, -0.2342, -0.1829, -0.1751, -0.2134, -0.2296, -0.1998,\n",
              "                      -0.2977, -0.2538, -0.3398, -0.1987, -0.2691, -0.2891, -0.1776, -0.2219,\n",
              "                      -0.0882, -0.3504, -0.3042, -0.1602, -0.1983, -0.1724, -0.2877, -0.2842,\n",
              "                      -0.1602, -0.2574, -0.1995, -0.1587, -0.1732, -0.1503, -0.3891, -0.1864,\n",
              "                      -0.1517, -0.1773, -0.2566, -0.2129, -0.1856, -0.2016, -0.3206, -0.2132,\n",
              "                      -0.1719, -0.3676, -0.1365, -0.1365, -0.1897, -0.0491, -0.1876, -0.1591,\n",
              "                      -0.1332, -0.1522, -0.2238, -0.1705, -0.1430, -0.2475, -0.2797, -0.3098,\n",
              "                      -0.1261, -0.1937, -0.2824, -0.3588, -0.2154, -0.2754, -0.3777, -0.3310,\n",
              "                      -0.4123, -0.1747, -0.2824, -0.2444, -0.2906, -0.4425, -0.3243, -0.1765,\n",
              "                      -0.2043, -0.1482, -0.2016, -0.2423, -0.1659, -0.2686, -0.2743, -0.2469,\n",
              "                      -0.3018, -0.2416, -0.2355, -0.1816, -0.1936, -0.4353, -0.2956, -0.2460,\n",
              "                      -0.3653, -0.1749, -0.2126, -0.2409, -0.1834, -0.2083, -0.1939, -0.0731,\n",
              "                      -0.1448, -0.3278, -0.4223, -0.3093, -0.2675, -0.1179, -0.3121, -0.0020,\n",
              "                      -0.1689, -0.3055, -0.1939, -0.0750, -0.1724, -0.1556, -0.1067, -0.2361,\n",
              "                      -0.3151, -0.1757, -0.2436, -0.2337, -0.0911, -0.1753, -0.2811, -0.2052,\n",
              "                      -0.2442, -0.2780, -0.1770, -0.3288, -0.1492, -0.3342,  0.0642, -0.2417,\n",
              "                      -0.3258, -0.3752, -0.2537, -0.2403, -0.2132, -0.1549, -0.2201, -0.3219,\n",
              "                      -0.1576, -0.1107, -0.1596, -0.1494, -0.3053, -0.2335, -0.3406, -0.0373,\n",
              "                      -0.0921, -0.2270, -0.2789, -0.1928, -0.0791, -0.1703, -0.3151, -0.2886,\n",
              "                      -0.2971, -0.2064, -0.3053, -0.1762, -0.0891, -0.1339, -0.1863, -0.1181,\n",
              "                      -0.2398, -0.2151, -0.2831, -0.2340, -0.2315, -0.1692, -0.2091, -0.2648,\n",
              "                      -0.2974, -0.1083, -0.2565, -0.1048, -0.2145, -0.2367, -0.2733, -0.2298,\n",
              "                      -0.3696, -0.2449, -0.2125, -0.2010, -0.2228, -0.1309, -0.1850, -0.2618,\n",
              "                      -0.2095, -0.1840, -0.1861, -0.3868, -0.2484, -0.2533, -0.1241, -0.1038,\n",
              "                      -0.1587, -0.2164, -0.2965, -0.2626, -0.2526, -0.2502, -0.3507, -0.2751,\n",
              "                      -0.3261, -0.1756, -0.2994, -0.4104, -0.2204, -0.1287, -0.1888, -0.1719,\n",
              "                      -0.0669, -0.1895, -0.1305, -0.1954, -0.4487, -0.1140, -0.1783, -0.1461,\n",
              "                      -0.1679,  0.0020, -0.2533, -0.2602, -0.2221, -0.1647, -0.1679, -0.2251,\n",
              "                      -0.2045, -0.2598, -0.1165, -0.2391, -0.1639, -0.1949, -0.2223, -0.1663,\n",
              "                      -0.2713, -0.1872, -0.2365, -0.0599, -0.2826, -0.2631, -0.1225, -0.3743,\n",
              "                      -0.0391, -0.3511, -0.0854, -0.4282, -0.1292, -0.2858, -0.3004, -0.0926],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.bn1.running_mean',\n",
              "              tensor([-0.1589, -0.2249, -0.2236, -0.4528, -0.3302, -0.4454, -0.4836, -0.1920,\n",
              "                      -0.8007, -0.8178, -0.1311, -0.2638, -0.4684, -0.1757, -0.4182, -0.4639,\n",
              "                      -0.5676, -0.4450, -0.2500, -0.2555, -0.3289, -0.5650, -0.9940, -0.4265,\n",
              "                      -0.3225, -0.3706, -0.1976, -0.4749, -0.3604, -0.5784, -0.3073, -0.6578,\n",
              "                      -0.4709, -0.3567, -0.2268, -0.4260, -1.0371,  0.0842, -0.5331, -0.3744,\n",
              "                      -0.5534, -0.8796, -0.5711, -0.5667, -0.3299, -0.4378, -0.7892, -0.4987,\n",
              "                      -0.6432, -1.2557, -0.5113, -0.1768, -0.2742, -0.3054, -0.4599, -0.2951,\n",
              "                      -0.4472, -0.5848, -0.4877, -0.7619, -0.1144,  0.2280,  0.2650, -0.2202,\n",
              "                      -0.4581, -0.3371, -0.3639, -0.4141, -0.1856, -0.7966, -0.7084, -0.3632,\n",
              "                      -0.4993, -0.3844, -0.1555, -0.0438, -1.2017, -1.0067, -0.3458, -0.5712,\n",
              "                      -0.7165, -0.4189, -0.2107, -0.3485, -0.2555, -0.5037, -0.7131, -0.0269,\n",
              "                      -0.3357, -0.1041, -0.1622, -0.2690,  0.2650, -0.7015, -0.5715, -0.5163,\n",
              "                      -0.6006, -0.2482, -0.3626, -0.6415, -0.7952, -0.7094, -0.2413, -0.4958,\n",
              "                      -0.5359, -0.6455, -0.5914, -0.5630, -0.3072, -0.4392, -0.0644, -0.1460,\n",
              "                      -0.3797, -0.0990, -0.3057, -0.0352, -0.1233, -0.1248, -0.5097, -0.3787,\n",
              "                      -0.0473, -0.5403, -1.0765, -0.5711, -0.5230, -0.3845, -0.6518,  0.1650,\n",
              "                      -0.9695,  0.0570,  0.0493, -0.3817, -0.7970, -0.7561, -0.4961, -0.4099,\n",
              "                      -0.5626, -0.3359, -0.6246, -0.4835, -0.5107, -0.3404, -0.1955, -0.0821,\n",
              "                      -0.2978, -0.4526, -0.1051, -0.0430, -0.4213, -0.3716, -0.2314, -0.4274,\n",
              "                      -0.1656, -0.2382, -0.5804, -0.2993, -0.5338, -0.6435, -0.5229, -0.1810,\n",
              "                      -0.2486, -0.5576, -0.6383,  0.0742, -0.7035, -0.5643, -0.2413, -0.6159,\n",
              "                      -0.8465, -0.4989, -0.3669, -0.1227, -0.0677, -0.9234, -0.3701, -0.0993,\n",
              "                      -0.3817, -0.5325, -0.7078, -0.9578, -0.4109, -0.6625, -0.5686, -0.6244,\n",
              "                      -0.2862, -0.4929, -0.1152, -0.0627, -0.1984,  0.0465, -0.2021, -0.5604,\n",
              "                      -0.4312, -0.5432, -0.5973, -0.4187, -0.5016, -0.2656, -0.0109, -1.0846,\n",
              "                      -0.4976, -0.7781, -0.5491, -0.5796, -0.4923, -0.4490, -0.2261, -0.5276,\n",
              "                      -0.3038, -0.7581, -0.8318, -0.6756, -0.4547, -0.1408, -0.6824, -0.6208,\n",
              "                      -0.0601, -0.6436, -0.9121, -0.5545, -0.2606, -0.5334, -0.1734, -0.2376,\n",
              "                      -0.1425, -0.5840, -0.3991, -0.9050, -0.2398, -0.2261, -0.3538, -0.9089,\n",
              "                      -0.5142, -0.1740, -0.4769, -0.4730, -0.6617, -0.5748, -0.5184, -0.4967,\n",
              "                      -0.7357, -0.3800, -0.5727,  0.1519, -0.8869, -0.4917, -0.1592, -0.7559,\n",
              "                      -0.1411, -0.1966, -0.8371, -0.1510, -0.0113, -0.4655,  0.1027, -0.5425,\n",
              "                      -0.3564, -0.5474, -0.6020, -0.5519, -0.2698, -1.0962, -0.5131, -0.3872,\n",
              "                      -0.4569, -0.3839, -0.7668, -0.1774,  0.2292, -0.2795, -0.5497, -0.5065,\n",
              "                      -0.1538, -0.4965, -0.5420, -0.5995, -0.6201, -0.6685, -0.5462, -0.4010,\n",
              "                      -0.6858, -1.0032, -0.5860, -0.3173,  0.4936, -0.4642, -0.4912,  0.1970,\n",
              "                      -0.1055, -0.4492, -0.7182, -0.4242, -0.6319, -0.4688, -0.5477, -0.4833,\n",
              "                       0.0378, -0.8058, -0.2545, -0.4715, -0.5071, -0.1068, -0.5960, -0.3109,\n",
              "                      -0.4491, -0.3561, -0.9511, -0.0092, -0.2633, -0.2781, -0.9234, -0.5382,\n",
              "                      -0.5672, -0.3441, -0.3643, -0.2971, -0.9585, -0.7057, -0.3505,  0.1822,\n",
              "                      -0.5398, -0.9532, -0.8033, -0.6265, -0.0863, -0.4515, -0.6120, -0.2663,\n",
              "                      -0.5898, -0.6739, -0.6445,  0.2042, -0.3906, -0.8651, -0.3492, -0.4743,\n",
              "                      -0.3626, -0.4429, -0.5348, -0.4467, -0.3211, -0.6657, -0.3600, -0.5771,\n",
              "                      -0.3737, -0.8678, -0.7899, -0.7668, -0.5396, -1.0598, -0.4944,  0.1685,\n",
              "                      -1.0686, -0.3299, -0.0581, -0.5854, -0.2969,  0.1701, -0.7969, -0.9223,\n",
              "                      -0.1959, -0.1731, -0.5650, -0.0726, -0.7374, -0.6925, -0.4548, -0.0624,\n",
              "                      -0.8650, -0.4060, -0.1145, -0.0474, -0.1557, -0.3640, -0.8984,  0.1358,\n",
              "                      -0.8367, -0.5718, -0.2251, -0.1932, -0.2617, -0.1940, -0.4910, -0.3362,\n",
              "                      -0.9803, -0.1513, -0.3613,  0.0156, -0.3801, -0.7189, -0.2882, -0.3059,\n",
              "                      -0.4767, -0.8173, -0.3804, -0.6625, -0.3727, -0.1895, -0.3512, -0.3298,\n",
              "                      -0.7694, -0.2002, -0.2561, -0.3699, -0.2607, -0.3593, -0.3324, -0.4717,\n",
              "                      -0.7627, -0.2965, -0.4654, -0.0133, -0.2258, -0.1276, -0.5899, -0.4019,\n",
              "                      -0.0655, -0.2970, -0.7835, -0.4683, -0.9358, -0.2060, -0.2553, -0.1769,\n",
              "                      -0.6175, -0.2301, -0.6947, -0.1977, -0.6862, -0.7732, -0.1665, -0.6802,\n",
              "                      -0.9241, -0.3250, -0.3710, -0.8728, -0.4666, -0.1985, -0.7034, -0.6387,\n",
              "                      -0.2957, -0.4914, -0.7274,  0.1392, -0.6083, -0.6828, -0.4375, -0.3179,\n",
              "                      -0.3689, -0.3685, -0.6221, -0.6664, -0.5664, -0.4938, -0.4145, -0.4052,\n",
              "                      -0.2931, -0.1971, -0.2175, -0.2846, -0.1615, -0.2894, -0.0011, -0.4619,\n",
              "                      -0.4142, -0.5266, -0.4373, -0.8703, -0.2794, -0.2315, -0.4510, -0.2333,\n",
              "                      -0.1390, -0.2720, -0.7559, -0.8772, -0.1841, -0.2696, -0.4667, -0.5151,\n",
              "                      -1.1242,  1.0801, -0.5073, -0.0428, -0.3734, -0.3955, -0.8598, -0.3250,\n",
              "                      -0.5930, -0.4511, -0.6811, -0.3919, -0.7199, -0.3458, -0.6088, -0.3580,\n",
              "                      -0.7040, -0.3833, -0.5441, -0.8921, -0.3249, -0.0105, -0.5185, -0.9184,\n",
              "                      -0.7285, -0.4895, -0.5124, -0.4786, -0.6071, -0.4035, -0.1297, -0.4959],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.bn1.running_var',\n",
              "              tensor([0.1387, 0.1136, 0.2445, 0.1020, 0.1318, 0.1232, 0.1759, 0.1112, 0.1731,\n",
              "                      0.1344, 0.1185, 0.1445, 0.1104, 0.1201, 0.1057, 0.1173, 0.1455, 0.1470,\n",
              "                      0.1335, 0.1369, 0.1152, 0.2116, 0.1914, 0.1260, 0.1327, 0.1234, 0.1177,\n",
              "                      0.1356, 0.1344, 0.1510, 0.1666, 0.1767, 0.1332, 0.2780, 0.1393, 0.1065,\n",
              "                      0.2478, 0.1358, 0.1130, 0.0995, 0.1520, 0.0934, 0.1429, 0.1582, 0.1153,\n",
              "                      0.2252, 0.1124, 0.1299, 0.1545, 0.2768, 0.1080, 0.1298, 0.1439, 0.1491,\n",
              "                      0.1269, 0.1303, 0.1200, 0.0999, 0.1547, 0.1337, 0.1335, 0.3325, 0.1913,\n",
              "                      0.1445, 0.1272, 0.1456, 0.2145, 0.1418, 0.1350, 0.1173, 0.1556, 0.1263,\n",
              "                      0.1445, 0.1265, 0.1638, 0.1185, 0.1277, 0.2578, 0.1064, 0.1531, 0.1540,\n",
              "                      0.1268, 0.1239, 0.1066, 0.1134, 0.1116, 0.1172, 0.1302, 0.1290, 0.2214,\n",
              "                      0.1111, 0.1164, 0.1786, 0.2670, 0.1390, 0.2291, 0.1288, 0.1153, 0.1373,\n",
              "                      0.1267, 0.0995, 0.1807, 0.1623, 0.1088, 0.1178, 0.1342, 0.1793, 0.1467,\n",
              "                      0.0860, 0.1316, 0.1261, 0.1399, 0.1239, 0.1532, 0.3365, 0.0954, 0.1222,\n",
              "                      0.1844, 0.1532, 0.2357, 0.1579, 0.1342, 0.1687, 0.1768, 0.1604, 0.1453,\n",
              "                      0.1494, 0.2282, 0.1293, 0.1530, 0.1597, 0.1445, 0.1545, 0.1873, 0.1553,\n",
              "                      0.1304, 0.1575, 0.1446, 0.1089, 0.1279, 0.1898, 0.1958, 0.1146, 0.1177,\n",
              "                      0.1189, 0.1155, 0.1687, 0.1302, 0.1012, 0.1450, 0.1828, 0.1449, 0.1542,\n",
              "                      0.1283, 0.1072, 0.0814, 0.1290, 0.1404, 0.2709, 0.1606, 0.1153, 0.1455,\n",
              "                      0.1551, 0.1327, 0.1577, 0.1538, 0.1570, 0.1148, 0.1764, 0.1684, 0.1081,\n",
              "                      0.1748, 0.1628, 0.1366, 0.1241, 0.1090, 0.1250, 0.1159, 0.1398, 0.1401,\n",
              "                      0.1792, 0.1574, 0.1470, 0.1416, 0.1936, 0.2058, 0.1496, 0.1681, 0.1369,\n",
              "                      0.1760, 0.1157, 0.1158, 0.1549, 0.1298, 0.2417, 0.2254, 0.1337, 0.1448,\n",
              "                      0.1681, 0.2456, 0.1386, 0.1585, 0.1443, 0.1486, 0.1058, 0.1234, 0.0759,\n",
              "                      0.1277, 0.1445, 0.0940, 0.1376, 0.1344, 0.1345, 0.1341, 0.1823, 0.1872,\n",
              "                      0.0930, 0.1265, 0.1576, 0.0947, 0.1674, 0.1334, 0.1273, 0.1153, 0.1334,\n",
              "                      0.1933, 0.1391, 0.2499, 0.1253, 0.0846, 0.1409, 0.1864, 0.1588, 0.1105,\n",
              "                      0.1308, 0.2126, 0.2099, 0.1468, 0.1758, 0.1084, 0.1664, 0.1237, 0.1050,\n",
              "                      0.1573, 0.1886, 0.1768, 0.1726, 0.1480, 0.1546, 0.1360, 0.2837, 0.1457,\n",
              "                      0.1890, 0.1204, 0.1516, 0.1598, 0.1454, 0.1634, 0.2289, 0.1287, 0.2817,\n",
              "                      0.1390, 0.1104, 0.1514, 0.1624, 0.1492, 0.1228, 0.1749, 0.0920, 0.1500,\n",
              "                      0.1744, 0.1375, 0.1060, 0.1433, 0.1340, 0.1560, 0.1427, 0.1307, 0.1226,\n",
              "                      0.1330, 0.1843, 0.2163, 0.1359, 0.1187, 0.3334, 0.0883, 0.1085, 0.1316,\n",
              "                      0.1928, 0.1077, 0.1329, 0.1588, 0.1188, 0.1811, 0.1107, 0.1957, 0.2207,\n",
              "                      0.2238, 0.1156, 0.1243, 0.1914, 0.2803, 0.1704, 0.1569, 0.1471, 0.0895,\n",
              "                      0.1567, 0.2364, 0.1506, 0.2004, 0.1631, 0.1301, 0.1480, 0.1333, 0.1647,\n",
              "                      0.1342, 0.1710, 0.2023, 0.1443, 0.1048, 0.1275, 0.1458, 0.1241, 0.1741,\n",
              "                      0.1288, 0.1315, 0.1358, 0.1643, 0.1105, 0.2582, 0.1514, 0.1551, 0.1746,\n",
              "                      0.1158, 0.1207, 0.1311, 0.1150, 0.1135, 0.1714, 0.1295, 0.1671, 0.1603,\n",
              "                      0.1569, 0.1475, 0.1160, 0.1666, 0.1720, 0.1285, 0.2492, 0.1544, 0.1768,\n",
              "                      0.1564, 0.1381, 0.1206, 0.1257, 0.1352, 0.2135, 0.1519, 0.1535, 0.1814,\n",
              "                      0.1284, 0.1904, 0.1045, 0.1057, 0.1413, 0.2048, 0.1424, 0.1138, 0.1671,\n",
              "                      0.1145, 0.1035, 0.2280, 0.1323, 0.1544, 0.1997, 0.1425, 0.1140, 0.1073,\n",
              "                      0.0768, 0.1294, 0.1079, 0.1730, 0.0944, 0.1190, 0.1228, 0.1440, 0.1468,\n",
              "                      0.1435, 0.1533, 0.1303, 0.3807, 0.1946, 0.1268, 0.2034, 0.1735, 0.1444,\n",
              "                      0.1094, 0.0863, 0.1807, 0.1064, 0.1964, 0.1452, 0.1778, 0.1492, 0.1289,\n",
              "                      0.1101, 0.0912, 0.1737, 0.2137, 0.1165, 0.1333, 0.1047, 0.1442, 0.1388,\n",
              "                      0.1254, 0.1256, 0.1087, 0.2244, 0.2561, 0.1411, 0.1624, 0.1959, 0.1799,\n",
              "                      0.2343, 0.1669, 0.1662, 0.1563, 0.1476, 0.2315, 0.1396, 0.2018, 0.1280,\n",
              "                      0.1887, 0.0895, 0.1057, 0.1802, 0.1390, 0.1658, 0.1602, 0.2049, 0.1161,\n",
              "                      0.1602, 0.1608, 0.1271, 0.1322, 0.1787, 0.2692, 0.2059, 0.1049, 0.1270,\n",
              "                      0.1592, 0.1756, 0.2458, 0.0992, 0.1472, 0.1652, 0.1107, 0.1141, 0.1984,\n",
              "                      0.3032, 0.1361, 0.1596, 0.3235, 0.1085, 0.1432, 0.1675, 0.0866, 0.1379,\n",
              "                      0.1451, 0.1674, 0.1434, 0.1513, 0.1412, 0.1279, 0.1595, 0.1169, 0.1177,\n",
              "                      0.1254, 0.1545, 0.1172, 0.2053, 0.1692, 0.1956, 0.1571, 0.1029, 0.1088,\n",
              "                      0.1531, 0.1819, 0.1447, 0.1216, 0.1610, 0.1168, 0.1122, 0.1479, 0.1853,\n",
              "                      0.1388, 0.0860, 0.1405, 0.1254, 0.1226, 0.1246, 0.2812, 0.1238, 0.1031,\n",
              "                      0.1467, 0.1521, 0.1207, 0.1398, 0.1676, 0.1937, 0.1439, 0.1720],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.bn1.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('layer4.0.conv2.weight',\n",
              "              tensor([[[[-1.1340e-04, -1.2281e-02, -1.6346e-02],\n",
              "                        [-1.0044e-02, -2.9724e-02, -3.6879e-02],\n",
              "                        [ 3.1427e-02,  2.0204e-02, -1.8334e-02]],\n",
              "              \n",
              "                       [[ 1.2589e-02,  3.4951e-02,  2.4212e-02],\n",
              "                        [-8.8953e-03, -2.5794e-02, -1.1865e-02],\n",
              "                        [-7.9706e-03, -4.9959e-03, -3.0273e-02]],\n",
              "              \n",
              "                       [[-9.3547e-03, -3.0074e-02,  3.6413e-03],\n",
              "                        [-1.4256e-02, -1.1458e-02,  3.1969e-03],\n",
              "                        [-1.2213e-03,  7.2354e-03,  4.9072e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.5144e-03, -9.1428e-03, -2.8556e-02],\n",
              "                        [-3.9442e-03,  1.5287e-03, -1.5715e-02],\n",
              "                        [-2.1522e-03,  9.6429e-03, -7.4031e-03]],\n",
              "              \n",
              "                       [[-1.8447e-02, -1.1626e-02, -1.6232e-02],\n",
              "                        [ 2.0941e-02,  6.1523e-02,  2.5463e-02],\n",
              "                        [-2.6084e-02, -3.0445e-02, -5.2495e-03]],\n",
              "              \n",
              "                       [[ 1.9628e-03,  4.7589e-03, -5.9058e-03],\n",
              "                        [-1.7398e-02,  3.8003e-03,  2.5563e-04],\n",
              "                        [-5.9521e-03, -1.9082e-03, -7.1663e-04]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.2835e-02,  2.5915e-03, -1.9627e-03],\n",
              "                        [-6.6428e-04, -7.9162e-04, -1.3266e-02],\n",
              "                        [-9.7860e-03, -1.8153e-02, -2.0838e-02]],\n",
              "              \n",
              "                       [[-1.4935e-02, -2.0198e-02, -2.9088e-02],\n",
              "                        [ 7.4330e-03, -1.6290e-02, -5.8755e-03],\n",
              "                        [ 3.3191e-03, -1.7395e-02, -5.6457e-03]],\n",
              "              \n",
              "                       [[-1.1832e-02, -3.5119e-02, -1.0311e-02],\n",
              "                        [-1.7716e-02, -5.7675e-02, -2.4333e-02],\n",
              "                        [-2.6336e-02, -4.3882e-02, -2.5844e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.5160e-02, -1.5190e-02, -2.8471e-03],\n",
              "                        [-2.3478e-02, -1.7442e-02, -3.6334e-03],\n",
              "                        [-4.7573e-03, -9.5033e-03, -2.7675e-03]],\n",
              "              \n",
              "                       [[-1.9323e-02, -1.8478e-02, -2.8281e-02],\n",
              "                        [-3.6607e-02, -6.8239e-02, -5.3096e-02],\n",
              "                        [-1.0804e-02, -2.4185e-02, -1.6148e-02]],\n",
              "              \n",
              "                       [[-2.0960e-02, -2.8324e-02, -5.0012e-03],\n",
              "                        [-7.4527e-03,  1.6552e-02,  4.5897e-03],\n",
              "                        [-1.3303e-02,  1.3233e-02, -1.4945e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-4.4353e-03, -4.2447e-03, -2.8163e-03],\n",
              "                        [ 1.5209e-02, -2.1596e-02, -9.2662e-03],\n",
              "                        [ 2.2546e-02,  1.1204e-02, -2.6375e-03]],\n",
              "              \n",
              "                       [[ 7.2372e-03, -1.1334e-02, -1.9429e-03],\n",
              "                        [ 4.8307e-04,  1.1621e-03, -9.3020e-03],\n",
              "                        [ 2.5139e-03,  9.4639e-04, -3.4710e-03]],\n",
              "              \n",
              "                       [[ 1.5986e-02,  1.0953e-03,  7.4757e-03],\n",
              "                        [ 1.9606e-02, -2.1207e-03, -2.1814e-03],\n",
              "                        [ 1.0868e-02, -4.0205e-03,  8.8392e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 3.0117e-02,  2.1687e-02,  2.4284e-02],\n",
              "                        [ 1.8632e-02,  2.3288e-02,  2.7777e-02],\n",
              "                        [ 8.8377e-03,  1.9257e-02,  2.3000e-02]],\n",
              "              \n",
              "                       [[-9.0600e-03, -1.0955e-02, -5.4218e-03],\n",
              "                        [-3.0370e-02, -3.6686e-02, -1.7814e-02],\n",
              "                        [ 7.7934e-04,  4.9352e-04,  1.5428e-02]],\n",
              "              \n",
              "                       [[-1.2193e-03, -2.3664e-02, -1.8371e-02],\n",
              "                        [-1.2382e-02, -1.3456e-02, -8.5454e-03],\n",
              "                        [-1.4634e-02,  1.0063e-02, -8.5087e-03]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-1.7640e-02, -1.8116e-02, -2.1266e-03],\n",
              "                        [-8.2122e-03, -3.4836e-03, -1.7486e-02],\n",
              "                        [ 2.4106e-02,  4.2325e-02,  1.9916e-02]],\n",
              "              \n",
              "                       [[ 4.7901e-03, -8.6360e-03, -1.1080e-02],\n",
              "                        [ 2.5276e-02, -8.5693e-04,  9.2466e-03],\n",
              "                        [ 2.2115e-02,  2.0184e-02,  1.0191e-02]],\n",
              "              \n",
              "                       [[-1.5588e-02, -2.7779e-02, -5.2615e-03],\n",
              "                        [-1.8342e-02, -4.4373e-02,  1.2698e-03],\n",
              "                        [-5.6302e-03, -8.4756e-03,  1.1192e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-2.0224e-02, -3.2916e-02, -1.6794e-02],\n",
              "                        [-1.8045e-02, -5.1324e-02, -2.6263e-02],\n",
              "                        [-3.6411e-04, -2.9248e-03, -9.4904e-03]],\n",
              "              \n",
              "                       [[-4.7966e-03, -8.3305e-04,  2.8443e-03],\n",
              "                        [-5.9247e-04, -2.4468e-02,  1.5308e-02],\n",
              "                        [ 2.9895e-02,  8.0327e-03,  4.1942e-02]],\n",
              "              \n",
              "                       [[-1.4613e-02, -1.7662e-02, -4.6051e-03],\n",
              "                        [-1.9261e-02, -8.7224e-03, -3.0986e-02],\n",
              "                        [-7.4234e-03, -5.8108e-03, -6.4039e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[-9.7005e-03, -6.0720e-03, -1.3723e-02],\n",
              "                        [-7.4033e-03, -1.7992e-02, -2.8030e-02],\n",
              "                        [-1.0825e-02,  1.5823e-03, -9.2025e-03]],\n",
              "              \n",
              "                       [[ 1.0206e-02, -2.0034e-03,  1.4795e-02],\n",
              "                        [ 4.8552e-03, -2.2902e-02,  5.7336e-04],\n",
              "                        [ 5.0343e-03,  1.0333e-02,  8.9639e-03]],\n",
              "              \n",
              "                       [[ 4.4991e-03,  8.7246e-04, -8.9921e-03],\n",
              "                        [ 3.9687e-03,  1.7234e-02,  9.8026e-03],\n",
              "                        [ 6.5970e-03,  1.9023e-02,  1.9856e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 7.9002e-03, -1.3190e-02,  6.7472e-03],\n",
              "                        [-1.8639e-03, -2.4044e-02, -9.5557e-03],\n",
              "                        [ 9.3762e-03, -1.0947e-02,  3.4352e-03]],\n",
              "              \n",
              "                       [[ 1.2563e-02,  3.7512e-03, -1.4082e-03],\n",
              "                        [ 7.9319e-03, -1.0882e-02, -3.9982e-03],\n",
              "                        [-1.9964e-03,  1.2358e-02,  7.8823e-03]],\n",
              "              \n",
              "                       [[-1.8083e-02, -2.5351e-02, -1.8601e-02],\n",
              "                        [-2.2471e-04, -1.7945e-04, -8.5525e-03],\n",
              "                        [-6.0964e-03,  1.0321e-02, -3.3069e-04]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 3.0886e-02, -6.7840e-03,  1.8106e-02],\n",
              "                        [ 2.2154e-02, -1.1097e-02, -1.8339e-02],\n",
              "                        [ 9.9467e-03, -1.2705e-02, -5.0340e-02]],\n",
              "              \n",
              "                       [[-4.1693e-03, -1.7791e-02, -7.8234e-03],\n",
              "                        [ 1.4183e-03, -5.1526e-02, -1.3252e-03],\n",
              "                        [ 9.9471e-03, -8.1030e-03,  1.2484e-02]],\n",
              "              \n",
              "                       [[ 1.5661e-02,  3.0743e-02,  3.4280e-03],\n",
              "                        [-3.8642e-03,  2.3619e-03, -1.3897e-02],\n",
              "                        [-9.2532e-03, -1.8077e-02,  1.8117e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 5.6594e-03,  1.6992e-02,  1.7343e-02],\n",
              "                        [-5.1209e-03,  7.0624e-06,  1.9058e-02],\n",
              "                        [-1.0541e-02, -1.5318e-02,  8.5010e-03]],\n",
              "              \n",
              "                       [[ 6.3521e-03,  9.9704e-03,  1.6998e-02],\n",
              "                        [ 1.6126e-02,  2.9231e-03,  1.6143e-02],\n",
              "                        [ 9.9360e-03,  1.4910e-02, -1.7945e-03]],\n",
              "              \n",
              "                       [[ 2.3786e-02, -1.4323e-02, -2.2844e-02],\n",
              "                        [ 8.6137e-04, -2.8625e-02,  7.4199e-03],\n",
              "                        [-1.7984e-03,  2.9588e-04,  1.5375e-02]]]], device='cuda:0')),\n",
              "             ('layer4.0.bn2.weight',\n",
              "              tensor([0.4545, 0.5184, 0.4560, 0.3296, 0.3702, 0.3695, 0.3683, 0.5839, 0.4453,\n",
              "                      0.5210, 0.4720, 0.3844, 0.3625, 0.5324, 0.3150, 0.4208, 0.3890, 0.5358,\n",
              "                      0.4323, 0.3264, 0.4312, 0.4657, 0.3940, 0.3795, 0.3882, 0.4576, 0.3496,\n",
              "                      0.3836, 0.3754, 0.4573, 0.4098, 0.4367, 0.4030, 0.4535, 0.4254, 0.4105,\n",
              "                      0.4473, 0.3680, 0.3976, 0.3500, 0.3551, 0.4142, 0.4460, 0.3069, 0.4682,\n",
              "                      0.4661, 0.4524, 0.5006, 0.4072, 0.4356, 0.3538, 0.3152, 0.4325, 0.4843,\n",
              "                      0.4267, 0.4039, 0.4518, 0.3607, 0.4599, 0.4005, 0.3503, 0.3813, 0.3995,\n",
              "                      0.5033, 0.4001, 0.3553, 0.4709, 0.5094, 0.4305, 0.4132, 0.4636, 0.4643,\n",
              "                      0.3752, 0.5564, 0.3521, 0.5218, 0.4675, 0.3593, 0.3642, 0.4255, 0.3816,\n",
              "                      0.4711, 0.3737, 0.4843, 0.5203, 0.3953, 0.4600, 0.3429, 0.4695, 0.4585,\n",
              "                      0.4141, 0.4374, 0.3191, 0.4089, 0.4169, 0.4314, 0.4195, 0.4509, 0.4419,\n",
              "                      0.5003, 0.5293, 0.4730, 0.4496, 0.3294, 0.3492, 0.4079, 0.5117, 0.4831,\n",
              "                      0.5024, 0.4269, 0.4286, 0.5040, 0.4135, 0.5186, 0.4762, 0.3663, 0.4414,\n",
              "                      0.4333, 0.3154, 0.3749, 0.4463, 0.4775, 0.4450, 0.3866, 0.4276, 0.5123,\n",
              "                      0.5148, 0.4343, 0.3692, 0.4192, 0.4286, 0.4793, 0.4159, 0.3448, 0.3700,\n",
              "                      0.3372, 0.4379, 0.4056, 0.3656, 0.3719, 0.4373, 0.4661, 0.3487, 0.4320,\n",
              "                      0.3476, 0.4499, 0.4214, 0.3126, 0.4359, 0.3482, 0.4092, 0.4528, 0.3506,\n",
              "                      0.5767, 0.4363, 0.4783, 0.2994, 0.4906, 0.3995, 0.4013, 0.5327, 0.4829,\n",
              "                      0.4784, 0.1595, 0.4936, 0.4384, 0.4209, 0.4555, 0.5282, 0.4781, 0.4759,\n",
              "                      0.3961, 0.4009, 0.4443, 0.4269, 0.3973, 0.3785, 0.4043, 0.5465, 0.5454,\n",
              "                      0.3895, 0.4263, 0.3494, 0.4261, 0.4213, 0.4071, 0.3754, 0.4812, 0.5098,\n",
              "                      0.4052, 0.4180, 0.4129, 0.4435, 0.3446, 0.4269, 0.4450, 0.3822, 0.4369,\n",
              "                      0.3926, 0.4445, 0.5438, 0.3828, 0.6490, 0.4395, 0.5575, 0.4245, 0.4473,\n",
              "                      0.3346, 0.3513, 0.3789, 0.4288, 0.4679, 0.4291, 0.3757, 0.4170, 0.3822,\n",
              "                      0.3977, 0.3972, 0.3971, 0.5371, 0.3426, 0.4333, 0.4416, 0.4315, 0.3861,\n",
              "                      0.3872, 0.3917, 0.4227, 0.3703, 0.4165, 0.4006, 0.3847, 0.4310, 0.4817,\n",
              "                      0.4237, 0.3501, 0.4377, 0.5218, 0.3922, 0.6617, 0.4244, 0.6425, 0.5317,\n",
              "                      0.3451, 0.5253, 0.5903, 0.4271, 0.3502, 0.4169, 0.4785, 0.6012, 0.3599,\n",
              "                      0.4189, 0.3808, 0.3174, 0.5709, 0.3655, 0.5289, 0.3920, 0.3417, 0.4249,\n",
              "                      0.5153, 0.3717, 0.3491, 0.3640, 0.3798, 0.4148, 0.4605, 0.3178, 0.5012,\n",
              "                      0.4692, 0.5194, 0.4366, 0.5657, 0.5378, 0.4256, 0.3886, 0.4216, 0.3945,\n",
              "                      0.4184, 0.4295, 0.3867, 0.4156, 0.3763, 0.2715, 0.3546, 0.3839, 0.4411,\n",
              "                      0.3391, 0.4529, 0.4260, 0.3818, 0.3136, 0.3999, 0.3809, 0.3983, 0.4493,\n",
              "                      0.4407, 0.3788, 0.3547, 0.4405, 0.4866, 0.4555, 0.4682, 0.4949, 0.2569,\n",
              "                      0.4128, 0.4391, 0.4440, 0.3814, 0.4397, 0.4929, 0.4838, 0.3500, 0.4722,\n",
              "                      0.4086, 0.4600, 0.3420, 0.6072, 0.5564, 0.4035, 0.4881, 0.4449, 0.4671,\n",
              "                      0.4909, 0.3155, 0.4757, 0.4184, 0.4115, 0.5332, 0.4521, 0.5090, 0.4903,\n",
              "                      0.4345, 0.4677, 0.3566, 0.4150, 0.3956, 0.3877, 0.3844, 0.3897, 0.5614,\n",
              "                      0.2736, 0.5644, 0.4276, 0.4844, 0.4570, 0.3284, 0.3252, 0.5766, 0.3487,\n",
              "                      0.3894, 0.3126, 0.4735, 0.4226, 0.3736, 0.4655, 0.4238, 0.3983, 0.4648,\n",
              "                      0.3832, 0.4907, 0.4385, 0.3956, 0.4440, 0.3431, 0.4919, 0.3730, 0.4564,\n",
              "                      0.4150, 0.5765, 0.5003, 0.7559, 0.5610, 0.4767, 0.4430, 0.3786, 0.3830,\n",
              "                      0.4612, 0.4164, 0.3983, 0.3829, 0.5006, 0.3699, 0.3688, 0.4276, 0.2976,\n",
              "                      0.4341, 0.3337, 0.4538, 0.4134, 0.3559, 0.4438, 0.5301, 0.3386, 0.4394,\n",
              "                      0.3905, 0.3747, 0.4311, 0.3741, 0.4395, 0.4294, 0.3951, 0.4574, 0.4898,\n",
              "                      0.3764, 0.4022, 0.4818, 0.4013, 0.4673, 0.4195, 0.4567, 0.3596, 0.4753,\n",
              "                      0.3909, 0.3751, 0.3193, 0.4271, 0.6406, 0.4581, 0.4136, 0.3695, 0.3464,\n",
              "                      0.4267, 0.4229, 0.3903, 0.4585, 0.4376, 0.4116, 0.4465, 0.6802, 0.4309,\n",
              "                      0.3612, 0.5263, 0.4622, 0.5793, 0.4493, 0.4069, 0.4160, 0.4830, 0.5567,\n",
              "                      0.4602, 0.5345, 0.3817, 0.3949, 0.4359, 0.4839, 0.4528, 0.4193, 0.3803,\n",
              "                      0.4370, 0.4133, 0.4712, 0.4176, 0.3433, 0.4758, 0.4536, 0.4400, 0.3857,\n",
              "                      0.3328, 0.4990, 0.3511, 0.3856, 0.4578, 0.3549, 0.4071, 0.4884, 0.3656,\n",
              "                      0.4665, 0.4755, 0.4769, 0.3326, 0.4350, 0.4265, 0.3914, 0.4224, 0.3960,\n",
              "                      0.4355, 0.4438, 0.7196, 0.3884, 0.5255, 0.3908, 0.3556, 0.5291, 0.4160,\n",
              "                      0.3362, 0.3304, 0.4050, 0.4925, 0.4418, 0.2549, 0.4793, 0.4340, 0.5509,\n",
              "                      0.4350, 0.4545, 0.4602, 0.3652, 0.4763, 0.3364, 0.4352, 0.3561, 0.4283,\n",
              "                      0.4485, 0.3606, 0.3494, 0.3947, 0.3561, 0.4254, 0.5213, 0.4169],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.bn2.bias',\n",
              "              tensor([-0.1740, -0.2063, -0.1940, -0.1768, -0.1617, -0.1279, -0.2157, -0.2794,\n",
              "                      -0.0888, -0.2044, -0.0901, -0.1468, -0.1908, -0.0093, -0.1508, -0.1683,\n",
              "                      -0.1919, -0.1556, -0.1641, -0.1750, -0.1192, -0.2314, -0.1896, -0.1806,\n",
              "                      -0.1774, -0.1777, -0.1706, -0.1463, -0.1467, -0.2497, -0.1840, -0.2525,\n",
              "                      -0.1635, -0.2470, -0.2429, -0.2894, -0.1258, -0.1693, -0.1938, -0.1796,\n",
              "                      -0.1453, -0.1008, -0.2781, -0.1019, -0.2202, -0.2633, -0.2295, -0.1856,\n",
              "                      -0.1676, -0.2322, -0.1147, -0.1738, -0.2762, -0.2514, -0.1889, -0.2205,\n",
              "                      -0.2273, -0.1838, -0.2054, -0.0684, -0.1922, -0.2040, -0.0959, -0.2837,\n",
              "                      -0.1315, -0.1702, -0.2233, -0.3802, -0.2855, -0.2448, -0.1616, -0.1934,\n",
              "                      -0.1735, -0.1984, -0.1452, -0.2732, -0.3372, -0.1632, -0.1701, -0.2705,\n",
              "                      -0.2237, -0.1498, -0.1490, -0.1478, -0.3025, -0.1348, -0.1790, -0.1540,\n",
              "                      -0.1445, -0.2335, -0.1983, -0.1456, -0.1636, -0.2255, -0.1587, -0.1826,\n",
              "                      -0.1537, -0.1898, -0.2317, -0.2385, -0.2050, -0.1401, -0.2058, -0.1328,\n",
              "                      -0.1225, -0.2152, -0.1860, -0.1895, -0.3055, -0.1930, -0.2638, -0.2173,\n",
              "                      -0.2073, -0.3461, -0.2662, -0.1887, -0.1807, -0.2181, -0.1710, -0.1594,\n",
              "                      -0.1106, -0.2211, -0.1125, -0.1570, -0.1823, -0.3526, -0.2995, -0.2191,\n",
              "                      -0.1439, -0.1642, -0.2938, -0.2143, -0.1426, -0.1650, -0.1843, -0.1837,\n",
              "                      -0.1384, -0.1481, -0.2003, -0.1866, -0.1670, -0.2601, -0.0551, -0.2036,\n",
              "                      -0.2013, -0.1950, -0.2414, -0.1021, -0.1328, -0.1057, -0.1361, -0.1671,\n",
              "                      -0.2334, -0.3356, -0.3533, -0.2417, -0.1255, -0.2211, -0.1857, -0.1721,\n",
              "                      -0.3466, -0.0991, -0.2488,  0.0726, -0.2858, -0.1114, -0.1593, -0.2189,\n",
              "                      -0.3222, -0.1743, -0.2557, -0.1466, -0.2503, -0.2892, -0.2415, -0.1387,\n",
              "                      -0.2009, -0.2148, -0.1280, -0.2707, -0.2104, -0.2205, -0.0196, -0.1418,\n",
              "                      -0.1135, -0.1423, -0.1755, -0.1749, -0.1980, -0.2276, -0.2009, -0.2424,\n",
              "                      -0.1785, -0.1681, -0.1836, -0.4039, -0.1253, -0.1518, -0.1336, -0.2143,\n",
              "                      -0.1160, -0.2483, -0.2613, -0.1667, -0.2567, -0.2251, -0.2032, -0.2111,\n",
              "                      -0.1056, -0.1406, -0.1912, -0.1625, -0.2275, -0.0870, -0.1792, -0.1899,\n",
              "                      -0.1620, -0.1884, -0.1497, -0.2859, -0.1753, -0.2244, -0.2367, -0.2037,\n",
              "                      -0.1281, -0.2180, -0.0971, -0.2184, -0.1221, -0.1804, -0.2125, -0.1825,\n",
              "                      -0.2279, -0.1555, -0.2115, -0.2321, -0.1681, -0.2229, -0.1258, -0.0762,\n",
              "                      -0.2583, -0.2473, -0.3004, -0.1509, -0.3604, -0.3717, -0.2010, -0.1458,\n",
              "                      -0.2138, -0.0677, -0.2001, -0.1681, -0.1854, -0.2192, -0.0741, -0.1621,\n",
              "                      -0.1156, -0.2208, -0.1470, -0.1418, -0.1396, -0.2929, -0.0992, -0.1053,\n",
              "                      -0.1826, -0.1038, -0.2598, -0.2080, -0.2206, -0.2433, -0.0455, -0.3473,\n",
              "                      -0.2638, -0.2184, -0.3714, -0.1757, -0.1202, -0.1712, -0.1865, -0.1868,\n",
              "                      -0.2031, -0.1741, -0.2817, -0.1168,  0.1020, -0.1832, -0.1671, -0.2126,\n",
              "                      -0.0123, -0.3471, -0.1965, -0.2033, -0.1491, -0.1786, -0.1381, -0.3027,\n",
              "                      -0.1994, -0.1854, -0.2163, -0.0803, -0.1712, -0.2236, -0.2089, -0.2080,\n",
              "                      -0.1941, -0.0515, -0.0697, -0.2115, -0.1674, -0.2150, -0.1284, -0.2226,\n",
              "                      -0.2003, -0.1675, -0.1805, -0.2049, -0.0969, -0.1604, -0.1992,  0.0575,\n",
              "                      -0.1093, -0.2748, -0.2633, -0.2485, -0.2836, -0.2128, -0.1842, -0.3022,\n",
              "                      -0.1706, -0.2953, -0.1149, -0.2121, -0.2552, -0.3119, -0.2970, -0.1552,\n",
              "                       0.0045, -0.2005, -0.2100, -0.1389, -0.1152,  0.0614, -0.0826, -0.1257,\n",
              "                      -0.1909, -0.3175, -0.2168, -0.1426, -0.0934,  0.0298, -0.1882, -0.1790,\n",
              "                      -0.1647, -0.2570, -0.1687, -0.1902, -0.2241, -0.1951, -0.1832, -0.2692,\n",
              "                      -0.0968, -0.3217, -0.0950, -0.1752, -0.1179, -0.2224, -0.2717, -0.1437,\n",
              "                      -0.2102, -0.1766, -0.1700, -0.2249, -0.1803, -0.3525, -0.2228, -0.2299,\n",
              "                      -0.2102, -0.2398, -0.2378, -0.1932, -0.1327, -0.2510, -0.1936, -0.1509,\n",
              "                      -0.1329, -0.1835, -0.1050, -0.2796, -0.0854, -0.1458, -0.2119, -0.1682,\n",
              "                      -0.2966, -0.1498, -0.1425, -0.2597, -0.1585, -0.1475, -0.1678, -0.1944,\n",
              "                      -0.2958, -0.1369, -0.2294, -0.2317, -0.1663, -0.1681, -0.2698, -0.2904,\n",
              "                      -0.1639, -0.2043, -0.1763, -0.2665, -0.1850, -0.1941, -0.1578, -0.2244,\n",
              "                      -0.1901, -0.2660, -0.4075, -0.2362, -0.1776, -0.2020, -0.1564, -0.2546,\n",
              "                      -0.0571, -0.2130, -0.2062, -0.1608, -0.1203, -0.1868, -0.3657, -0.1752,\n",
              "                      -0.2290, -0.2216, -0.2566, -0.2689, -0.1791, -0.1962, -0.1856, -0.2022,\n",
              "                      -0.1823, -0.2063, -0.3028, -0.1153, -0.1419, -0.2436, -0.1469, -0.1822,\n",
              "                      -0.3355, -0.1673, -0.1522, -0.2390, -0.1970, -0.2467, -0.1153, -0.1813,\n",
              "                      -0.1739, -0.1639, -0.2444, -0.1987, -0.1791, -0.0451, -0.1963, -0.1966,\n",
              "                      -0.1698, -0.1524, -0.2627, -0.1861, -0.2087, -0.2182, -0.1550, -0.1503,\n",
              "                      -0.1668, -0.3038, -0.1567, -0.2368, -0.2187, -0.1843, -0.2900, -0.3274,\n",
              "                      -0.2249, -0.1906, -0.1691, -0.0926, -0.1787, -0.1279, -0.1389, -0.1612,\n",
              "                      -0.1854, -0.2690, -0.2442, -0.0935, -0.2276, -0.2733, -0.2319, -0.2523,\n",
              "                      -0.2868, -0.2479, -0.1767, -0.2725, -0.1014, -0.1633, -0.1920, -0.1753,\n",
              "                      -0.2136, -0.1241, -0.0954, -0.2171, -0.1557, -0.1992, -0.3257, -0.1444],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.bn2.running_mean',\n",
              "              tensor([-0.2674, -0.2440, -0.1337, -0.1638, -0.1210, -0.1052, -0.1550, -0.2320,\n",
              "                      -0.2366, -0.2270, -0.2217, -0.1872, -0.1203, -0.1453, -0.1633, -0.1059,\n",
              "                      -0.1649, -0.1932, -0.1472, -0.1894, -0.1530, -0.1786, -0.2279, -0.1317,\n",
              "                      -0.1948, -0.1616, -0.1846, -0.1826, -0.1333, -0.1005, -0.1991, -0.2100,\n",
              "                      -0.2035, -0.2441, -0.1954, -0.1744, -0.3260, -0.0627, -0.0698, -0.1086,\n",
              "                      -0.1686, -0.3295, -0.2526, -0.1944, -0.1637, -0.2554, -0.2718, -0.2305,\n",
              "                      -0.0905, -0.1674, -0.1364, -0.0974, -0.1974, -0.1889, -0.1275, -0.1716,\n",
              "                      -0.1628, -0.1851, -0.2664, -0.1885, -0.2310, -0.1286, -0.2002, -0.1975,\n",
              "                      -0.2369, -0.1170, -0.1734, -0.2722, -0.0849, -0.2798, -0.1454, -0.2268,\n",
              "                      -0.1498, -0.1913, -0.1116, -0.1592, -0.2013, -0.1305, -0.2122, -0.1369,\n",
              "                      -0.1613, -0.0695, -0.1014, -0.1415, -0.2048, -0.1301, -0.2677, -0.1169,\n",
              "                      -0.2355, -0.0604, -0.1574, -0.1455, -0.2260, -0.2015, -0.1274, -0.2290,\n",
              "                      -0.0576, -0.1380, -0.0948, -0.2154, -0.1424, -0.2659, -0.3570, -0.0760,\n",
              "                      -0.0928, -0.1217, -0.2249, -0.1988, -0.2028, -0.1958, -0.2458, -0.2113,\n",
              "                      -0.0212, -0.2626, -0.3328, -0.1644, -0.2745, -0.1050, -0.2010, -0.1244,\n",
              "                      -0.1448, -0.2412, -0.1725, -0.1631, -0.2440, -0.3019, -0.2675,  0.1001,\n",
              "                      -0.1387, -0.0577, -0.2079, -0.1938, -0.1199, -0.0865, -0.1063, -0.1166,\n",
              "                      -0.1726, -0.1256, -0.1457, -0.2097, -0.1628, -0.1126, -0.0857, -0.1082,\n",
              "                      -0.1237, -0.2287, -0.2342, -0.2098, -0.1782, -0.0799, -0.2054, -0.2055,\n",
              "                      -0.2931, -0.2844, -0.2300, -0.1952, -0.2101, -0.0449, -0.1780, -0.0851,\n",
              "                      -0.1692, -0.1064, -0.1520, -0.0063, -0.1916, -0.2165, -0.2583, -0.1781,\n",
              "                      -0.1948, -0.0746, -0.2431, -0.1945, -0.0757, -0.2202, -0.1736, -0.1018,\n",
              "                      -0.2085, -0.1566, -0.2756, -0.0905, -0.1524, -0.1500, -0.1255, -0.1243,\n",
              "                      -0.0738, -0.0920, -0.3153, -0.0952, -0.4038, -0.2085, -0.3078, -0.1007,\n",
              "                      -0.2129, -0.0764, -0.1362, -0.2599, -0.2452, -0.1468, -0.2008, -0.1503,\n",
              "                      -0.1742, -0.1987, -0.1616, -0.1203, -0.1333, -0.1379, -0.1490, -0.1489,\n",
              "                      -0.2332,  0.0100, -0.2086, -0.1905, -0.2581, -0.1207, -0.2434, -0.1094,\n",
              "                      -0.1452, -0.1353, -0.2564, -0.2614, -0.2220, -0.0967, -0.0500, -0.2079,\n",
              "                      -0.2687, -0.2268, -0.1965, -0.1600, -0.0887, -0.2217, -0.1296, -0.2369,\n",
              "                      -0.1855,  0.4195, -0.2030, -0.0963, -0.1895,  0.5235, -0.1658, -0.2969,\n",
              "                      -0.2407, -0.3030, -0.0539, -0.1089, -0.2239, -0.2556, -0.1330, -0.2190,\n",
              "                      -0.2130, -0.0594, -0.2030, -0.1309, -0.0358, -0.0581, -0.2067, -0.2489,\n",
              "                      -0.0903, -0.0997, -0.0148, -0.2315, -0.1489, -0.0912, -0.2211, -0.1785,\n",
              "                      -0.0154, -0.1315, -0.1472, -0.1527, -0.1936, -0.0121, -0.2526, -0.2637,\n",
              "                      -0.0685, -0.1249, -0.2911, -0.2406, -0.3064, -0.2507, -0.1832, -0.3110,\n",
              "                      -0.2339, -0.1026, -0.1929, -0.1937,  0.1508, -0.0629, -0.1778, -0.1249,\n",
              "                      -0.1976, -0.2666, -0.2711, -0.1002, -0.1651, -0.1991, -0.1670, -0.1486,\n",
              "                      -0.1688, -0.1052, -0.1841, -0.1807, -0.1204, -0.2057, -0.1592, -0.1894,\n",
              "                      -0.1756, -0.1992, -0.1712, -0.1559,  0.0067, -0.1403, -0.1721, -0.2810,\n",
              "                      -0.1661, -0.0574, -0.1240, -0.1694, -0.1462, -0.1566, -0.2330, -0.1229,\n",
              "                      -0.1269, -0.1415, -0.2119, -0.1065, -0.1776, -0.1642, -0.1465, -0.2764,\n",
              "                      -0.1334, -0.1676, -0.2135, -0.1915, -0.2631, -0.2777, -0.1405, -0.2708,\n",
              "                      -0.2823, -0.0703, -0.1131, -0.1038, -0.1490, -0.1196, -0.1361, -0.2382,\n",
              "                      -0.2314, -0.1722, -0.2396, -0.1508, -0.1733, -0.2308, -0.2343, -0.2158,\n",
              "                      -0.1494, -0.1278, -0.1358, -0.0770, -0.1885, -0.1078, -0.1054, -0.0230,\n",
              "                      -0.2190, -0.1337, -0.1627, -0.1956, -0.0122, -0.1128, -0.2548, -0.1302,\n",
              "                      -0.1295, -0.0512, -0.2592, -0.1791, -0.3642, -0.2827, -0.1389, -0.2330,\n",
              "                      -0.1436, -0.1373, -0.0557, -0.1333, -0.1144, -0.0768, -0.0974, -0.1048,\n",
              "                      -0.1381, -0.1246, -0.2430, -0.1579, -0.2382, -0.1472, -0.1856, -0.1357,\n",
              "                      -0.0482, -0.2077, -0.1292, -0.1402, -0.1263, -0.2045, -0.1465, -0.1827,\n",
              "                      -0.1086, -0.0779, -0.2211, -0.2930, -0.1239, -0.2030, -0.1775, -0.1938,\n",
              "                      -0.1406, -0.1994, -0.2504, -0.2709, -0.0649, -0.2514, -0.1146, -0.2061,\n",
              "                      -0.1063, -0.1444, -0.3036, -0.0585, -0.2653, -0.1161, -0.1599, -0.1060,\n",
              "                      -0.2304, -0.2038, -0.2095, -0.3446, -0.2140, -0.1132, -0.4446, -0.1758,\n",
              "                      -0.1264, -0.2363, -0.1361, -0.1027, -0.2396, -0.1103, -0.1815, -0.1579,\n",
              "                      -0.1529, -0.2102, -0.2840, -0.1316, -0.1472, -0.1690, -0.2350, -0.2094,\n",
              "                      -0.1329, -0.0904, -0.1122, -0.1366, -0.1953, -0.0931, -0.0841, -0.1521,\n",
              "                      -0.1828, -0.1188, -0.2100, -0.1868, -0.2277, -0.1498, -0.1920, -0.2207,\n",
              "                      -0.1296, -0.1172, -0.2635, -0.1214, -0.1373, -0.2367, -0.1163, -0.2656,\n",
              "                      -0.1627, -0.1992, -0.1349, -0.2163, -0.2393, -0.1513, -0.2375, -0.3445,\n",
              "                      -0.1635, -0.1495, -0.2059, -0.0964, -0.2645, -0.1805, -0.2130, -0.2690,\n",
              "                      -0.1367, -0.2320, -0.0656, -0.2517, -0.2371, -0.2139, -0.1852, -0.1739,\n",
              "                      -0.0265, -0.0473, -0.1695, -0.1812, -0.2099, -0.1578, -0.0152, -0.0999,\n",
              "                      -0.1190, -0.0789, -0.1042, -0.1779, -0.1742, -0.3030, -0.1215, -0.2413],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.bn2.running_var',\n",
              "              tensor([0.0311, 0.0335, 0.0282, 0.0162, 0.0191, 0.0253, 0.0244, 0.0425, 0.0300,\n",
              "                      0.0251, 0.0349, 0.0247, 0.0229, 0.0842, 0.0199, 0.0223, 0.0209, 0.0528,\n",
              "                      0.0250, 0.0155, 0.0223, 0.0329, 0.0293, 0.0199, 0.0231, 0.0229, 0.0214,\n",
              "                      0.0253, 0.0267, 0.0210, 0.0250, 0.0409, 0.0262, 0.0212, 0.0179, 0.0193,\n",
              "                      0.0306, 0.0247, 0.0321, 0.0180, 0.0266, 0.0328, 0.0208, 0.0214, 0.0308,\n",
              "                      0.0242, 0.0198, 0.0476, 0.0190, 0.0284, 0.0265, 0.0162, 0.0223, 0.0267,\n",
              "                      0.0218, 0.0232, 0.0272, 0.0305, 0.0253, 0.0341, 0.0233, 0.0269, 0.0311,\n",
              "                      0.0234, 0.0329, 0.0255, 0.0321, 0.0184, 0.0311, 0.0224, 0.0405, 0.0256,\n",
              "                      0.0195, 0.0348, 0.0225, 0.0173, 0.0174, 0.0272, 0.0265, 0.0273, 0.0229,\n",
              "                      0.0298, 0.0261, 0.0265, 0.0246, 0.0300, 0.0348, 0.0220, 0.0402, 0.0359,\n",
              "                      0.0312, 0.0280, 0.0206, 0.0234, 0.0228, 0.0333, 0.0182, 0.0208, 0.0260,\n",
              "                      0.0287, 0.0316, 0.0284, 0.0289, 0.0191, 0.0171, 0.0213, 0.0350, 0.0396,\n",
              "                      0.0288, 0.0327, 0.0243, 0.0250, 0.0178, 0.0293, 0.0283, 0.0223, 0.0249,\n",
              "                      0.0507, 0.0266, 0.0223, 0.0265, 0.0297, 0.0235, 0.0217, 0.0220, 0.0201,\n",
              "                      0.0334, 0.0213, 0.0194, 0.0256, 0.0229, 0.0281, 0.0224, 0.0142, 0.0247,\n",
              "                      0.0194, 0.0270, 0.0248, 0.0211, 0.0281, 0.0275, 0.0297, 0.0299, 0.0215,\n",
              "                      0.0251, 0.0276, 0.0236, 0.0229, 0.0263, 0.0314, 0.0354, 0.0276, 0.0199,\n",
              "                      0.0282, 0.0158, 0.0334, 0.0240, 0.0418, 0.0262, 0.0230, 0.0224, 0.0358,\n",
              "                      0.0201, 0.0426, 0.0251, 0.0371, 0.0322, 0.0190, 0.0257, 0.0252, 0.0256,\n",
              "                      0.0291, 0.0262, 0.0215, 0.0186, 0.0355, 0.0307, 0.0203, 0.0299, 0.0484,\n",
              "                      0.0400, 0.0241, 0.0330, 0.0211, 0.0203, 0.0257, 0.0236, 0.0205, 0.0377,\n",
              "                      0.0194, 0.0332, 0.0252, 0.0463, 0.0139, 0.0258, 0.0190, 0.0233, 0.0411,\n",
              "                      0.0269, 0.0296, 0.0381, 0.0273, 0.0365, 0.0228, 0.0224, 0.0204, 0.0232,\n",
              "                      0.0210, 0.0243, 0.0193, 0.0231, 0.0342, 0.0262, 0.0317, 0.0282, 0.0327,\n",
              "                      0.0243, 0.0269, 0.0194, 0.0230, 0.0282, 0.0203, 0.0258, 0.0180, 0.0304,\n",
              "                      0.0212, 0.0343, 0.0212, 0.0240, 0.0304, 0.0247, 0.0194, 0.0209, 0.0838,\n",
              "                      0.0207, 0.0199, 0.0258, 0.0964, 0.0360, 0.0747, 0.0221, 0.0398, 0.0302,\n",
              "                      0.0205, 0.0233, 0.0255, 0.0179, 0.0222, 0.0222, 0.0593, 0.0418, 0.0279,\n",
              "                      0.0267, 0.0184, 0.0247, 0.0503, 0.0284, 0.0254, 0.0261, 0.0198, 0.0275,\n",
              "                      0.0274, 0.0236, 0.0211, 0.0208, 0.0281, 0.0167, 0.0362, 0.0251, 0.0352,\n",
              "                      0.0521, 0.0241, 0.0202, 0.0377, 0.0310, 0.0252, 0.0302, 0.0257, 0.0236,\n",
              "                      0.0317, 0.0303, 0.0244, 0.0188, 0.0400, 0.0403, 0.0185, 0.0243, 0.0290,\n",
              "                      0.0217, 0.0182, 0.0259, 0.0200, 0.0209, 0.0220, 0.0248, 0.0169, 0.0405,\n",
              "                      0.0260, 0.0211, 0.0277, 0.0401, 0.0320, 0.0198, 0.0278, 0.0357, 0.0182,\n",
              "                      0.0287, 0.0206, 0.0265, 0.0224, 0.0275, 0.0288, 0.0321, 0.0250, 0.0262,\n",
              "                      0.0220, 0.0249, 0.0186, 0.0391, 0.0851, 0.0271, 0.0213, 0.0242, 0.0217,\n",
              "                      0.0242, 0.0187, 0.0199, 0.0191, 0.0183, 0.0352, 0.0372, 0.0304, 0.0354,\n",
              "                      0.0207, 0.0198, 0.0212, 0.0830, 0.0209, 0.0205, 0.0244, 0.0237, 0.1168,\n",
              "                      0.0175, 0.0575, 0.0236, 0.0262, 0.0314, 0.0307, 0.0250, 0.0912, 0.0204,\n",
              "                      0.0197, 0.0230, 0.0234, 0.0229, 0.0197, 0.0290, 0.0213, 0.0204, 0.0250,\n",
              "                      0.0277, 0.0253, 0.0259, 0.0216, 0.0265, 0.0182, 0.0286, 0.0228, 0.0290,\n",
              "                      0.0219, 0.0305, 0.0306, 0.1292, 0.0273, 0.0271, 0.0197, 0.0232, 0.0226,\n",
              "                      0.0298, 0.0240, 0.0243, 0.0203, 0.0332, 0.0215, 0.0201, 0.0200, 0.0192,\n",
              "                      0.0205, 0.0200, 0.0228, 0.0200, 0.0126, 0.0142, 0.0426, 0.0161, 0.0253,\n",
              "                      0.0218, 0.0295, 0.0201, 0.0232, 0.0153, 0.0348, 0.0182, 0.0257, 0.0427,\n",
              "                      0.0324, 0.0170, 0.0162, 0.0222, 0.0222, 0.0250, 0.0195, 0.0192, 0.0328,\n",
              "                      0.0224, 0.0198, 0.0184, 0.0255, 0.0374, 0.0212, 0.0320, 0.0178, 0.0182,\n",
              "                      0.0209, 0.0356, 0.0201, 0.0253, 0.0396, 0.0399, 0.0312, 0.0561, 0.0231,\n",
              "                      0.0225, 0.0272, 0.0264, 0.0279, 0.0368, 0.0280, 0.0253, 0.0229, 0.0530,\n",
              "                      0.0263, 0.0292, 0.0202, 0.0256, 0.0217, 0.0298, 0.0226, 0.0271, 0.0143,\n",
              "                      0.0185, 0.0226, 0.0280, 0.0202, 0.0235, 0.0275, 0.0347, 0.0336, 0.0279,\n",
              "                      0.0174, 0.0418, 0.0248, 0.0207, 0.0217, 0.0254, 0.0269, 0.0253, 0.0206,\n",
              "                      0.0302, 0.0237, 0.0249, 0.0232, 0.0261, 0.0159, 0.0258, 0.0211, 0.0204,\n",
              "                      0.0315, 0.0225, 0.0429, 0.0155, 0.0383, 0.0190, 0.0224, 0.0394, 0.0347,\n",
              "                      0.0244, 0.0160, 0.0177, 0.0304, 0.0267, 0.0237, 0.0225, 0.0210, 0.0421,\n",
              "                      0.0242, 0.0210, 0.0200, 0.0297, 0.0201, 0.0315, 0.0221, 0.0260, 0.0201,\n",
              "                      0.0271, 0.0217, 0.0206, 0.0201, 0.0225, 0.0287, 0.0192, 0.0194],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.bn2.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('layer4.0.downsample.0.weight', tensor([[[[ 0.0016]],\n",
              "              \n",
              "                       [[ 0.0063]],\n",
              "              \n",
              "                       [[ 0.0189]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0110]],\n",
              "              \n",
              "                       [[-0.0293]],\n",
              "              \n",
              "                       [[ 0.0131]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0310]],\n",
              "              \n",
              "                       [[-0.0149]],\n",
              "              \n",
              "                       [[ 0.0519]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0207]],\n",
              "              \n",
              "                       [[-0.0280]],\n",
              "              \n",
              "                       [[ 0.0019]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0533]],\n",
              "              \n",
              "                       [[-0.0393]],\n",
              "              \n",
              "                       [[ 0.0380]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0375]],\n",
              "              \n",
              "                       [[-0.0162]],\n",
              "              \n",
              "                       [[-0.0430]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0479]],\n",
              "              \n",
              "                       [[ 0.0446]],\n",
              "              \n",
              "                       [[ 0.0116]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0057]],\n",
              "              \n",
              "                       [[ 0.0055]],\n",
              "              \n",
              "                       [[-0.0692]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0556]],\n",
              "              \n",
              "                       [[-0.0194]],\n",
              "              \n",
              "                       [[-0.0478]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0021]],\n",
              "              \n",
              "                       [[ 0.0384]],\n",
              "              \n",
              "                       [[ 0.0126]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0271]],\n",
              "              \n",
              "                       [[-0.0031]],\n",
              "              \n",
              "                       [[ 0.0091]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0078]],\n",
              "              \n",
              "                       [[-0.0137]],\n",
              "              \n",
              "                       [[-0.0107]]]], device='cuda:0')),\n",
              "             ('layer4.0.downsample.1.weight',\n",
              "              tensor([ 0.1732,  0.3429,  0.2889,  0.3587,  0.1623,  0.1964,  0.3239,  0.4091,\n",
              "                       0.2143,  0.2127,  0.1135,  0.2097,  0.3022,  0.1032,  0.2058,  0.2620,\n",
              "                       0.3689,  0.3278,  0.2809,  0.2675,  0.1650,  0.3607,  0.3483,  0.3160,\n",
              "                       0.2259,  0.1024,  0.3483,  0.2532,  0.3433,  0.2429,  0.2716,  0.3866,\n",
              "                       0.2123,  0.2507,  0.2649,  0.3663,  0.1910,  0.2246,  0.3094,  0.2861,\n",
              "                       0.2307,  0.2949,  0.3154,  0.3607,  0.2548,  0.1817,  0.2758,  0.3941,\n",
              "                       0.1823,  0.2692,  0.1689,  0.3648,  0.2197,  0.2587,  0.2588,  0.3895,\n",
              "                       0.3481,  0.2772,  0.3119,  0.0941,  0.2828,  0.3409,  0.1341,  0.2804,\n",
              "                       0.1532,  0.2916,  0.2603,  0.1804,  0.3675,  0.2187,  0.2192,  0.2034,\n",
              "                       0.2351,  0.1050,  0.2875,  0.2286,  0.3406,  0.3562,  0.2532,  0.2475,\n",
              "                       0.2974,  0.2626,  0.2288,  0.1439,  0.2358,  0.1740,  0.2385,  0.3340,\n",
              "                       0.1972,  0.1856,  0.2107,  0.2045,  0.2511,  0.4040,  0.1769,  0.1917,\n",
              "                       0.3716,  0.2411,  0.2687,  0.1917,  0.2959,  0.2142,  0.2061,  0.3210,\n",
              "                       0.3472,  0.3913,  0.1360,  0.3015,  0.1766,  0.3650,  0.2719,  0.2172,\n",
              "                       0.2745,  0.4337,  0.2669,  0.2774,  0.1295,  0.5128,  0.3372,  0.2466,\n",
              "                       0.1374,  0.1934,  0.0556,  0.2738,  0.1826,  0.2855,  0.2423,  0.1517,\n",
              "                       0.3236,  0.1837,  0.3308,  0.1789,  0.1940,  0.3440,  0.4114,  0.3068,\n",
              "                       0.1272,  0.3053,  0.1801,  0.2874,  0.2464,  0.4575,  0.2181,  0.1828,\n",
              "                       0.2505,  0.3421,  0.3154,  0.3115,  0.1404,  0.3040,  0.1441,  0.1241,\n",
              "                       0.2821,  0.2793,  0.3495,  0.2208,  0.2658,  0.2587,  0.1756,  0.2745,\n",
              "                       0.3451,  0.4241,  0.2661,  0.2682,  0.2995,  0.0806,  0.2827,  0.2350,\n",
              "                       0.3495,  0.2932,  0.2373,  0.2737,  0.2840,  0.3351,  0.2750,  0.3115,\n",
              "                       0.3284,  0.2186,  0.2544,  0.1933,  0.4514,  0.3066,  0.1994,  0.1880,\n",
              "                       0.3782,  0.3165,  0.2605,  0.2037,  0.2319,  0.2221,  0.2814,  0.4313,\n",
              "                       0.4394,  0.4163,  0.1681,  0.3583,  0.2670,  0.2760,  0.3293,  0.1744,\n",
              "                       0.1071,  0.3090,  0.4206,  0.2351,  0.3915,  0.3307,  0.2073,  0.4277,\n",
              "                       0.1819,  0.3140,  0.2254,  0.1623,  0.1776,  0.2476,  0.2198,  0.1950,\n",
              "                       0.2483,  0.2725,  0.2323,  0.2177,  0.3791,  0.5121,  0.2519,  0.2692,\n",
              "                       0.2880,  0.1863,  0.1620,  0.2020,  0.3461,  0.2568,  0.1378,  0.2390,\n",
              "                       0.2316,  0.2578,  0.2397,  0.3722,  0.1264,  0.2192,  0.3039,  0.0977,\n",
              "                       0.1624,  0.1345,  0.4346,  0.2835,  0.2605,  0.2700,  0.2502,  0.2747,\n",
              "                       0.1842,  0.1943,  0.2876,  0.3913,  0.3706,  0.3119,  0.1397,  0.2766,\n",
              "                       0.3225,  0.2888,  0.1427,  0.3347,  0.1794,  0.2677,  0.0878,  0.2784,\n",
              "                       0.3653,  0.2043,  0.2709,  0.2427,  0.3534,  0.3000,  0.1439,  0.2581,\n",
              "                       0.2535,  0.3400,  0.3293,  0.2088,  0.2111,  0.2197,  0.2001,  0.2372,\n",
              "                       0.2328,  0.2690,  0.2459,  0.3819, -0.0400,  0.2310,  0.2738,  0.2528,\n",
              "                       0.1121,  0.2292,  0.2847,  0.3240,  0.2875,  0.2262,  0.2462,  0.3078,\n",
              "                       0.3048,  0.3662,  0.2570,  0.1795,  0.3894,  0.2914,  0.2009,  0.3154,\n",
              "                       0.3455,  0.2308,  0.0621,  0.2905,  0.2123,  0.2334,  0.3249,  0.2645,\n",
              "                       0.3008,  0.3106,  0.1744,  0.1777,  0.1784,  0.3201,  0.3605, -0.0495,\n",
              "                       0.1614,  0.2262,  0.3419,  0.4000,  0.2308,  0.2870,  0.1311,  0.2619,\n",
              "                       0.2077,  0.2201,  0.1630,  0.2845,  0.2579,  0.2328,  0.2500,  0.2506,\n",
              "                       0.1101,  0.2919,  0.2347,  0.1822,  0.1081,  0.0820,  0.2997,  0.2686,\n",
              "                       0.1729,  0.2252,  0.2042,  0.2642,  0.1391,  0.1184,  0.2308,  0.2690,\n",
              "                       0.2893,  0.2740,  0.2763,  0.3648,  0.2967,  0.3190,  0.3260,  0.2875,\n",
              "                       0.1659,  0.2844,  0.1367,  0.1913,  0.2834,  0.3186,  0.2066,  0.3705,\n",
              "                       0.3453,  0.0789,  0.2730,  0.2062,  0.2285,  0.1889,  0.2082,  0.2069,\n",
              "                       0.3345,  0.3420,  0.3542,  0.3842,  0.2013,  0.3188,  0.3216,  0.3274,\n",
              "                       0.2791,  0.2425,  0.2638,  0.3602,  0.3144,  0.2611,  0.2604,  0.2946,\n",
              "                       0.3441,  0.1953,  0.3770,  0.3581,  0.3286,  0.2669,  0.1695,  0.2829,\n",
              "                       0.4151,  0.2887,  0.1801,  0.2421,  0.3652,  0.1904,  0.2864,  0.2381,\n",
              "                       0.2290,  0.1725,  0.2488,  0.2127,  0.3937,  0.1533,  0.1625,  0.3255,\n",
              "                       0.3214,  0.2239,  0.2768,  0.3097,  0.1714,  0.2322,  0.2243,  0.3093,\n",
              "                       0.1321,  0.2956,  0.2571,  0.1633,  0.0841,  0.1763,  0.3376,  0.1047,\n",
              "                       0.3618,  0.1686,  0.4317,  0.3410,  0.2250,  0.3350,  0.2450,  0.1456,\n",
              "                       0.1491,  0.2465,  0.2881,  0.2925,  0.2051,  0.2529,  0.2010,  0.2397,\n",
              "                       0.2762,  0.3466,  0.3279,  0.3801,  0.2629,  0.2564,  0.2417,  0.1038,\n",
              "                       0.2604,  0.2711,  0.3947,  0.3401,  0.3700,  0.1272,  0.1672,  0.1850,\n",
              "                       0.4466,  0.2468,  0.2863,  0.3034,  0.1939,  0.3102,  0.1563,  0.2737,\n",
              "                       0.1974,  0.2441,  0.3368,  0.2587,  0.2702,  0.2180,  0.2979,  0.3053,\n",
              "                       0.3115,  0.2305,  0.2281,  0.1444,  0.3144,  0.1033,  0.2879,  0.2937,\n",
              "                       0.4384,  0.2059,  0.4073,  0.3141,  0.2090,  0.2800,  0.1985,  0.3211,\n",
              "                       0.2793,  0.2110,  0.2633,  0.2248,  0.2904,  0.2133,  0.3414,  0.2354,\n",
              "                       0.2616,  0.3220,  0.2412,  0.3003,  0.2047,  0.3348,  0.3408,  0.1927],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.downsample.1.bias',\n",
              "              tensor([-0.1740, -0.2063, -0.1940, -0.1768, -0.1617, -0.1279, -0.2157, -0.2794,\n",
              "                      -0.0888, -0.2044, -0.0901, -0.1468, -0.1908, -0.0093, -0.1508, -0.1683,\n",
              "                      -0.1919, -0.1556, -0.1641, -0.1750, -0.1192, -0.2314, -0.1896, -0.1806,\n",
              "                      -0.1774, -0.1777, -0.1706, -0.1463, -0.1467, -0.2497, -0.1840, -0.2525,\n",
              "                      -0.1635, -0.2470, -0.2429, -0.2894, -0.1258, -0.1693, -0.1938, -0.1796,\n",
              "                      -0.1453, -0.1008, -0.2781, -0.1019, -0.2202, -0.2633, -0.2295, -0.1856,\n",
              "                      -0.1676, -0.2322, -0.1147, -0.1738, -0.2762, -0.2514, -0.1889, -0.2205,\n",
              "                      -0.2273, -0.1838, -0.2054, -0.0684, -0.1922, -0.2040, -0.0959, -0.2837,\n",
              "                      -0.1315, -0.1702, -0.2233, -0.3802, -0.2855, -0.2448, -0.1616, -0.1934,\n",
              "                      -0.1735, -0.1984, -0.1452, -0.2732, -0.3372, -0.1632, -0.1701, -0.2705,\n",
              "                      -0.2237, -0.1498, -0.1490, -0.1478, -0.3025, -0.1348, -0.1790, -0.1540,\n",
              "                      -0.1445, -0.2335, -0.1983, -0.1456, -0.1636, -0.2255, -0.1587, -0.1826,\n",
              "                      -0.1537, -0.1898, -0.2317, -0.2385, -0.2050, -0.1401, -0.2058, -0.1328,\n",
              "                      -0.1225, -0.2152, -0.1860, -0.1895, -0.3055, -0.1930, -0.2638, -0.2173,\n",
              "                      -0.2073, -0.3461, -0.2662, -0.1887, -0.1807, -0.2181, -0.1710, -0.1594,\n",
              "                      -0.1106, -0.2211, -0.1125, -0.1570, -0.1823, -0.3526, -0.2995, -0.2191,\n",
              "                      -0.1439, -0.1642, -0.2938, -0.2143, -0.1426, -0.1650, -0.1843, -0.1837,\n",
              "                      -0.1384, -0.1481, -0.2003, -0.1866, -0.1670, -0.2601, -0.0551, -0.2036,\n",
              "                      -0.2013, -0.1950, -0.2414, -0.1021, -0.1328, -0.1057, -0.1361, -0.1671,\n",
              "                      -0.2334, -0.3356, -0.3533, -0.2417, -0.1255, -0.2211, -0.1857, -0.1721,\n",
              "                      -0.3466, -0.0991, -0.2488,  0.0726, -0.2858, -0.1114, -0.1593, -0.2189,\n",
              "                      -0.3222, -0.1743, -0.2557, -0.1466, -0.2503, -0.2892, -0.2415, -0.1387,\n",
              "                      -0.2009, -0.2148, -0.1280, -0.2707, -0.2104, -0.2205, -0.0196, -0.1418,\n",
              "                      -0.1135, -0.1423, -0.1755, -0.1749, -0.1980, -0.2276, -0.2009, -0.2424,\n",
              "                      -0.1785, -0.1681, -0.1836, -0.4039, -0.1253, -0.1518, -0.1336, -0.2143,\n",
              "                      -0.1160, -0.2483, -0.2613, -0.1667, -0.2567, -0.2251, -0.2032, -0.2111,\n",
              "                      -0.1056, -0.1406, -0.1912, -0.1625, -0.2275, -0.0870, -0.1792, -0.1899,\n",
              "                      -0.1620, -0.1884, -0.1497, -0.2859, -0.1753, -0.2244, -0.2367, -0.2037,\n",
              "                      -0.1281, -0.2180, -0.0971, -0.2184, -0.1221, -0.1804, -0.2125, -0.1825,\n",
              "                      -0.2279, -0.1555, -0.2115, -0.2321, -0.1681, -0.2229, -0.1258, -0.0762,\n",
              "                      -0.2583, -0.2473, -0.3004, -0.1509, -0.3604, -0.3717, -0.2010, -0.1458,\n",
              "                      -0.2138, -0.0677, -0.2001, -0.1681, -0.1854, -0.2192, -0.0741, -0.1621,\n",
              "                      -0.1156, -0.2208, -0.1470, -0.1418, -0.1396, -0.2929, -0.0992, -0.1053,\n",
              "                      -0.1826, -0.1038, -0.2598, -0.2080, -0.2206, -0.2433, -0.0455, -0.3473,\n",
              "                      -0.2638, -0.2184, -0.3714, -0.1757, -0.1202, -0.1712, -0.1865, -0.1868,\n",
              "                      -0.2031, -0.1741, -0.2817, -0.1168,  0.1020, -0.1832, -0.1671, -0.2126,\n",
              "                      -0.0123, -0.3471, -0.1965, -0.2033, -0.1491, -0.1786, -0.1381, -0.3027,\n",
              "                      -0.1994, -0.1854, -0.2163, -0.0803, -0.1712, -0.2236, -0.2089, -0.2080,\n",
              "                      -0.1941, -0.0515, -0.0697, -0.2115, -0.1674, -0.2150, -0.1284, -0.2226,\n",
              "                      -0.2003, -0.1675, -0.1805, -0.2049, -0.0969, -0.1604, -0.1992,  0.0575,\n",
              "                      -0.1093, -0.2748, -0.2633, -0.2485, -0.2836, -0.2128, -0.1842, -0.3022,\n",
              "                      -0.1706, -0.2953, -0.1149, -0.2121, -0.2552, -0.3119, -0.2970, -0.1552,\n",
              "                       0.0045, -0.2005, -0.2100, -0.1389, -0.1152,  0.0614, -0.0826, -0.1257,\n",
              "                      -0.1909, -0.3175, -0.2168, -0.1426, -0.0934,  0.0298, -0.1882, -0.1790,\n",
              "                      -0.1647, -0.2570, -0.1687, -0.1902, -0.2241, -0.1951, -0.1832, -0.2692,\n",
              "                      -0.0968, -0.3217, -0.0950, -0.1752, -0.1179, -0.2224, -0.2717, -0.1437,\n",
              "                      -0.2102, -0.1766, -0.1700, -0.2249, -0.1803, -0.3525, -0.2228, -0.2299,\n",
              "                      -0.2102, -0.2398, -0.2378, -0.1932, -0.1327, -0.2510, -0.1936, -0.1509,\n",
              "                      -0.1329, -0.1835, -0.1050, -0.2796, -0.0854, -0.1458, -0.2119, -0.1682,\n",
              "                      -0.2966, -0.1498, -0.1425, -0.2597, -0.1585, -0.1475, -0.1678, -0.1944,\n",
              "                      -0.2958, -0.1369, -0.2294, -0.2317, -0.1663, -0.1681, -0.2698, -0.2904,\n",
              "                      -0.1639, -0.2043, -0.1763, -0.2665, -0.1850, -0.1941, -0.1578, -0.2244,\n",
              "                      -0.1901, -0.2660, -0.4075, -0.2362, -0.1776, -0.2020, -0.1564, -0.2546,\n",
              "                      -0.0571, -0.2130, -0.2062, -0.1608, -0.1203, -0.1868, -0.3657, -0.1752,\n",
              "                      -0.2290, -0.2216, -0.2566, -0.2689, -0.1791, -0.1962, -0.1856, -0.2022,\n",
              "                      -0.1823, -0.2063, -0.3028, -0.1153, -0.1419, -0.2436, -0.1469, -0.1822,\n",
              "                      -0.3355, -0.1673, -0.1522, -0.2390, -0.1970, -0.2467, -0.1153, -0.1813,\n",
              "                      -0.1739, -0.1639, -0.2444, -0.1987, -0.1791, -0.0451, -0.1963, -0.1966,\n",
              "                      -0.1698, -0.1524, -0.2627, -0.1861, -0.2087, -0.2182, -0.1550, -0.1503,\n",
              "                      -0.1668, -0.3038, -0.1567, -0.2368, -0.2187, -0.1843, -0.2900, -0.3274,\n",
              "                      -0.2249, -0.1906, -0.1691, -0.0926, -0.1787, -0.1279, -0.1389, -0.1612,\n",
              "                      -0.1854, -0.2690, -0.2442, -0.0935, -0.2276, -0.2733, -0.2319, -0.2523,\n",
              "                      -0.2868, -0.2479, -0.1767, -0.2725, -0.1014, -0.1633, -0.1920, -0.1753,\n",
              "                      -0.2136, -0.1241, -0.0954, -0.2171, -0.1557, -0.1992, -0.3257, -0.1444],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.downsample.1.running_mean',\n",
              "              tensor([-0.1132, -0.1363,  0.0059,  0.0929,  0.0548, -0.0276, -0.2248, -0.1454,\n",
              "                       0.0216, -0.1045, -0.0837, -0.0277,  0.0368, -0.0958, -0.0106, -0.0673,\n",
              "                      -0.0348, -0.2483, -0.0874, -0.0517,  0.0186, -0.2879, -0.0152, -0.0024,\n",
              "                       0.0877,  0.0140, -0.2178, -0.1168, -0.1677, -0.1048,  0.0103, -0.1370,\n",
              "                      -0.0951, -0.1906, -0.0165, -0.0862,  0.0139, -0.2095,  0.0255,  0.0390,\n",
              "                      -0.0398,  0.0093, -0.0358, -0.0389,  0.1172, -0.0443, -0.0668,  0.1580,\n",
              "                       0.0706, -0.1887, -0.0770, -0.2201, -0.0248, -0.0432, -0.0473,  0.1453,\n",
              "                      -0.0724,  0.0333,  0.0249, -0.1206, -0.0707, -0.1030,  0.0048,  0.0187,\n",
              "                      -0.0394, -0.0900,  0.0589, -0.0291, -0.0207, -0.0977, -0.1259, -0.1858,\n",
              "                      -0.0724, -0.1336, -0.0752, -0.0942, -0.0738,  0.0439, -0.1084, -0.0185,\n",
              "                       0.0106, -0.0124, -0.1289, -0.1258, -0.1600,  0.1119, -0.0184, -0.0822,\n",
              "                      -0.0781, -0.1380,  0.0185, -0.1278, -0.0586,  0.0254, -0.0556, -0.1464,\n",
              "                       0.0464, -0.1169, -0.1120, -0.1792, -0.0308, -0.0595, -0.1688,  0.0569,\n",
              "                      -0.0487,  0.1217, -0.1130,  0.0525, -0.0923,  0.0655, -0.1507,  0.0224,\n",
              "                      -0.0251, -0.2715, -0.1051, -0.0605, -0.0834,  0.2462, -0.0090, -0.0683,\n",
              "                      -0.1940,  0.0978,  0.0316, -0.0616,  0.0298, -0.0233,  0.0070, -0.0788,\n",
              "                      -0.0624,  0.0847, -0.0320,  0.0383, -0.0460, -0.0292, -0.0283, -0.1295,\n",
              "                      -0.0121, -0.0467,  0.0927, -0.1421, -0.0633, -0.1501, -0.1616,  0.0582,\n",
              "                       0.0340, -0.0477, -0.0770,  0.2329, -0.0179, -0.0815,  0.0129, -0.0474,\n",
              "                       0.0251, -0.1397, -0.2400, -0.0328, -0.0808, -0.1855, -0.1045, -0.0798,\n",
              "                      -0.0308,  0.0336, -0.1074,  0.1126, -0.1414, -0.1009,  0.0141, -0.1237,\n",
              "                      -0.0604,  0.0650, -0.1294, -0.0295, -0.0381, -0.1329, -0.0611,  0.0102,\n",
              "                       0.0451, -0.0184, -0.1271, -0.0139, -0.2064, -0.0575, -0.2162, -0.0608,\n",
              "                      -0.0087, -0.0221, -0.0993, -0.1391, -0.1046, -0.2047,  0.0232, -0.0774,\n",
              "                       0.0440, -0.1058,  0.0906, -0.0693, -0.1869, -0.0917, -0.0412, -0.0027,\n",
              "                      -0.0193, -0.1135, -0.1258,  0.0382, -0.0901, -0.1287, -0.0042, -0.1937,\n",
              "                      -0.0371, -0.0249,  0.0989, -0.0835, -0.0765,  0.0522, -0.0926,  0.0145,\n",
              "                      -0.0531, -0.0256, -0.0619, -0.1632, -0.0321, -0.0627, -0.0340, -0.0018,\n",
              "                      -0.0469,  0.0577, -0.0305, -0.0091, -0.1229,  0.0350,  0.0188, -0.0994,\n",
              "                      -0.1907, -0.1520, -0.0974, -0.0105, -0.0644, -0.2578, -0.0452, -0.0583,\n",
              "                       0.0367, -0.0675, -0.1672,  0.0210,  0.0205, -0.2153, -0.1675, -0.0665,\n",
              "                      -0.1369, -0.1063, -0.0202, -0.0608, -0.1519, -0.1446,  0.0396, -0.0504,\n",
              "                      -0.0562,  0.0804,  0.0260, -0.1571,  0.0670, -0.1409, -0.1402, -0.0672,\n",
              "                       0.0747, -0.0795, -0.1585,  0.0337,  0.1841,  0.0587, -0.0013,  0.0275,\n",
              "                      -0.0706, -0.1333, -0.1951, -0.0234,  0.0076,  0.1142, -0.2133, -0.0072,\n",
              "                      -0.1498,  0.0443, -0.1084, -0.1335,  0.1113,  0.1059, -0.0522, -0.0612,\n",
              "                      -0.1172, -0.0617, -0.0787,  0.0823, -0.0483, -0.0281, -0.0535, -0.0419,\n",
              "                      -0.0574, -0.0067, -0.1264, -0.0739,  0.1528, -0.1316, -0.0597,  0.0303,\n",
              "                      -0.0014,  0.0054, -0.0221, -0.0400, -0.1337, -0.0140, -0.0470, -0.0747,\n",
              "                      -0.0359, -0.0679,  0.0254,  0.0272, -0.0912, -0.0759,  0.0759,  0.1808,\n",
              "                      -0.1269, -0.1261,  0.0585, -0.0412, -0.1642, -0.1046, -0.0313, -0.0447,\n",
              "                      -0.0625, -0.1309,  0.0682, -0.0998, -0.1541,  0.0926,  0.0351,  0.0049,\n",
              "                      -0.0901,  0.0042, -0.0997, -0.0351,  0.0077, -0.1537, -0.0123,  0.0548,\n",
              "                      -0.0936, -0.0057, -0.0188, -0.0208, -0.0973, -0.1540, -0.0674, -0.1420,\n",
              "                      -0.0684,  0.0685, -0.0051, -0.1949,  0.0940,  0.0286, -0.0971, -0.0657,\n",
              "                       0.0582, -0.1641, -0.1464, -0.0236,  0.0538, -0.0303,  0.0283, -0.0444,\n",
              "                       0.0557,  0.0069, -0.0225, -0.1082,  0.5456,  0.0435, -0.0536, -0.0638,\n",
              "                      -0.0213, -0.0045, -0.0930,  0.0075, -0.0781, -0.0590,  0.0424, -0.1595,\n",
              "                      -0.0633, -0.1579, -0.1344, -0.0211, -0.0112, -0.0610, -0.0145, -0.1247,\n",
              "                      -0.1172, -0.0575, -0.0554, -0.0540, -0.0507,  0.0504, -0.1139, -0.0761,\n",
              "                      -0.0439, -0.0736, -0.1040,  0.0507,  0.1338, -0.2321, -0.0287, -0.0390,\n",
              "                       0.1306,  0.0171, -0.0427, -0.1761,  0.0592, -0.1153,  0.0211, -0.0660,\n",
              "                      -0.0482, -0.0248, -0.1125,  0.1049, -0.1456, -0.0806, -0.0097, -0.0801,\n",
              "                      -0.0169, -0.0325,  0.0121, -0.0064, -0.1119, -0.1641,  0.1193,  0.0298,\n",
              "                      -0.1309, -0.0612, -0.1455,  0.0886, -0.0343, -0.0957, -0.1152, -0.0509,\n",
              "                      -0.1465, -0.0278,  0.0410, -0.0510, -0.0010,  0.0402,  0.0057, -0.0157,\n",
              "                      -0.1253,  0.0664, -0.0831, -0.0449,  0.0071, -0.0556, -0.0576, -0.0465,\n",
              "                       0.0367, -0.1802,  0.0015, -0.0650, -0.0704, -0.0518,  0.0086,  0.0647,\n",
              "                      -0.0532,  0.0904, -0.2027, -0.1070, -0.1120,  0.0043, -0.0905, -0.0854,\n",
              "                      -0.0017, -0.0650, -0.1490, -0.0050, -0.0153, -0.0330, -0.2340, -0.0609,\n",
              "                      -0.0172, -0.1693,  0.0154, -0.1381,  0.0716, -0.1153, -0.0553, -0.1681,\n",
              "                      -0.0143,  0.0200, -0.1483,  0.0764, -0.0832,  0.0226, -0.0145, -0.0410,\n",
              "                      -0.0645, -0.1053, -0.0732, -0.1120, -0.0055, -0.0018,  0.0721, -0.0362,\n",
              "                      -0.1156,  0.1003, -0.0278, -0.1974, -0.1285, -0.0004, -0.0253, -0.0252],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.downsample.1.running_var',\n",
              "              tensor([0.0149, 0.0366, 0.0236, 0.0477, 0.0094, 0.0145, 0.0414, 0.0327, 0.0178,\n",
              "                      0.0108, 0.0075, 0.0147, 0.0256, 0.0078, 0.0196, 0.0219, 0.0385, 0.0349,\n",
              "                      0.0225, 0.0208, 0.0145, 0.0420, 0.0393, 0.0267, 0.0217, 0.0050, 0.0376,\n",
              "                      0.0209, 0.0412, 0.0169, 0.0315, 0.0518, 0.0182, 0.0176, 0.0229, 0.0213,\n",
              "                      0.0195, 0.0295, 0.0498, 0.0236, 0.0289, 0.0365, 0.0346, 0.0339, 0.0243,\n",
              "                      0.0119, 0.0177, 0.0497, 0.0132, 0.0226, 0.0170, 0.0317, 0.0130, 0.0160,\n",
              "                      0.0246, 0.0417, 0.0235, 0.0292, 0.0228, 0.0110, 0.0266, 0.0442, 0.0101,\n",
              "                      0.0213, 0.0138, 0.0397, 0.0172, 0.0093, 0.0325, 0.0206, 0.0240, 0.0192,\n",
              "                      0.0172, 0.0051, 0.0318, 0.0161, 0.0423, 0.0387, 0.0223, 0.0177, 0.0351,\n",
              "                      0.0238, 0.0189, 0.0129, 0.0193, 0.0136, 0.0202, 0.0429, 0.0212, 0.0154,\n",
              "                      0.0180, 0.0265, 0.0203, 0.0407, 0.0193, 0.0194, 0.0475, 0.0165, 0.0227,\n",
              "                      0.0174, 0.0272, 0.0115, 0.0155, 0.0289, 0.0277, 0.0472, 0.0176, 0.0275,\n",
              "                      0.0161, 0.0451, 0.0252, 0.0111, 0.0214, 0.0411, 0.0225, 0.0343, 0.0092,\n",
              "                      0.0822, 0.0319, 0.0201, 0.0144, 0.0146, 0.0038, 0.0148, 0.0113, 0.0158,\n",
              "                      0.0152, 0.0114, 0.0366, 0.0122, 0.0302, 0.0152, 0.0147, 0.0237, 0.0519,\n",
              "                      0.0318, 0.0073, 0.0248, 0.0170, 0.0285, 0.0227, 0.0581, 0.0193, 0.0142,\n",
              "                      0.0230, 0.0244, 0.0314, 0.0427, 0.0122, 0.0320, 0.0154, 0.0098, 0.0405,\n",
              "                      0.0221, 0.0139, 0.0198, 0.0298, 0.0291, 0.0167, 0.0234, 0.0275, 0.0412,\n",
              "                      0.0175, 0.0804, 0.0304, 0.0069, 0.0283, 0.0189, 0.0236, 0.0265, 0.0184,\n",
              "                      0.0238, 0.0202, 0.0270, 0.0201, 0.0294, 0.0417, 0.0156, 0.0167, 0.0113,\n",
              "                      0.0448, 0.0305, 0.0351, 0.0154, 0.0338, 0.0299, 0.0289, 0.0111, 0.0161,\n",
              "                      0.0187, 0.0288, 0.0422, 0.0731, 0.0307, 0.0150, 0.0247, 0.0246, 0.0322,\n",
              "                      0.0428, 0.0105, 0.0111, 0.0263, 0.0298, 0.0201, 0.0257, 0.0306, 0.0184,\n",
              "                      0.0481, 0.0239, 0.0315, 0.0195, 0.0137, 0.0102, 0.0208, 0.0143, 0.0180,\n",
              "                      0.0283, 0.0312, 0.0146, 0.0163, 0.0444, 0.0535, 0.0190, 0.0191, 0.0288,\n",
              "                      0.0125, 0.0115, 0.0135, 0.0352, 0.0200, 0.0110, 0.0169, 0.0196, 0.0565,\n",
              "                      0.0187, 0.0342, 0.0104, 0.0407, 0.0244, 0.0047, 0.0128, 0.0098, 0.0462,\n",
              "                      0.0374, 0.0157, 0.0172, 0.0189, 0.0285, 0.0116, 0.0187, 0.0268, 0.0311,\n",
              "                      0.0471, 0.0274, 0.0132, 0.0229, 0.0436, 0.0217, 0.0087, 0.0328, 0.0177,\n",
              "                      0.0228, 0.0065, 0.0354, 0.0291, 0.0185, 0.0283, 0.0256, 0.0362, 0.0425,\n",
              "                      0.0147, 0.0166, 0.0201, 0.0294, 0.0396, 0.0171, 0.0198, 0.0199, 0.0141,\n",
              "                      0.0166, 0.0173, 0.0196, 0.0166, 0.0406, 0.0074, 0.0187, 0.0200, 0.0270,\n",
              "                      0.0088, 0.0125, 0.0291, 0.0350, 0.0357, 0.0202, 0.0192, 0.0175, 0.0339,\n",
              "                      0.0264, 0.0203, 0.0152, 0.0635, 0.0293, 0.0143, 0.0188, 0.0233, 0.0279,\n",
              "                      0.0052, 0.0229, 0.0154, 0.0181, 0.0302, 0.0202, 0.0276, 0.0354, 0.0139,\n",
              "                      0.0132, 0.0178, 0.0403, 0.0243, 0.0056, 0.0149, 0.0107, 0.0286, 0.0296,\n",
              "                      0.0172, 0.0302, 0.0084, 0.0177, 0.0113, 0.0164, 0.0203, 0.0316, 0.0213,\n",
              "                      0.0157, 0.0197, 0.0222, 0.0114, 0.0247, 0.0242, 0.0112, 0.0081, 0.0070,\n",
              "                      0.0372, 0.0408, 0.0093, 0.0125, 0.0182, 0.0386, 0.0127, 0.0088, 0.0191,\n",
              "                      0.0232, 0.0341, 0.0190, 0.0210, 0.0339, 0.0237, 0.0270, 0.0268, 0.0224,\n",
              "                      0.0222, 0.0226, 0.0095, 0.0146, 0.0299, 0.0350, 0.0172, 0.0398, 0.0503,\n",
              "                      0.0046, 0.0180, 0.0104, 0.0385, 0.0150, 0.0121, 0.0103, 0.0246, 0.0427,\n",
              "                      0.0346, 0.0283, 0.0168, 0.0286, 0.0298, 0.0260, 0.0246, 0.0163, 0.0280,\n",
              "                      0.0270, 0.0361, 0.0233, 0.0191, 0.0174, 0.0209, 0.0100, 0.0456, 0.0246,\n",
              "                      0.0254, 0.0212, 0.0119, 0.0241, 0.0314, 0.0282, 0.0164, 0.0299, 0.0544,\n",
              "                      0.0218, 0.0189, 0.0125, 0.0241, 0.0112, 0.0258, 0.0115, 0.0301, 0.0159,\n",
              "                      0.0143, 0.0253, 0.0306, 0.0185, 0.0256, 0.0255, 0.0127, 0.0191, 0.0169,\n",
              "                      0.0191, 0.0070, 0.0276, 0.0243, 0.0140, 0.0073, 0.0169, 0.0431, 0.0099,\n",
              "                      0.0343, 0.0142, 0.0417, 0.0204, 0.0191, 0.0246, 0.0186, 0.0095, 0.0101,\n",
              "                      0.0177, 0.0226, 0.0290, 0.0197, 0.0241, 0.0139, 0.0151, 0.0274, 0.0258,\n",
              "                      0.0224, 0.0313, 0.0210, 0.0183, 0.0229, 0.0043, 0.0197, 0.0360, 0.0333,\n",
              "                      0.0298, 0.0355, 0.0090, 0.0136, 0.0112, 0.0512, 0.0158, 0.0255, 0.0181,\n",
              "                      0.0147, 0.0243, 0.0129, 0.0348, 0.0150, 0.0134, 0.0516, 0.0213, 0.0229,\n",
              "                      0.0161, 0.0282, 0.0224, 0.0330, 0.0106, 0.0174, 0.0137, 0.0383, 0.0077,\n",
              "                      0.0284, 0.0275, 0.0427, 0.0131, 0.0291, 0.0384, 0.0118, 0.0149, 0.0110,\n",
              "                      0.0300, 0.0229, 0.0138, 0.0273, 0.0186, 0.0317, 0.0139, 0.0449, 0.0248,\n",
              "                      0.0188, 0.0347, 0.0172, 0.0205, 0.0135, 0.0365, 0.0184, 0.0125],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.0.downsample.1.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('layer4.1.conv1.weight', tensor([[[[-0.0127, -0.0101,  0.0039],\n",
              "                        [ 0.0013, -0.0108,  0.0096],\n",
              "                        [ 0.0113,  0.0128,  0.0225]],\n",
              "              \n",
              "                       [[-0.0025,  0.0110,  0.0091],\n",
              "                        [-0.0199, -0.0172, -0.0129],\n",
              "                        [-0.0124, -0.0046, -0.0042]],\n",
              "              \n",
              "                       [[-0.0131, -0.0153,  0.0015],\n",
              "                        [-0.0183, -0.0304, -0.0126],\n",
              "                        [-0.0127, -0.0267, -0.0223]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0077, -0.0033, -0.0128],\n",
              "                        [ 0.0068,  0.0058,  0.0143],\n",
              "                        [-0.0105, -0.0104, -0.0077]],\n",
              "              \n",
              "                       [[ 0.0073,  0.0046, -0.0142],\n",
              "                        [-0.0082,  0.0009, -0.0190],\n",
              "                        [-0.0029,  0.0073, -0.0116]],\n",
              "              \n",
              "                       [[ 0.0202,  0.0224,  0.0223],\n",
              "                        [ 0.0267,  0.0288,  0.0344],\n",
              "                        [ 0.0101, -0.0049,  0.0061]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0125, -0.0104, -0.0246],\n",
              "                        [-0.0124, -0.0043, -0.0202],\n",
              "                        [-0.0214, -0.0057, -0.0184]],\n",
              "              \n",
              "                       [[-0.0263, -0.0225, -0.0309],\n",
              "                        [-0.0395, -0.0261, -0.0282],\n",
              "                        [-0.0257, -0.0192, -0.0213]],\n",
              "              \n",
              "                       [[-0.0047,  0.0016, -0.0064],\n",
              "                        [-0.0065, -0.0020, -0.0054],\n",
              "                        [-0.0078, -0.0106, -0.0118]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0183, -0.0021,  0.0113],\n",
              "                        [-0.0050, -0.0203, -0.0148],\n",
              "                        [ 0.0221,  0.0068,  0.0048]],\n",
              "              \n",
              "                       [[-0.0187, -0.0005, -0.0076],\n",
              "                        [-0.0175, -0.0077, -0.0166],\n",
              "                        [-0.0165, -0.0242, -0.0300]],\n",
              "              \n",
              "                       [[-0.0307, -0.0139, -0.0000],\n",
              "                        [-0.0131, -0.0049, -0.0193],\n",
              "                        [-0.0135, -0.0155, -0.0044]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0323, -0.0053, -0.0204],\n",
              "                        [-0.0236,  0.0004, -0.0282],\n",
              "                        [-0.0269,  0.0026, -0.0295]],\n",
              "              \n",
              "                       [[-0.0062, -0.0150, -0.0012],\n",
              "                        [-0.0182, -0.0270, -0.0244],\n",
              "                        [-0.0077, -0.0156, -0.0090]],\n",
              "              \n",
              "                       [[-0.0003, -0.0088, -0.0056],\n",
              "                        [-0.0009, -0.0107, -0.0089],\n",
              "                        [ 0.0056, -0.0022,  0.0047]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0203, -0.0351, -0.0208],\n",
              "                        [-0.0105, -0.0319, -0.0253],\n",
              "                        [-0.0101, -0.0213, -0.0198]],\n",
              "              \n",
              "                       [[ 0.0050,  0.0192,  0.0116],\n",
              "                        [ 0.0023,  0.0096,  0.0099],\n",
              "                        [ 0.0076, -0.0050, -0.0046]],\n",
              "              \n",
              "                       [[-0.0107, -0.0160, -0.0236],\n",
              "                        [-0.0144, -0.0097, -0.0161],\n",
              "                        [-0.0265,  0.0127,  0.0135]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-0.0283, -0.0319, -0.0387],\n",
              "                        [-0.0188, -0.0077, -0.0154],\n",
              "                        [-0.0147, -0.0174, -0.0189]],\n",
              "              \n",
              "                       [[-0.0042, -0.0131, -0.0030],\n",
              "                        [-0.0072, -0.0079, -0.0115],\n",
              "                        [-0.0033,  0.0037, -0.0067]],\n",
              "              \n",
              "                       [[-0.0036, -0.0053,  0.0063],\n",
              "                        [-0.0044, -0.0037,  0.0048],\n",
              "                        [ 0.0118,  0.0277,  0.0232]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0001,  0.0013,  0.0051],\n",
              "                        [-0.0153, -0.0241, -0.0184],\n",
              "                        [-0.0271, -0.0317, -0.0332]],\n",
              "              \n",
              "                       [[ 0.0151,  0.0057,  0.0126],\n",
              "                        [-0.0062, -0.0285, -0.0170],\n",
              "                        [-0.0181, -0.0482, -0.0262]],\n",
              "              \n",
              "                       [[-0.0194, -0.0068,  0.0108],\n",
              "                        [-0.0003,  0.0101,  0.0196],\n",
              "                        [-0.0060, -0.0146, -0.0126]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0107,  0.0102, -0.0015],\n",
              "                        [-0.0030, -0.0005, -0.0104],\n",
              "                        [-0.0195, -0.0143, -0.0075]],\n",
              "              \n",
              "                       [[ 0.0074, -0.0028, -0.0168],\n",
              "                        [ 0.0038, -0.0058, -0.0160],\n",
              "                        [-0.0050, -0.0117, -0.0147]],\n",
              "              \n",
              "                       [[ 0.0276,  0.0092,  0.0242],\n",
              "                        [ 0.0110, -0.0114,  0.0028],\n",
              "                        [ 0.0063, -0.0185, -0.0061]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0081, -0.0035, -0.0044],\n",
              "                        [ 0.0096,  0.0016,  0.0073],\n",
              "                        [ 0.0150,  0.0181,  0.0212]],\n",
              "              \n",
              "                       [[ 0.0019,  0.0008,  0.0207],\n",
              "                        [-0.0073, -0.0049,  0.0052],\n",
              "                        [-0.0180, -0.0144, -0.0098]],\n",
              "              \n",
              "                       [[-0.0091, -0.0072, -0.0073],\n",
              "                        [ 0.0078,  0.0007,  0.0070],\n",
              "                        [-0.0112,  0.0023,  0.0141]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0022, -0.0007,  0.0095],\n",
              "                        [ 0.0096, -0.0006,  0.0078],\n",
              "                        [ 0.0072,  0.0001, -0.0005]],\n",
              "              \n",
              "                       [[-0.0130,  0.0059, -0.0160],\n",
              "                        [ 0.0252,  0.0224,  0.0339],\n",
              "                        [ 0.0006, -0.0022,  0.0116]],\n",
              "              \n",
              "                       [[-0.0283, -0.0129, -0.0164],\n",
              "                        [-0.0160, -0.0174, -0.0139],\n",
              "                        [ 0.0015,  0.0145, -0.0119]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0082, -0.0217, -0.0229],\n",
              "                        [ 0.0064, -0.0002,  0.0014],\n",
              "                        [-0.0065,  0.0096, -0.0031]],\n",
              "              \n",
              "                       [[ 0.0096,  0.0228,  0.0332],\n",
              "                        [ 0.0282,  0.0266,  0.0447],\n",
              "                        [-0.0234, -0.0020, -0.0086]],\n",
              "              \n",
              "                       [[-0.0080, -0.0080, -0.0056],\n",
              "                        [-0.0003, -0.0060, -0.0093],\n",
              "                        [ 0.0042, -0.0008, -0.0053]]]], device='cuda:0')),\n",
              "             ('layer4.1.bn1.weight',\n",
              "              tensor([0.2847, 0.2821, 0.2620, 0.3198, 0.2891, 0.3420, 0.2623, 0.2744, 0.3226,\n",
              "                      0.2885, 0.3256, 0.3130, 0.3355, 0.2846, 0.3348, 0.3577, 0.3122, 0.4580,\n",
              "                      0.2190, 0.3373, 0.2579, 0.2987, 0.3172, 0.3171, 0.4295, 0.2891, 0.3640,\n",
              "                      0.3487, 0.3563, 0.3566, 0.2757, 0.3097, 0.2616, 0.3137, 0.3461, 0.3379,\n",
              "                      0.3479, 0.2818, 0.2553, 0.3133, 0.2963, 0.3939, 0.2505, 0.2087, 0.3028,\n",
              "                      0.2729, 0.3074, 0.3150, 0.2789, 0.3274, 0.2940, 0.1985, 0.2843, 0.3751,\n",
              "                      0.2634, 0.3182, 0.3182, 0.2204, 0.3372, 0.3076, 0.3298, 0.3102, 0.2439,\n",
              "                      0.3447, 0.3569, 0.2826, 0.2332, 0.3243, 0.2994, 0.2934, 0.3285, 0.3419,\n",
              "                      0.3574, 0.3291, 0.2587, 0.3421, 0.3487, 0.2809, 0.3357, 0.3490, 0.2712,\n",
              "                      0.3047, 0.4091, 0.3343, 0.3094, 0.3593, 0.3805, 0.4407, 0.2432, 0.2472,\n",
              "                      0.3073, 0.3975, 0.2755, 0.3635, 0.3884, 0.2661, 0.3489, 0.2864, 0.3700,\n",
              "                      0.2045, 0.2695, 0.2728, 0.3737, 0.3286, 0.2453, 0.2274, 0.2641, 0.2771,\n",
              "                      0.3708, 0.2417, 0.3834, 0.2673, 0.2858, 0.2752, 0.3067, 0.1691, 0.4049,\n",
              "                      0.2286, 0.3542, 0.3299, 0.2937, 0.1762, 0.3410, 0.2843, 0.2151, 0.3299,\n",
              "                      0.3041, 0.3649, 0.2619, 0.3711, 0.2288, 0.2788, 0.2210, 0.3309, 0.2744,\n",
              "                      0.3558, 0.3293, 0.3051, 0.3284, 0.3260, 0.2707, 0.2908, 0.4089, 0.3504,\n",
              "                      0.3749, 0.3850, 0.3233, 0.2984, 0.2249, 0.2323, 0.1947, 0.2371, 0.3188,\n",
              "                      0.3195, 0.2325, 0.2994, 0.2652, 0.3434, 0.2516, 0.3598, 0.2228, 0.2982,\n",
              "                      0.3482, 0.2665, 0.2780, 0.3038, 0.2429, 0.3301, 0.3173, 0.2965, 0.2254,\n",
              "                      0.2859, 0.2623, 0.3026, 0.3236, 0.3633, 0.3208, 0.3588, 0.2311, 0.2827,\n",
              "                      0.3570, 0.2720, 0.4174, 0.3355, 0.3609, 0.2724, 0.2946, 0.3136, 0.2959,\n",
              "                      0.3741, 0.3461, 0.3884, 0.2870, 0.2935, 0.2913, 0.3102, 0.1377, 0.2427,\n",
              "                      0.2304, 0.2879, 0.2726, 0.2710, 0.2955, 0.3127, 0.3003, 0.3499, 0.2852,\n",
              "                      0.3131, 0.3764, 0.2850, 0.2968, 0.3494, 0.3142, 0.2932, 0.3493, 0.3026,\n",
              "                      0.2658, 0.2336, 0.3563, 0.2963, 0.3242, 0.3038, 0.2353, 0.3126, 0.2739,\n",
              "                      0.3638, 0.2741, 0.3079, 0.3763, 0.2853, 0.3259, 0.3387, 0.3512, 0.3082,\n",
              "                      0.3729, 0.3745, 0.3715, 0.2808, 0.3069, 0.3153, 0.2962, 0.1632, 0.2198,\n",
              "                      0.4080, 0.3530, 0.2903, 0.3285, 0.3351, 0.3172, 0.2116, 0.3803, 0.2907,\n",
              "                      0.3048, 0.2690, 0.2206, 0.2912, 0.3238, 0.2958, 0.2343, 0.1518, 0.2565,\n",
              "                      0.2849, 0.3432, 0.3585, 0.3100, 0.3370, 0.3233, 0.3331, 0.3394, 0.2759,\n",
              "                      0.2187, 0.1923, 0.3225, 0.2926, 0.2988, 0.2936, 0.3255, 0.3449, 0.2813,\n",
              "                      0.3116, 0.3808, 0.3020, 0.3503, 0.3088, 0.3815, 0.3094, 0.2118, 0.2666,\n",
              "                      0.3152, 0.3215, 0.3044, 0.2788, 0.3514, 0.3675, 0.3282, 0.3291, 0.2217,\n",
              "                      0.2961, 0.2956, 0.3092, 0.2590, 0.4026, 0.3088, 0.2591, 0.3227, 0.2397,\n",
              "                      0.3776, 0.3050, 0.3610, 0.3507, 0.3302, 0.2708, 0.3127, 0.3064, 0.2353,\n",
              "                      0.3290, 0.3026, 0.3547, 0.2190, 0.3626, 0.3504, 0.3074, 0.2750, 0.2449,\n",
              "                      0.3369, 0.3838, 0.1763, 0.2918, 0.3152, 0.3482, 0.2941, 0.3361, 0.2476,\n",
              "                      0.2699, 0.2737, 0.3780, 0.3587, 0.3171, 0.3808, 0.2794, 0.2700, 0.3020,\n",
              "                      0.3818, 0.3446, 0.2485, 0.3227, 0.2341, 0.3251, 0.2167, 0.3672, 0.3073,\n",
              "                      0.3163, 0.2628, 0.2928, 0.3542, 0.2922, 0.3143, 0.2639, 0.2600, 0.2547,\n",
              "                      0.3632, 0.2693, 0.2518, 0.3330, 0.3286, 0.2052, 0.3429, 0.3142, 0.2903,\n",
              "                      0.2896, 0.2534, 0.3076, 0.3108, 0.2744, 0.3050, 0.2148, 0.2961, 0.3053,\n",
              "                      0.2999, 0.2703, 0.2804, 0.3491, 0.3199, 0.3611, 0.2105, 0.3235, 0.3876,\n",
              "                      0.3196, 0.3331, 0.2869, 0.2653, 0.2616, 0.2901, 0.2877, 0.3036, 0.3510,\n",
              "                      0.2159, 0.2762, 0.3314, 0.2603, 0.1994, 0.2938, 0.2763, 0.2779, 0.2660,\n",
              "                      0.3911, 0.3777, 0.2565, 0.2656, 0.2041, 0.2858, 0.3633, 0.3209, 0.2078,\n",
              "                      0.3091, 0.2861, 0.2150, 0.2864, 0.3168, 0.2756, 0.2746, 0.3160, 0.2805,\n",
              "                      0.2898, 0.3272, 0.2856, 0.2120, 0.3049, 0.3408, 0.2795, 0.3806, 0.3587,\n",
              "                      0.2517, 0.3129, 0.2674, 0.1704, 0.2849, 0.3003, 0.1951, 0.3099, 0.3048,\n",
              "                      0.2584, 0.2810, 0.2648, 0.3165, 0.3322, 0.2800, 0.2553, 0.4050, 0.2302,\n",
              "                      0.2466, 0.3215, 0.3435, 0.3060, 0.3326, 0.1867, 0.3013, 0.2984, 0.3297,\n",
              "                      0.2864, 0.3381, 0.1403, 0.2852, 0.2118, 0.2889, 0.2867, 0.2252, 0.3034,\n",
              "                      0.3093, 0.2400, 0.3181, 0.3233, 0.3247, 0.2556, 0.2409, 0.3338, 0.3327,\n",
              "                      0.3094, 0.3071, 0.3147, 0.2556, 0.3445, 0.2817, 0.3040, 0.2708, 0.2896,\n",
              "                      0.3348, 0.4024, 0.3856, 0.3176, 0.2926, 0.3681, 0.3696, 0.2481, 0.2861,\n",
              "                      0.3373, 0.3236, 0.3295, 0.3745, 0.1908, 0.2930, 0.3334, 0.3004, 0.3435,\n",
              "                      0.2880, 0.3080, 0.3103, 0.3777, 0.3219, 0.2825, 0.3273, 0.2523],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.1.bn1.bias',\n",
              "              tensor([-0.1472, -0.3125, -0.2058, -0.2873, -0.1522, -0.1861, -0.1826, -0.1526,\n",
              "                      -0.2282, -0.1274, -0.2298, -0.2217, -0.1078, -0.2618, -0.3073, -0.3694,\n",
              "                      -0.2952, -0.4632,  0.0344, -0.2276, -0.1926, -0.1924, -0.2765, -0.2395,\n",
              "                      -0.4988, -0.1711, -0.4977, -0.2476, -0.4670, -0.3917, -0.2171, -0.1390,\n",
              "                      -0.0962, -0.2746, -0.3069, -0.3185, -0.3158, -0.1628, -0.0198, -0.1844,\n",
              "                      -0.1642, -0.1972, -0.1749, -0.1707, -0.1855, -0.2208, -0.2344, -0.2568,\n",
              "                      -0.3119, -0.1405, -0.1766,  0.0033, -0.2620, -0.3998, -0.1445, -0.1538,\n",
              "                      -0.3336, -0.1665, -0.2809, -0.2011, -0.3132, -0.2533, -0.1342, -0.3185,\n",
              "                      -0.3888, -0.2019, -0.0303, -0.2453, -0.2809, -0.1958, -0.1506, -0.4590,\n",
              "                      -0.3316, -0.3131, -0.3093, -0.1499, -0.3219, -0.2020, -0.2670, -0.2562,\n",
              "                      -0.1430, -0.1881, -0.3817, -0.2131, -0.1888, -0.3678, -0.3553, -0.5916,\n",
              "                      -0.1695, -0.1761, -0.2126, -0.5028, -0.2476, -0.1363, -0.4142, -0.2017,\n",
              "                      -0.2836, -0.2728, -0.3977, -0.0573, -0.1940, -0.0972, -0.3027, -0.2409,\n",
              "                      -0.2547, -0.0889, -0.1341, -0.2949, -0.3036, -0.1690, -0.5127, -0.1987,\n",
              "                      -0.1475, -0.1723, -0.2060, -0.2257, -0.3033, -0.0550, -0.2928, -0.1268,\n",
              "                      -0.1392, -0.0085, -0.3054, -0.1575, -0.0645, -0.2004, -0.1569, -0.3681,\n",
              "                      -0.2239, -0.2501, -0.0068, -0.3116, -0.0443, -0.2474, -0.2140, -0.5202,\n",
              "                      -0.2809, -0.1750, -0.2923, -0.1635, -0.1679, -0.2358, -0.5671, -0.1763,\n",
              "                      -0.3224, -0.2984, -0.1762, -0.3711, -0.0585, -0.1408,  0.0080, -0.1146,\n",
              "                      -0.2976, -0.3092, -0.1010, -0.2538, -0.2639, -0.2904, -0.1257, -0.3863,\n",
              "                      -0.0339, -0.2192, -0.4244, -0.2494, -0.1255, -0.2186, -0.1499, -0.3533,\n",
              "                      -0.3473, -0.2004, -0.0698, -0.1806, -0.0840, -0.2426, -0.2595, -0.3001,\n",
              "                      -0.2171, -0.3809, -0.0787, -0.1043, -0.3543, -0.2342, -0.3288, -0.2530,\n",
              "                      -0.4400,  0.0170, -0.1150, -0.2188, -0.1480, -0.4376, -0.1738, -0.4454,\n",
              "                      -0.3401, -0.2797, -0.1600, -0.1778,  0.0914, -0.0119, -0.0996, -0.1725,\n",
              "                       0.0450, -0.2155, -0.1278, -0.2152, -0.2694, -0.2332, -0.3571, -0.2439,\n",
              "                      -0.4516, -0.2375, -0.2446, -0.1427, -0.2649, -0.3009, -0.4120, -0.2460,\n",
              "                      -0.1760,  0.0431, -0.2151, -0.1522, -0.2819, -0.3396, -0.1849, -0.1285,\n",
              "                      -0.2030, -0.4869, -0.2061, -0.1557, -0.4486, -0.2552, -0.1050, -0.2531,\n",
              "                      -0.1881, -0.2210, -0.2394, -0.4217, -0.2433, -0.1321, -0.1775, -0.1601,\n",
              "                      -0.1259,  0.0902, -0.0729, -0.4361, -0.3394, -0.1965, -0.2186, -0.2262,\n",
              "                      -0.2608, -0.0292, -0.3330, -0.3015, -0.2401, -0.2328, -0.1236, -0.2539,\n",
              "                      -0.1885, -0.1762, -0.1533,  0.0537, -0.0826, -0.2542, -0.2808, -0.3069,\n",
              "                      -0.3522, -0.3554, -0.3485, -0.3318, -0.3646, -0.0726, -0.0780,  0.0365,\n",
              "                      -0.2533, -0.2735, -0.1651, -0.2940, -0.1570, -0.3926, -0.2138, -0.2177,\n",
              "                      -0.4238, -0.1842, -0.4846, -0.3081, -0.3198, -0.1937, -0.0121, -0.1019,\n",
              "                      -0.3146, -0.1244, -0.2268,  0.0590, -0.2811, -0.2238, -0.3041, -0.2385,\n",
              "                      -0.2285, -0.1669, -0.3009, -0.1384,  0.0329, -0.3551, -0.2565,  0.0250,\n",
              "                      -0.2899, -0.0758, -0.2456, -0.3157, -0.2748, -0.3112, -0.4506, -0.2061,\n",
              "                      -0.1613, -0.2025, -0.0385, -0.1931, -0.1827, -0.2447,  0.0103, -0.3004,\n",
              "                      -0.2305, -0.1948, -0.1308, -0.1780, -0.2491, -0.3856,  0.0927, -0.1055,\n",
              "                      -0.2359, -0.3051, -0.2400, -0.2805, -0.0497, -0.1268, -0.2009, -0.5583,\n",
              "                      -0.2464, -0.2693, -0.5044, -0.0565, -0.1612, -0.2263, -0.4290, -0.2785,\n",
              "                      -0.1576, -0.3535, -0.0969, -0.2627, -0.1229, -0.2760, -0.2220, -0.1747,\n",
              "                      -0.2558, -0.1426, -0.3235, -0.1185, -0.2614, -0.0952,  0.0122, -0.1886,\n",
              "                      -0.2257, -0.1585, -0.1727, -0.1338, -0.3427, -0.0225, -0.2767, -0.2384,\n",
              "                      -0.1511, -0.3271, -0.1102, -0.2700, -0.1967, -0.2533, -0.2694, -0.0222,\n",
              "                      -0.2308, -0.0270, -0.2508, -0.1419, -0.1437, -0.2330, -0.2525, -0.4235,\n",
              "                       0.0151, -0.1928, -0.3028, -0.2088, -0.4476, -0.2532, -0.1723, -0.3078,\n",
              "                      -0.3463, -0.2836, -0.2991, -0.2345,  0.0035, -0.1686, -0.4376, -0.2181,\n",
              "                       0.0616, -0.2148, -0.2158, -0.0542, -0.2743, -0.3635, -0.3028, -0.1135,\n",
              "                      -0.3824,  0.0555, -0.1875, -0.2366, -0.2717, -0.0673, -0.1277, -0.3056,\n",
              "                       0.0431, -0.3136, -0.2831, -0.1534, -0.1518, -0.2507, -0.1920, -0.3153,\n",
              "                      -0.2689, -0.1914, -0.1921, -0.2456, -0.1809, -0.1848, -0.3206, -0.4468,\n",
              "                      -0.2834, -0.3076, -0.1650,  0.0261, -0.1959, -0.2487, -0.0313, -0.1691,\n",
              "                      -0.2406, -0.2119, -0.3039, -0.2559, -0.1940, -0.3279, -0.1431, -0.1363,\n",
              "                      -0.3826, -0.2234, -0.0884, -0.1992, -0.3019, -0.2589, -0.2459,  0.0252,\n",
              "                      -0.3094, -0.1991, -0.2520, -0.2441, -0.4074,  0.0466, -0.3109, -0.0844,\n",
              "                      -0.2072, -0.1271, -0.1957, -0.2159, -0.2401, -0.0658, -0.2017, -0.2653,\n",
              "                      -0.2032, -0.0329, -0.1858, -0.3811, -0.3366, -0.1256, -0.2674, -0.2972,\n",
              "                      -0.1189, -0.2771, -0.2125, -0.2423, -0.3304, -0.1068, -0.2579, -0.3632,\n",
              "                      -0.2300, -0.3143, -0.1313, -0.1873, -0.1888, -0.1393, -0.0463, -0.3565,\n",
              "                      -0.2084, -0.3161, -0.4111, -0.0026, -0.1937, -0.2032, -0.1003, -0.4937,\n",
              "                      -0.1530, -0.2628, -0.1959, -0.4132, -0.2129, -0.1638, -0.0837, -0.1335],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.1.bn1.running_mean',\n",
              "              tensor([-0.5706, -0.9052, -0.4699, -0.6853, -0.8662, -0.4345, -0.7400, -0.6066,\n",
              "                      -0.2902, -0.4527, -0.4004, -0.5712, -0.5421, -0.7364, -0.5825, -0.5784,\n",
              "                      -0.6132, -0.6935, -0.7595, -0.5260, -0.5130, -0.3962, -0.5705, -0.4467,\n",
              "                      -0.8086, -0.7784, -0.5019, -0.5397, -0.4164, -0.5671, -0.5574, -0.6042,\n",
              "                      -0.7301, -0.8737, -0.7258, -0.6491, -0.6805, -0.6460, -0.5115, -0.4332,\n",
              "                      -0.4829, -0.5855, -0.5152, -0.7185, -0.6728, -0.6513, -0.4414, -0.6085,\n",
              "                      -0.7163, -0.4113, -0.6856, -0.7631, -0.7310, -0.8347, -0.6691, -0.6052,\n",
              "                      -0.4165, -0.4417, -0.6383, -0.6058, -0.5578, -0.4390, -0.6225, -0.5255,\n",
              "                      -0.4302, -0.5586, -0.6244, -0.4405, -0.8660, -0.5932, -0.5899, -0.7659,\n",
              "                      -0.7676, -0.6826, -0.8502, -0.4875, -0.6810, -0.5599, -0.7230, -0.5778,\n",
              "                      -0.6764, -0.6551, -0.7071, -0.5872, -0.5041, -0.5562, -0.5221, -1.3083,\n",
              "                      -0.8937, -0.8717, -0.7372, -0.4929, -0.6946, -0.5880, -0.8392, -0.4684,\n",
              "                      -0.5287, -0.6707, -0.5176, -0.6109, -0.7355, -0.5708, -0.4853, -0.7023,\n",
              "                      -0.6124, -0.8542, -0.6092, -0.7189, -0.5704, -0.7469, -0.7038, -0.7464,\n",
              "                      -0.4731, -0.6114, -0.6519,  1.1809, -0.6666, -0.5143, -0.6826, -0.6020,\n",
              "                      -0.4107, -0.9014, -0.6308, -0.4632, -0.7041, -0.6465, -0.4923, -0.6060,\n",
              "                      -0.6780, -0.5606, -0.8098, -0.6056, -0.7321, -0.6462, -0.6756, -0.6500,\n",
              "                      -0.4427, -0.6569, -0.4910, -0.5234, -0.5077, -0.4150, -0.8412, -0.6528,\n",
              "                      -0.6720, -0.4698, -0.4077, -0.6809, -0.7173, -0.3676, -0.7943, -0.3674,\n",
              "                      -0.4924, -0.7465, -0.4605, -0.5290, -0.6927, -0.7708, -0.5961, -0.6835,\n",
              "                      -0.6052, -0.6787, -0.7889, -0.7263, -0.9475, -0.5484, -0.6433, -0.6522,\n",
              "                      -0.4876, -0.6017, -0.2691, -0.4971, -0.3041, -0.6672, -0.6799, -0.5630,\n",
              "                      -0.4833, -0.5803, -0.5870, -0.7512, -0.5873, -0.6227, -0.4911, -0.5870,\n",
              "                      -0.6323, -0.5737, -0.5212, -0.7818, -0.6253, -0.6300, -0.5750, -0.6936,\n",
              "                      -0.5084, -0.7795, -0.3984, -0.5824,  0.4646, -0.4766, -0.5575, -0.6726,\n",
              "                      -0.4338, -0.7000, -0.3733, -0.7302, -0.6110, -0.6507, -0.7034, -0.6564,\n",
              "                      -0.5815, -0.5318, -0.6926, -0.5943, -0.8840, -0.6685, -0.7766, -0.6823,\n",
              "                      -0.4052, -0.4851, -0.4729, -0.4691, -0.4140, -0.5133, -0.5902, -0.3183,\n",
              "                      -0.6018, -0.6986, -0.9609, -0.6831, -0.5054, -0.5906, -0.6163, -0.9646,\n",
              "                      -0.6697, -0.7564, -0.5369, -0.8222, -0.7727, -0.4712, -0.3465, -0.6821,\n",
              "                      -0.5539, -0.3770, -0.5258, -0.7399, -0.5866, -0.3446, -0.5215, -0.4035,\n",
              "                      -0.4246, -0.7508, -0.4159, -0.4884, -0.6114, -0.7323, -0.5221, -0.5908,\n",
              "                      -0.4840, -0.5178, -0.6337, -0.5701, -0.6013, -0.4078, -0.5539, -0.7116,\n",
              "                      -0.8048, -0.6169, -0.6956, -0.7452, -0.6963, -0.4534, -0.4675, -0.6070,\n",
              "                      -0.5927, -0.7520, -0.6237, -0.7696, -0.5769, -0.6042, -0.7113, -0.5525,\n",
              "                      -0.7779, -0.4714, -0.7264, -0.5770, -0.6641, -0.6432, -0.5753, -0.5363,\n",
              "                      -0.8946, -0.6429, -0.4930, -0.7529, -0.4926, -0.4806, -0.6028, -0.4674,\n",
              "                      -0.7254, -0.5204, -0.7939, -0.5396, -0.8718, -0.7238, -0.5622, -0.8179,\n",
              "                      -0.5767, -0.5822, -0.8174, -0.7808, -0.7523, -0.7862, -0.8341, -0.6099,\n",
              "                      -0.6284, -0.5637, -0.6232, -0.5174, -0.6820, -0.7727, -0.6365, -0.3646,\n",
              "                      -0.7145, -0.4175, -0.1486, -0.6806, -0.8829, -0.6007, -0.2743, -0.5591,\n",
              "                      -0.4357, -0.5740, -0.3254, -0.6634, -0.5908, -0.5979, -0.7493, -0.8520,\n",
              "                      -0.4725, -0.4948, -0.5376, -0.5573, -0.6343, -0.6530, -0.7127, -0.7318,\n",
              "                      -0.3788, -0.7993, -0.4771, -0.5336, -0.4861, -0.5965, -0.4355, -0.4826,\n",
              "                      -0.6446, -0.6472, -0.7016, -0.7553, -0.4579, -0.3672, -0.5739, -0.6588,\n",
              "                      -0.5086, -0.8029, -0.7605, -0.5771, -0.8460, -0.7728, -0.7207, -0.6397,\n",
              "                      -0.4676, -0.5798, -0.5008, -0.6754, -0.6244, -0.9053, -0.6822, -0.6588,\n",
              "                      -0.4187, -0.7224, -0.6028, -0.5116, -0.5983, -0.6336, -0.4849, -0.5994,\n",
              "                      -0.6760, -0.8631, -0.4576, -0.5535, -0.6803, -0.4722, -0.8250, -0.7930,\n",
              "                      -0.5697, -0.8155, -0.4623, -0.5837, -0.5093, -0.5756, -0.7223, -0.6818,\n",
              "                      -0.0942, -0.5172, -0.8725, -0.6523, -0.6039, -0.7434, -0.8657, -0.4666,\n",
              "                      -0.5865, -0.5278, -0.7824, -0.5593, -0.6404, -0.2173, -0.4993, -0.5797,\n",
              "                      -0.5014, -0.6560, -0.5601, -0.6635, -0.4645, -0.4987, -0.6115, -0.5354,\n",
              "                      -0.6237, -0.6213, -0.5188, -0.6253, -0.4544, -0.6589, -0.6489, -0.8891,\n",
              "                      -0.8429, -0.5786, -0.7178, -0.3839, -0.5329, -0.5100, -0.5215, -0.5137,\n",
              "                      -0.4559, -0.5036, -0.5598, -0.7122, -0.7151, -0.5122, -0.7519, -0.4295,\n",
              "                      -0.7370, -0.6332, -0.4648, -0.4867, -0.7977, -0.7104, -0.6555, -0.9159,\n",
              "                      -0.6594, -0.4973, -0.4719, -0.6333, -0.9222, -0.4701, -0.5679, -0.6512,\n",
              "                      -0.8329, -0.6279, -0.7330, -0.6579, -0.5653, -0.7888, -0.5767, -0.7624,\n",
              "                      -0.5664, -0.6773, -0.6719, -0.7822, -0.8555, -0.5959, -0.5567, -0.6255,\n",
              "                      -0.4681, -0.8663, -0.4917, -0.5358, -0.7524, -0.7548, -0.5517, -0.7100,\n",
              "                      -0.7349, -0.4180, -0.5144, -0.4717, -0.5122, -0.7097, -0.5460, -0.6548,\n",
              "                      -0.5870, -0.8089, -0.8393, -0.5704, -0.4478, -0.5730, -0.6063, -0.8911,\n",
              "                      -0.7940, -0.5579, -0.5657, -0.7658, -0.5748, -0.7221, -0.5358, -0.8525],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.1.bn1.running_var',\n",
              "              tensor([0.1982, 0.1536, 0.1297, 0.1437, 0.1798, 0.1750, 0.1564, 0.1879, 0.1725,\n",
              "                      0.1644, 0.1298, 0.1545, 0.2127, 0.1454, 0.1297, 0.1560, 0.1347, 0.2201,\n",
              "                      0.2321, 0.1449, 0.1561, 0.1267, 0.1348, 0.1420, 0.1219, 0.1637, 0.1283,\n",
              "                      0.1600, 0.1359, 0.1350, 0.1364, 0.1792, 0.1675, 0.2058, 0.1543, 0.1565,\n",
              "                      0.1432, 0.2139, 0.1975, 0.1746, 0.1482, 0.2530, 0.1202, 0.1582, 0.1878,\n",
              "                      0.1498, 0.1547, 0.1626, 0.1251, 0.1529, 0.1692, 0.2262, 0.1241, 0.1786,\n",
              "                      0.1633, 0.1866, 0.1485, 0.1371, 0.1611, 0.2055, 0.1613, 0.1370, 0.1728,\n",
              "                      0.1495, 0.0913, 0.1216, 0.1907, 0.1134, 0.1415, 0.1378, 0.1612, 0.1318,\n",
              "                      0.1519, 0.1723, 0.1151, 0.1830, 0.1290, 0.1503, 0.1697, 0.1506, 0.1904,\n",
              "                      0.2183, 0.1669, 0.2184, 0.1329, 0.1701, 0.2050, 0.1820, 0.1615, 0.1641,\n",
              "                      0.1586, 0.1080, 0.1944, 0.2189, 0.1913, 0.1928, 0.1220, 0.1425, 0.1399,\n",
              "                      0.1646, 0.1876, 0.2431, 0.1710, 0.1474, 0.1633, 0.1803, 0.2387, 0.1230,\n",
              "                      0.1237, 0.1786, 0.1248, 0.1231, 0.1240, 0.1933, 0.1711, 0.1752, 0.1510,\n",
              "                      0.2158, 0.1410, 0.1471, 0.1692, 0.1954, 0.1659, 0.1379, 0.1492, 0.1892,\n",
              "                      0.1285, 0.1543, 0.1544, 0.1845, 0.1649, 0.1248, 0.1906, 0.1474, 0.1454,\n",
              "                      0.0926, 0.1112, 0.1922, 0.1320, 0.2099, 0.1312, 0.1476, 0.1464, 0.1602,\n",
              "                      0.1705, 0.1868, 0.1430, 0.1108, 0.2976, 0.1447, 0.2111, 0.1431, 0.1782,\n",
              "                      0.1517, 0.1390, 0.1477, 0.1300, 0.1493, 0.1204, 0.1395, 0.1432, 0.1212,\n",
              "                      0.1383, 0.1908, 0.1951, 0.1893, 0.1299, 0.1501, 0.1592, 0.1320, 0.0968,\n",
              "                      0.1987, 0.2213, 0.1494, 0.1475, 0.1723, 0.2217, 0.1647, 0.1357, 0.2419,\n",
              "                      0.1328, 0.1751, 0.1900, 0.1160, 0.1300, 0.1972, 0.1639, 0.1340, 0.1846,\n",
              "                      0.1474, 0.1655, 0.1203, 0.1107, 0.1391, 0.1532, 0.1699, 0.1841, 0.1558,\n",
              "                      0.2085, 0.2247, 0.1759, 0.1763, 0.1605, 0.1414, 0.1545, 0.1483, 0.1409,\n",
              "                      0.1817, 0.1299, 0.1282, 0.1371, 0.2546, 0.1594, 0.1413, 0.1507, 0.1632,\n",
              "                      0.1237, 0.2241, 0.1584, 0.1528, 0.1350, 0.1680, 0.1103, 0.2053, 0.2019,\n",
              "                      0.1286, 0.2138, 0.1452, 0.1309, 0.1297, 0.2644, 0.1646, 0.2042, 0.1487,\n",
              "                      0.1724, 0.1615, 0.2182, 0.1739, 0.1596, 0.2043, 0.1786, 0.1690, 0.1335,\n",
              "                      0.1593, 0.1101, 0.1873, 0.2004, 0.1937, 0.1428, 0.1869, 0.1779, 0.1508,\n",
              "                      0.1738, 0.1315, 0.1590, 0.1438, 0.1352, 0.1826, 0.1778, 0.1802, 0.1879,\n",
              "                      0.1348, 0.1505, 0.1628, 0.1024, 0.1793, 0.1340, 0.1431, 0.1431, 0.2035,\n",
              "                      0.1203, 0.1936, 0.1699, 0.1192, 0.2516, 0.1578, 0.2009, 0.1335, 0.2001,\n",
              "                      0.1219, 0.1732, 0.1664, 0.1128, 0.1215, 0.1287, 0.1537, 0.1753, 0.2114,\n",
              "                      0.2232, 0.1413, 0.1634, 0.2051, 0.1769, 0.1702, 0.1386, 0.1509, 0.1436,\n",
              "                      0.1765, 0.1550, 0.1799, 0.2828, 0.1604, 0.1714, 0.2514, 0.1324, 0.1618,\n",
              "                      0.2158, 0.1449, 0.1507, 0.1554, 0.1229, 0.1128, 0.2396, 0.1282, 0.1480,\n",
              "                      0.1430, 0.1721, 0.1410, 0.2120, 0.1484, 0.1842, 0.1949, 0.1418, 0.1213,\n",
              "                      0.1464, 0.1313, 0.2221, 0.1356, 0.1657, 0.1553, 0.1724, 0.1516, 0.1817,\n",
              "                      0.1797, 0.1773, 0.1189, 0.1527, 0.1611, 0.1471, 0.1837, 0.2101, 0.1741,\n",
              "                      0.1437, 0.1808, 0.1566, 0.1599, 0.1556, 0.2035, 0.2091, 0.1624, 0.1415,\n",
              "                      0.1623, 0.1280, 0.2202, 0.1752, 0.1525, 0.1822, 0.1518, 0.1928, 0.1807,\n",
              "                      0.2402, 0.2416, 0.1879, 0.2632, 0.1822, 0.1694, 0.1374, 0.1671, 0.1534,\n",
              "                      0.1347, 0.1423, 0.1525, 0.2021, 0.1714, 0.1613, 0.2592, 0.1558, 0.1727,\n",
              "                      0.1851, 0.1618, 0.1534, 0.1448, 0.1479, 0.1199, 0.1835, 0.1993, 0.2173,\n",
              "                      0.1688, 0.1042, 0.1295, 0.2055, 0.1394, 0.1334, 0.1304, 0.1448, 0.1461,\n",
              "                      0.1551, 0.1357, 0.1423, 0.1617, 0.3177, 0.1643, 0.2061, 0.2083, 0.1243,\n",
              "                      0.1525, 0.2271, 0.1446, 0.1113, 0.2163, 0.1810, 0.1764, 0.1579, 0.1367,\n",
              "                      0.1488, 0.1311, 0.1244, 0.1246, 0.1571, 0.2229, 0.1515, 0.1887, 0.1370,\n",
              "                      0.1274, 0.1313, 0.1612, 0.1160, 0.1466, 0.1868, 0.1463, 0.1326, 0.1686,\n",
              "                      0.1383, 0.1302, 0.1535, 0.1551, 0.1225, 0.1517, 0.1282, 0.1618, 0.1355,\n",
              "                      0.1382, 0.1243, 0.1213, 0.1442, 0.1032, 0.2061, 0.2470, 0.1681, 0.1798,\n",
              "                      0.1460, 0.1268, 0.1907, 0.1630, 0.1865, 0.2447, 0.1267, 0.1533, 0.1789,\n",
              "                      0.1320, 0.1618, 0.1623, 0.1235, 0.1997, 0.1526, 0.1611, 0.1268, 0.1319,\n",
              "                      0.1262, 0.2007, 0.1657, 0.1614, 0.1902, 0.1946, 0.1672, 0.1264, 0.1885,\n",
              "                      0.1942, 0.1424, 0.1140, 0.1465, 0.2181, 0.1727, 0.1309, 0.1432, 0.1894,\n",
              "                      0.1815, 0.2024, 0.2351, 0.1482, 0.2396, 0.1756, 0.2186, 0.1579, 0.2276,\n",
              "                      0.1423, 0.1645, 0.1350, 0.1342, 0.1705, 0.1288, 0.1543, 0.1956, 0.1151,\n",
              "                      0.2013, 0.1823, 0.2325, 0.1470, 0.1737, 0.1644, 0.2339, 0.2265],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.1.bn1.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('layer4.1.conv2.weight', tensor([[[[ 0.0062,  0.0110,  0.0032],\n",
              "                        [ 0.0070,  0.0096, -0.0002],\n",
              "                        [ 0.0099,  0.0146,  0.0056]],\n",
              "              \n",
              "                       [[-0.0112, -0.0128, -0.0094],\n",
              "                        [-0.0041, -0.0038, -0.0019],\n",
              "                        [-0.0061, -0.0068, -0.0073]],\n",
              "              \n",
              "                       [[-0.0093, -0.0105, -0.0087],\n",
              "                        [-0.0090, -0.0089, -0.0068],\n",
              "                        [-0.0096, -0.0071, -0.0048]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0110, -0.0128, -0.0140],\n",
              "                        [-0.0088, -0.0095, -0.0123],\n",
              "                        [-0.0085, -0.0089, -0.0101]],\n",
              "              \n",
              "                       [[ 0.0026,  0.0043,  0.0016],\n",
              "                        [ 0.0035,  0.0049,  0.0057],\n",
              "                        [ 0.0099,  0.0102,  0.0092]],\n",
              "              \n",
              "                       [[-0.0098, -0.0137, -0.0132],\n",
              "                        [-0.0076, -0.0106, -0.0083],\n",
              "                        [-0.0038, -0.0060, -0.0062]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0051,  0.0030,  0.0023],\n",
              "                        [-0.0025, -0.0051, -0.0061],\n",
              "                        [-0.0049, -0.0062, -0.0098]],\n",
              "              \n",
              "                       [[-0.0151, -0.0128, -0.0147],\n",
              "                        [-0.0098, -0.0068, -0.0122],\n",
              "                        [-0.0072, -0.0083, -0.0108]],\n",
              "              \n",
              "                       [[ 0.0024,  0.0016, -0.0008],\n",
              "                        [-0.0002,  0.0015, -0.0012],\n",
              "                        [ 0.0048,  0.0027,  0.0055]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0299,  0.0234,  0.0250],\n",
              "                        [ 0.0288,  0.0191,  0.0244],\n",
              "                        [ 0.0255,  0.0212,  0.0214]],\n",
              "              \n",
              "                       [[ 0.0176,  0.0193,  0.0220],\n",
              "                        [ 0.0122,  0.0122,  0.0169],\n",
              "                        [ 0.0134,  0.0099,  0.0153]],\n",
              "              \n",
              "                       [[ 0.0299,  0.0268,  0.0314],\n",
              "                        [ 0.0370,  0.0310,  0.0373],\n",
              "                        [ 0.0258,  0.0262,  0.0251]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0081, -0.0017, -0.0037],\n",
              "                        [-0.0003,  0.0063,  0.0036],\n",
              "                        [-0.0005,  0.0057,  0.0046]],\n",
              "              \n",
              "                       [[-0.0005, -0.0002,  0.0000],\n",
              "                        [ 0.0045,  0.0064,  0.0051],\n",
              "                        [-0.0008,  0.0014,  0.0023]],\n",
              "              \n",
              "                       [[-0.0336, -0.0284, -0.0335],\n",
              "                        [-0.0370, -0.0290, -0.0307],\n",
              "                        [-0.0370, -0.0317, -0.0303]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0069, -0.0031, -0.0069],\n",
              "                        [-0.0089, -0.0032, -0.0038],\n",
              "                        [-0.0074, -0.0003, -0.0040]],\n",
              "              \n",
              "                       [[ 0.0109,  0.0079,  0.0143],\n",
              "                        [ 0.0015, -0.0008,  0.0051],\n",
              "                        [-0.0043, -0.0039, -0.0022]],\n",
              "              \n",
              "                       [[-0.0135, -0.0155, -0.0139],\n",
              "                        [-0.0152, -0.0190, -0.0173],\n",
              "                        [-0.0067, -0.0092, -0.0087]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0024,  0.0011,  0.0010],\n",
              "                        [-0.0078, -0.0027, -0.0047],\n",
              "                        [-0.0088, -0.0042, -0.0042]],\n",
              "              \n",
              "                       [[ 0.0033,  0.0011,  0.0005],\n",
              "                        [ 0.0105,  0.0112,  0.0091],\n",
              "                        [ 0.0180,  0.0162,  0.0144]],\n",
              "              \n",
              "                       [[-0.0001, -0.0060, -0.0061],\n",
              "                        [-0.0058, -0.0046, -0.0073],\n",
              "                        [-0.0078, -0.0060, -0.0066]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0206, -0.0182, -0.0171],\n",
              "                        [-0.0160, -0.0156, -0.0136],\n",
              "                        [-0.0168, -0.0182, -0.0149]],\n",
              "              \n",
              "                       [[ 0.0022,  0.0054, -0.0022],\n",
              "                        [ 0.0024,  0.0068, -0.0012],\n",
              "                        [-0.0064, -0.0007, -0.0071]],\n",
              "              \n",
              "                       [[-0.0046, -0.0132, -0.0096],\n",
              "                        [ 0.0005, -0.0066, -0.0078],\n",
              "                        [-0.0031, -0.0040, -0.0067]]],\n",
              "              \n",
              "              \n",
              "                      [[[-0.0185, -0.0176, -0.0212],\n",
              "                        [-0.0166, -0.0129, -0.0206],\n",
              "                        [-0.0118, -0.0112, -0.0188]],\n",
              "              \n",
              "                       [[ 0.0193,  0.0213,  0.0239],\n",
              "                        [ 0.0171,  0.0116,  0.0222],\n",
              "                        [ 0.0217,  0.0163,  0.0245]],\n",
              "              \n",
              "                       [[-0.0078, -0.0051, -0.0040],\n",
              "                        [-0.0105, -0.0085, -0.0079],\n",
              "                        [-0.0060, -0.0041, -0.0041]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 0.0208,  0.0110,  0.0137],\n",
              "                        [ 0.0195,  0.0128,  0.0139],\n",
              "                        [ 0.0247,  0.0263,  0.0242]],\n",
              "              \n",
              "                       [[ 0.0052,  0.0118,  0.0089],\n",
              "                        [ 0.0116,  0.0149,  0.0104],\n",
              "                        [ 0.0004,  0.0018, -0.0009]],\n",
              "              \n",
              "                       [[ 0.0113,  0.0264,  0.0165],\n",
              "                        [ 0.0064,  0.0169,  0.0089],\n",
              "                        [-0.0073,  0.0052, -0.0048]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 0.0128,  0.0113,  0.0097],\n",
              "                        [ 0.0061,  0.0055,  0.0023],\n",
              "                        [-0.0015,  0.0023, -0.0037]],\n",
              "              \n",
              "                       [[-0.0075,  0.0007, -0.0060],\n",
              "                        [-0.0104, -0.0045, -0.0093],\n",
              "                        [-0.0097, -0.0065, -0.0107]],\n",
              "              \n",
              "                       [[ 0.0253,  0.0199,  0.0259],\n",
              "                        [ 0.0211,  0.0121,  0.0172],\n",
              "                        [ 0.0249,  0.0219,  0.0249]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-0.0153, -0.0160, -0.0180],\n",
              "                        [-0.0088, -0.0103, -0.0092],\n",
              "                        [-0.0115, -0.0151, -0.0135]],\n",
              "              \n",
              "                       [[ 0.0055, -0.0006,  0.0023],\n",
              "                        [ 0.0015, -0.0059, -0.0034],\n",
              "                        [-0.0012, -0.0058, -0.0031]],\n",
              "              \n",
              "                       [[-0.0140, -0.0131, -0.0110],\n",
              "                        [-0.0061, -0.0033, -0.0036],\n",
              "                        [ 0.0041,  0.0062,  0.0048]]]], device='cuda:0')),\n",
              "             ('layer4.1.bn2.weight',\n",
              "              tensor([1.8505, 1.8471, 1.7832, 1.8485, 1.9726, 1.8192, 1.9739, 2.2944, 1.7851,\n",
              "                      1.9111, 1.7956, 1.7944, 1.9282, 1.7437, 1.8952, 1.8329, 1.8160, 2.3672,\n",
              "                      1.8190, 1.7459, 1.8122, 1.9821, 1.9064, 1.9236, 1.8998, 1.9991, 1.8708,\n",
              "                      1.8131, 1.9192, 1.9050, 1.7907, 2.0110, 1.8624, 1.7831, 1.8888, 1.8956,\n",
              "                      1.9149, 1.8420, 1.7109, 1.7522, 1.7976, 1.7198, 1.7946, 1.8075, 1.7813,\n",
              "                      1.8549, 1.9436, 2.0992, 1.9155, 1.8604, 1.8670, 1.8848, 1.7810, 1.8673,\n",
              "                      1.7702, 1.9694, 1.9824, 1.8934, 1.9650, 1.8879, 1.8876, 1.9595, 1.8937,\n",
              "                      1.9408, 1.7617, 1.8723, 1.6669, 2.0978, 2.0583, 1.9322, 1.9220, 1.7742,\n",
              "                      1.7809, 1.9792, 1.8089, 1.8113, 1.8016, 1.8009, 1.8317, 1.8164, 1.8383,\n",
              "                      1.8282, 1.8887, 2.1744, 1.7886, 1.8095, 1.8271, 1.7385, 1.7886, 1.7936,\n",
              "                      1.6434, 1.8863, 1.9330, 1.8803, 1.7137, 1.8196, 1.7310, 1.7940, 1.8774,\n",
              "                      1.7267, 2.0826, 1.9208, 1.9529, 1.8237, 1.7550, 1.6200, 1.9356, 1.9209,\n",
              "                      1.8228, 1.9200, 1.8461, 1.7806, 1.8115, 1.8333, 1.8710, 1.8631, 1.7285,\n",
              "                      2.1993, 1.8764, 1.8394, 1.8432, 1.8605, 1.8129, 1.6396, 1.8691, 1.8463,\n",
              "                      1.8935, 1.9512, 1.7063, 1.9984, 1.9117, 1.9106, 1.8994, 1.8658, 2.0109,\n",
              "                      2.0759, 1.8521, 1.8709, 1.8897, 1.8096, 1.7261, 1.9867, 1.8069, 1.9443,\n",
              "                      1.9191, 1.9139, 1.8916, 1.8138, 1.8887, 1.9613, 1.7548, 1.8108, 1.9819,\n",
              "                      1.7852, 1.6986, 1.9626, 1.9825, 2.0009, 1.8137, 1.8342, 1.8638, 2.1553,\n",
              "                      1.9520, 2.3874, 2.0480, 1.9777, 1.7496, 1.9278, 1.8471, 1.8028, 1.9235,\n",
              "                      1.8170, 1.9340, 1.9759, 1.8404, 1.6526, 1.9351, 1.9313, 2.0169, 1.8218,\n",
              "                      1.9374, 1.7738, 2.2014, 1.8114, 1.7780, 1.9061, 2.0037, 1.9392, 1.8175,\n",
              "                      1.8553, 1.8520, 1.8360, 1.9330, 1.8824, 1.8021, 1.8348, 1.8233, 1.7204,\n",
              "                      1.7878, 1.8194, 1.7787, 1.9530, 2.0328, 1.7429, 2.0454, 1.9145, 1.8541,\n",
              "                      1.8392, 1.7970, 1.9314, 1.7352, 1.7280, 1.9332, 1.7977, 2.0092, 1.8658,\n",
              "                      1.8209, 1.8781, 1.8022, 1.9831, 1.9799, 1.9483, 1.8301, 1.8288, 1.7306,\n",
              "                      1.8212, 1.8694, 1.9405, 1.7825, 1.8553, 1.8693, 1.8435, 1.8522, 1.9076,\n",
              "                      1.8006, 1.8033, 1.7983, 2.0220, 1.7190, 1.9694, 1.7975, 1.8199, 2.2398,\n",
              "                      1.6651, 1.8539, 2.1948, 1.9356, 1.7554, 1.7867, 1.8904, 1.9289, 1.9137,\n",
              "                      1.8583, 1.9626, 1.8390, 2.2505, 1.8456, 2.0877, 2.0059, 1.8344, 1.8640,\n",
              "                      1.9907, 1.8224, 1.8779, 1.8705, 1.7922, 1.9191, 1.7384, 1.7698, 1.9101,\n",
              "                      1.8083, 1.9678, 1.8931, 1.7380, 2.0663, 1.7853, 1.8774, 1.7872, 1.9389,\n",
              "                      1.8349, 2.4303, 1.7448, 1.8006, 1.7561, 1.8662, 1.8588, 1.8974, 1.7747,\n",
              "                      1.9904, 2.0030, 1.7290, 1.7653, 1.8477, 2.0094, 1.8670, 1.9220, 1.8442,\n",
              "                      1.9975, 1.7878, 1.6289, 1.8263, 1.9792, 1.7440, 1.7275, 1.9061, 1.8154,\n",
              "                      1.9251, 1.8500, 1.8202, 1.9332, 1.9072, 1.9133, 1.9455, 1.7549, 1.7837,\n",
              "                      1.8150, 2.0119, 1.7857, 1.9172, 1.8613, 1.7276, 1.8932, 1.8731, 1.9439,\n",
              "                      1.8963, 1.7474, 1.8590, 1.9262, 1.8112, 1.8445, 1.7789, 2.0612, 1.9486,\n",
              "                      1.9432, 1.9107, 1.7819, 1.6968, 1.8556, 1.9073, 1.8572, 1.8467, 1.7701,\n",
              "                      1.6315, 1.8572, 1.7631, 1.8609, 1.9702, 1.7717, 1.7914, 1.8928, 1.9147,\n",
              "                      1.7936, 1.7738, 1.8019, 1.8581, 1.7098, 1.8338, 1.9064, 1.8514, 1.8549,\n",
              "                      1.8723, 1.9878, 1.8911, 1.7854, 1.9196, 1.8310, 1.8698, 1.8456, 1.8876,\n",
              "                      1.9807, 1.8507, 1.9731, 1.9780, 1.8155, 1.7815, 1.9370, 1.7271, 1.7708,\n",
              "                      1.9657, 1.8769, 1.9239, 1.7858, 1.7913, 1.8714, 1.8696, 1.8987, 1.7818,\n",
              "                      2.0954, 1.8189, 1.7179, 1.9146, 1.9677, 1.8674, 1.8088, 1.8487, 1.8709,\n",
              "                      1.6931, 1.7615, 1.9280, 1.9760, 2.0550, 1.9129, 1.8673, 1.7771, 1.7937,\n",
              "                      1.8383, 1.8670, 1.9582, 1.7480, 1.8883, 1.9813, 1.9262, 1.7567, 1.8002,\n",
              "                      1.8686, 2.0430, 1.7224, 1.8959, 1.8867, 1.8853, 1.8176, 1.8872, 1.8595,\n",
              "                      1.7789, 1.8343, 2.0028, 1.9205, 2.1441, 1.8613, 1.9449, 1.8984, 1.9605,\n",
              "                      1.8688, 1.8533, 2.0173, 2.1043, 1.8487, 1.7916, 1.8241, 1.7689, 1.9154,\n",
              "                      1.8824, 1.8786, 1.7517, 1.8364, 1.9790, 1.9033, 1.9010, 2.0213, 1.7262,\n",
              "                      1.7972, 1.9659, 1.8519, 1.8561, 1.7428, 1.8998, 1.7782, 1.9653, 1.8276,\n",
              "                      1.9122, 2.0491, 1.9030, 1.9585, 1.8861, 1.8637, 1.7964, 1.9653, 1.8564,\n",
              "                      2.0647, 1.9727, 1.8488, 1.8359, 1.7976, 1.9169, 1.9027, 1.8909, 1.8713,\n",
              "                      1.7847, 1.9642, 1.7793, 1.7666, 1.8848, 1.7085, 1.8195, 1.8879, 2.0320,\n",
              "                      1.8596, 1.9191, 1.9795, 1.8502, 1.9194, 1.8382, 1.9886, 1.9104, 1.8907,\n",
              "                      1.8903, 1.7141, 1.8922, 1.9053, 1.9373, 1.8804, 1.6609, 1.8586, 1.7620,\n",
              "                      1.8692, 1.5935, 1.9443, 1.9696, 1.8041, 1.7539, 2.1189, 1.9641],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.1.bn2.bias',\n",
              "              tensor([0.2401, 0.3474, 0.3361, 0.4733, 0.2352, 0.2456, 0.2222, 0.3887, 0.3220,\n",
              "                      0.2911, 0.2524, 0.2212, 0.2608, 0.2438, 0.2383, 0.3190, 0.2830, 0.6641,\n",
              "                      0.3034, 0.2392, 0.2365, 0.4407, 0.2392, 0.3427, 0.2735, 0.2267, 0.3234,\n",
              "                      0.4017, 0.1528, 0.2377, 0.3432, 0.0960, 0.2413, 0.2639, 0.2078, 0.2021,\n",
              "                      0.2666, 0.3377, 0.2788, 0.3204, 0.2454, 0.2672, 0.2011, 0.3393, 0.2188,\n",
              "                      0.2397, 0.2389, 0.5078, 0.2905, 0.1995, 0.3397, 0.2862, 0.2433, 0.2578,\n",
              "                      0.3678, 0.2251, 0.4799, 0.3116, 0.3829, 0.2688, 0.2078, 0.2720, 0.3519,\n",
              "                      0.2106, 0.2509, 0.4401, 0.2758, 0.1829, 0.3211, 0.1261, 0.2284, 0.1665,\n",
              "                      0.3075, 0.1539, 0.3039, 0.2767, 0.2097, 0.3065, 0.2336, 0.2363, 0.2591,\n",
              "                      0.4039, 0.4740, 0.5520, 0.2195, 0.3550, 0.2831, 0.2309, 0.3765, 0.2785,\n",
              "                      0.2528, 0.2591, 0.1811, 0.2889, 0.2690, 0.2228, 0.3429, 0.2891, 0.2629,\n",
              "                      0.3093, 0.2690, 0.3584, 0.3024, 0.3977, 0.3239, 0.2300, 0.2794, 0.2266,\n",
              "                      0.2205, 0.2871, 0.2459, 0.3535, 0.2329, 0.2973, 0.2114, 0.2985, 0.3374,\n",
              "                      0.0816, 0.3136, 0.3124, 0.3949, 0.2629, 0.2445, 0.3116, 0.2807, 0.1608,\n",
              "                      0.2279, 0.2676, 0.3205, 0.2885, 0.1890, 0.2075, 0.1165, 0.2389, 0.3886,\n",
              "                      0.2510, 0.2050, 0.3236, 0.2598, 0.2533, 0.3077, 0.2034, 0.3060, 0.1994,\n",
              "                      0.2250, 0.1692, 0.1693, 0.4012, 0.2402, 0.4014, 0.2800, 0.2960, 0.1907,\n",
              "                      0.2781, 0.3045, 0.1841, 0.2722, 0.2728, 0.2139, 0.1912, 0.3353, 0.6509,\n",
              "                      0.2797, 0.4020, 0.2168, 0.2413, 0.4218, 0.2177, 0.3066, 0.3618, 0.2379,\n",
              "                      0.2437, 0.1485, 0.1158, 0.2819, 0.3262, 0.2409, 0.1770, 0.4158, 0.2157,\n",
              "                      0.1968, 0.3089, 0.5824, 0.3309, 0.3951, 0.3336, 0.1888, 0.3037, 0.2447,\n",
              "                      0.2566, 0.2101, 0.2160, 0.3368, 0.4875, 0.2617, 0.2625, 0.3401, 0.2330,\n",
              "                      0.3156, 0.2409, 0.2500, 0.2598, 0.4220, 0.2654, 0.3744, 0.2805, 0.2231,\n",
              "                      0.2091, 0.3194, 0.3824, 0.1843, 0.2104, 0.2436, 0.3730, 0.2702, 0.2756,\n",
              "                      0.2935, 0.1549, 0.1954, 0.2883, 0.2012, 0.3408, 0.2837, 0.2251, 0.3118,\n",
              "                      0.1902, 0.4085, 0.1796, 0.4462, 0.2909, 0.2817, 0.2834, 0.2017, 0.3701,\n",
              "                      0.2136, 0.3417, 0.3436, 0.2808, 0.2849, 0.3289, 0.2728, 0.2566, 0.2081,\n",
              "                      0.2932, 0.3134, 0.2185, 0.2944, 0.2454, 0.3276, 0.3597, 0.4369, 0.2573,\n",
              "                      0.2956, 0.1963, 0.3067, 0.5729, 0.2176, 0.3904, 0.2991, 0.3932, 0.3185,\n",
              "                      0.2221, 0.2795, 0.2992, 0.1942, 0.3121, 0.1774, 0.3036, 0.3164, 0.2629,\n",
              "                      0.2573, 0.1881, 0.2777, 0.2921, 0.1571, 0.2932, 0.3247, 0.2691, 0.2474,\n",
              "                      0.1577, 0.5555, 0.2619, 0.2940, 0.2957, 0.1661, 0.2093, 0.2109, 0.2459,\n",
              "                      0.2669, 0.1706, 0.3298, 0.2929, 0.1684, 0.1550, 0.2896, 0.1726, 0.3368,\n",
              "                      0.5089, 0.2918, 0.3266, 0.1861, 0.2240, 0.2265, 0.2868, 0.4407, 0.2801,\n",
              "                      0.1844, 0.3169, 0.2426, 0.1860, 0.4018, 0.2947, 0.4889, 0.2410, 0.2387,\n",
              "                      0.2808, 0.2743, 0.2900, 0.4032, 0.1582, 0.3368, 0.3405, 0.2904, 0.2358,\n",
              "                      0.1857, 0.3379, 0.3210, 0.1911, 0.2443, 0.2206, 0.3327, 0.3396, 0.2342,\n",
              "                      0.2211, 0.2775, 0.2405, 0.3460, 0.2852, 0.3305, 0.2992, 0.2038, 0.1486,\n",
              "                      0.4032, 0.5207, 0.3488, 0.1942, 0.1894, 0.2764, 0.1932, 0.2290, 0.1668,\n",
              "                      0.2657, 0.2526, 0.2831, 0.2467, 0.2527, 0.2570, 0.3640, 0.2821, 0.1593,\n",
              "                      0.2660, 0.2818, 0.1839, 0.2759, 0.4164, 0.2349, 0.3815, 0.3175, 0.3202,\n",
              "                      0.1944, 0.4441, 0.2278, 0.2103, 0.2871, 0.3097, 0.2227, 0.3341, 0.2354,\n",
              "                      0.2862, 0.3160, 0.4588, 0.2979, 0.3548, 0.3382, 0.4291, 0.2775, 0.2372,\n",
              "                      0.3050, 0.1927, 0.4000, 0.2962, 0.2583, 0.1711, 0.3809, 0.4544, 0.2814,\n",
              "                      0.3078, 0.2909, 0.2536, 0.2230, 0.4361, 0.4407, 0.2091, 0.2997, 0.3510,\n",
              "                      0.2590, 0.2958, 0.2644, 0.2635, 0.1755, 0.2015, 0.2701, 0.3053, 0.2529,\n",
              "                      0.3865, 0.2386, 0.2547, 0.2328, 0.1853, 0.2373, 0.2139, 0.2935, 0.2996,\n",
              "                      0.2987, 0.3358, 0.1760, 0.3079, 0.3385, 0.2593, 0.2889, 0.2252, 0.2694,\n",
              "                      0.2061, 0.2720, 0.2502, 0.5228, 0.2613, 0.3246, 0.2272, 0.2400, 0.2111,\n",
              "                      0.1991, 0.2228, 0.3969, 0.4025, 0.2474, 0.3686, 0.2452, 0.3338, 0.3541,\n",
              "                      0.3275, 0.2116, 0.3149, 0.2366, 0.3101, 0.2765, 0.3500, 0.2716, 0.2780,\n",
              "                      0.2453, 0.4447, 0.2053, 0.2073, 0.2195, 0.3297, 0.2743, 0.2429, 0.2440,\n",
              "                      0.2352, 0.2687, 0.2904, 0.4146, 0.2838, 0.2319, 0.1713, 0.2026, 0.2039,\n",
              "                      0.2590, 0.1205, 0.3220, 0.3326, 0.3653, 0.3086, 0.2144, 0.4809, 0.3125,\n",
              "                      0.3470, 0.3028, 0.4961, 0.2361, 0.3686, 0.4112, 0.2503, 0.1980, 0.1614,\n",
              "                      0.1960, 0.2791, 0.2495, 0.3112, 0.2400, 0.2794, 0.3363, 0.2833, 0.2921,\n",
              "                      0.2399, 0.3075, 0.4891, 0.3163, 0.3252, 0.3227, 0.3714, 0.2927],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.1.bn2.running_mean',\n",
              "              tensor([-0.0335, -0.0647, -0.0751, -0.0007, -0.0395,  0.0163, -0.0407, -0.0266,\n",
              "                       0.1413, -0.0061, -0.0046,  0.0206, -0.0825,  0.0492,  0.0362, -0.0570,\n",
              "                      -0.0653, -0.1117,  0.0390, -0.0685,  0.0203, -0.0099, -0.0012, -0.0423,\n",
              "                       0.0233,  0.0015,  0.0381,  0.0239, -0.0153, -0.0664, -0.0583,  0.0364,\n",
              "                      -0.0301, -0.0445, -0.0050, -0.0227, -0.0202, -0.0251,  0.0194, -0.0634,\n",
              "                      -0.0750, -0.0169, -0.0742,  0.0019, -0.0358, -0.0758,  0.0208,  0.1669,\n",
              "                      -0.0206, -0.0422, -0.0141,  0.0287,  0.0001, -0.0147, -0.0130,  0.0228,\n",
              "                      -0.0257,  0.0038, -0.0778, -0.0557,  0.0170, -0.0378, -0.0482, -0.0071,\n",
              "                      -0.0367, -0.0126,  0.0182, -0.0414, -0.0844, -0.0144,  0.0040, -0.0310,\n",
              "                       0.0110, -0.0186, -0.0418, -0.0867, -0.0122, -0.0326, -0.0542, -0.0508,\n",
              "                      -0.0458,  0.0115, -0.0262,  0.1154, -0.0583, -0.0553,  0.0483, -0.0322,\n",
              "                      -0.0346,  0.0204, -0.0408, -0.0100,  0.0026, -0.0218, -0.0184, -0.0003,\n",
              "                       0.0182, -0.0747, -0.0529, -0.0062, -0.0060, -0.0386, -0.0123, -0.0373,\n",
              "                       0.0083,  0.0206, -0.0526, -0.0280,  0.0095,  0.0048,  0.0074, -0.0426,\n",
              "                      -0.0442, -0.0371, -0.0867, -0.0082, -0.0427,  0.0777, -0.0137, -0.0056,\n",
              "                      -0.0452,  0.0400, -0.0133,  0.0495,  0.0020,  0.0005, -0.0278,  0.0041,\n",
              "                      -0.0045, -0.0007, -0.0420, -0.0428, -0.0314, -0.0330, -0.0700, -0.0997,\n",
              "                      -0.0268, -0.0304, -0.0181, -0.0081, -0.0115,  0.0125, -0.0091, -0.0698,\n",
              "                      -0.0851,  0.0079,  0.0097,  0.0193, -0.0105, -0.0865, -0.0221,  0.0131,\n",
              "                      -0.0136, -0.0394, -0.0536, -0.0269, -0.0190,  0.0193, -0.0039,  0.0009,\n",
              "                      -0.0190, -0.0976, -0.0255,  0.1491, -0.0649,  0.0156,  0.0330, -0.0746,\n",
              "                      -0.0565, -0.0984,  0.0053, -0.0343, -0.0205, -0.0237, -0.0343, -0.0396,\n",
              "                      -0.0060, -0.0401, -0.0008, -0.0034, -0.0092,  0.0396, -0.0726, -0.1416,\n",
              "                       0.0340, -0.0135, -0.0336, -0.0828, -0.0091, -0.0662,  0.0068,  0.0057,\n",
              "                       0.0360,  0.0468,  0.0080, -0.0312, -0.0472, -0.0182,  0.0024, -0.0489,\n",
              "                       0.0037, -0.0157, -0.0242, -0.0119,  0.0068, -0.0283,  0.0187,  0.0109,\n",
              "                      -0.0747, -0.0761, -0.0445,  0.0110,  0.0257, -0.0923, -0.0221,  0.0157,\n",
              "                      -0.0610, -0.0078, -0.0249, -0.0776,  0.0272, -0.0818,  0.0312, -0.0021,\n",
              "                       0.0774, -0.0521, -0.0672, -0.0886,  0.0773, -0.0669, -0.0094, -0.0284,\n",
              "                      -0.0373,  0.0117,  0.0106,  0.0154,  0.0348, -0.0295, -0.0262,  0.0268,\n",
              "                      -0.0234, -0.0509, -0.0181, -0.0254,  0.0346, -0.0754, -0.0965, -0.0508,\n",
              "                      -0.0281,  0.0125, -0.0202,  0.0165, -0.0097,  0.0012,  0.0194,  0.0183,\n",
              "                      -0.0049, -0.0573, -0.0453, -0.0185, -0.0018, -0.0300, -0.0436, -0.0288,\n",
              "                      -0.0450, -0.0032,  0.0183,  0.0018,  0.0079, -0.0489,  0.0155, -0.0040,\n",
              "                      -0.0048,  0.0330, -0.0316, -0.0249, -0.0608, -0.0019, -0.0503, -0.0318,\n",
              "                       0.0163,  0.0023, -0.0124, -0.0044,  0.0087,  0.0192,  0.0227, -0.0463,\n",
              "                       0.0147, -0.0058, -0.0875,  0.0057,  0.0184,  0.0095,  0.0195,  0.0107,\n",
              "                      -0.0164, -0.0500, -0.0271,  0.0528,  0.0355, -0.0311, -0.0256, -0.0004,\n",
              "                       0.0031,  0.0305, -0.0069, -0.0619, -0.0443, -0.0450, -0.0521, -0.0044,\n",
              "                      -0.0123, -0.0131, -0.0114, -0.0124, -0.0086, -0.0040,  0.0131, -0.0098,\n",
              "                      -0.0376, -0.0661,  0.0086, -0.0519, -0.0327,  0.0272,  0.0281, -0.0297,\n",
              "                      -0.0253, -0.0326,  0.0474,  0.0636, -0.0232,  0.0504, -0.0789, -0.0264,\n",
              "                      -0.0057,  0.0146, -0.0215,  0.0536, -0.0413, -0.0078, -0.0772,  0.1042,\n",
              "                       0.0309,  0.0078,  0.0012,  0.0369, -0.0343, -0.0044,  0.0046, -0.0496,\n",
              "                      -0.0135, -0.0380,  0.0008,  0.0165,  0.0352, -0.0328, -0.0096, -0.0436,\n",
              "                       0.0383, -0.0209,  0.0206, -0.0146, -0.0109, -0.0513, -0.0117, -0.0111,\n",
              "                      -0.0278, -0.0238, -0.1412,  0.0182, -0.0377, -0.0179, -0.0213,  0.0083,\n",
              "                      -0.0125, -0.0419, -0.0707,  0.0378, -0.0589,  0.0116,  0.0588, -0.0439,\n",
              "                       0.0096,  0.0204, -0.0059, -0.0014, -0.0146, -0.0309,  0.0172, -0.0437,\n",
              "                      -0.0625, -0.0197, -0.0108,  0.0047, -0.0796,  0.0183,  0.0157, -0.0014,\n",
              "                      -0.1127, -0.0352, -0.0245, -0.0234,  0.0992, -0.0100, -0.0549, -0.0106,\n",
              "                       0.0242, -0.0391, -0.0342, -0.0718,  0.0117, -0.0130,  0.0607, -0.0686,\n",
              "                       0.0725,  0.0278, -0.0051, -0.0264,  0.0076, -0.0342,  0.0143, -0.0142,\n",
              "                       0.0281,  0.0133, -0.0997,  0.0017, -0.0234,  0.0758, -0.0260, -0.0135,\n",
              "                      -0.0335, -0.0323, -0.0509, -0.0126, -0.0204,  0.0216, -0.0031, -0.0093,\n",
              "                       0.0043, -0.0417, -0.0196, -0.0564, -0.0567, -0.0496, -0.0744, -0.0136,\n",
              "                      -0.0222, -0.0220, -0.0224,  0.0132, -0.0552,  0.0078, -0.0808,  0.0170,\n",
              "                       0.0130, -0.0519,  0.0434,  0.0190,  0.0125, -0.0110, -0.0235,  0.0086,\n",
              "                      -0.0025, -0.0699, -0.0057, -0.0334, -0.0581, -0.0195, -0.0407,  0.0196,\n",
              "                       0.0023, -0.0213, -0.0205, -0.0473, -0.0024, -0.0248, -0.0404, -0.0386,\n",
              "                      -0.0465,  0.0239, -0.0098, -0.0387,  0.0351, -0.0434, -0.0223,  0.0074,\n",
              "                      -0.1343, -0.0361, -0.0034,  0.0170,  0.0220, -0.0536, -0.0312,  0.0258,\n",
              "                      -0.0403, -0.0365, -0.0252, -0.0626, -0.0503,  0.0272, -0.0399, -0.0055,\n",
              "                      -0.0905, -0.0251, -0.0335, -0.0589, -0.0239, -0.0537, -0.0222, -0.0153],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.1.bn2.running_var',\n",
              "              tensor([0.0178, 0.0317, 0.0268, 0.0251, 0.0282, 0.0285, 0.0369, 0.0363, 0.0275,\n",
              "                      0.0294, 0.0270, 0.0281, 0.0284, 0.0202, 0.0331, 0.0224, 0.0313, 0.0304,\n",
              "                      0.0346, 0.0238, 0.0352, 0.0412, 0.0289, 0.0305, 0.0248, 0.0384, 0.0254,\n",
              "                      0.0371, 0.0356, 0.0212, 0.0218, 0.0364, 0.0269, 0.0223, 0.0270, 0.0310,\n",
              "                      0.0267, 0.0324, 0.0241, 0.0183, 0.0269, 0.0337, 0.0252, 0.0286, 0.0241,\n",
              "                      0.0231, 0.0320, 0.0478, 0.0302, 0.0328, 0.0304, 0.0272, 0.0351, 0.0306,\n",
              "                      0.0278, 0.0428, 0.0279, 0.0325, 0.0290, 0.0284, 0.0376, 0.0318, 0.0319,\n",
              "                      0.0348, 0.0260, 0.0267, 0.0236, 0.0350, 0.0344, 0.0242, 0.0275, 0.0215,\n",
              "                      0.0288, 0.0346, 0.0303, 0.0219, 0.0252, 0.0300, 0.0278, 0.0233, 0.0273,\n",
              "                      0.0306, 0.0346, 0.0321, 0.0243, 0.0241, 0.0387, 0.0280, 0.0210, 0.0226,\n",
              "                      0.0191, 0.0308, 0.0278, 0.0441, 0.0240, 0.0227, 0.0260, 0.0265, 0.0259,\n",
              "                      0.0214, 0.0376, 0.0244, 0.0308, 0.0301, 0.0279, 0.0209, 0.0313, 0.0365,\n",
              "                      0.0281, 0.0236, 0.0261, 0.0231, 0.0231, 0.0304, 0.0271, 0.0232, 0.0236,\n",
              "                      0.0325, 0.0294, 0.0280, 0.0283, 0.0247, 0.0329, 0.0208, 0.0303, 0.0252,\n",
              "                      0.0248, 0.0361, 0.0260, 0.0337, 0.0223, 0.0257, 0.0246, 0.0284, 0.0411,\n",
              "                      0.0292, 0.0236, 0.0390, 0.0232, 0.0248, 0.0201, 0.0480, 0.0265, 0.0273,\n",
              "                      0.0290, 0.0402, 0.0308, 0.0221, 0.0275, 0.0301, 0.0329, 0.0291, 0.0294,\n",
              "                      0.0273, 0.0210, 0.0292, 0.0331, 0.0280, 0.0307, 0.0291, 0.0284, 0.0571,\n",
              "                      0.0315, 0.0677, 0.0258, 0.0346, 0.0266, 0.0242, 0.0339, 0.0316, 0.0249,\n",
              "                      0.0278, 0.0346, 0.0190, 0.0258, 0.0232, 0.0239, 0.0284, 0.0312, 0.0323,\n",
              "                      0.0355, 0.0239, 0.0411, 0.0257, 0.0256, 0.0395, 0.0259, 0.0299, 0.0251,\n",
              "                      0.0217, 0.0241, 0.0329, 0.0344, 0.0340, 0.0242, 0.0250, 0.0353, 0.0169,\n",
              "                      0.0282, 0.0281, 0.0295, 0.0375, 0.0310, 0.0184, 0.0333, 0.0259, 0.0327,\n",
              "                      0.0302, 0.0249, 0.0204, 0.0227, 0.0237, 0.0410, 0.0288, 0.0343, 0.0410,\n",
              "                      0.0206, 0.0393, 0.0310, 0.0388, 0.0415, 0.0327, 0.0271, 0.0279, 0.0240,\n",
              "                      0.0219, 0.0279, 0.0199, 0.0264, 0.0253, 0.0268, 0.0205, 0.0280, 0.0375,\n",
              "                      0.0276, 0.0227, 0.0399, 0.0321, 0.0239, 0.0374, 0.0267, 0.0219, 0.0386,\n",
              "                      0.0262, 0.0315, 0.0343, 0.0263, 0.0219, 0.0234, 0.0257, 0.0297, 0.0379,\n",
              "                      0.0558, 0.0410, 0.0305, 0.0366, 0.0363, 0.0342, 0.0287, 0.0363, 0.0274,\n",
              "                      0.0248, 0.0208, 0.0232, 0.0380, 0.0285, 0.0236, 0.0221, 0.0219, 0.0270,\n",
              "                      0.0363, 0.0276, 0.0275, 0.0256, 0.0307, 0.0213, 0.0229, 0.0239, 0.0213,\n",
              "                      0.0241, 0.0304, 0.0307, 0.0246, 0.0336, 0.0307, 0.0342, 0.0348, 0.0187,\n",
              "                      0.0323, 0.0246, 0.0280, 0.0313, 0.0300, 0.0315, 0.0369, 0.0290, 0.0311,\n",
              "                      0.0347, 0.0318, 0.0395, 0.0306, 0.0353, 0.0251, 0.0195, 0.0280, 0.0360,\n",
              "                      0.0264, 0.0229, 0.0323, 0.0302, 0.0306, 0.0408, 0.0247, 0.0234, 0.0245,\n",
              "                      0.0316, 0.0327, 0.0226, 0.0248, 0.0286, 0.0274, 0.0224, 0.0284, 0.0323,\n",
              "                      0.0289, 0.0308, 0.0301, 0.0233, 0.0213, 0.0168, 0.0288, 0.0285, 0.0334,\n",
              "                      0.0369, 0.0247, 0.0370, 0.0263, 0.0397, 0.0334, 0.0296, 0.0283, 0.0196,\n",
              "                      0.0294, 0.0325, 0.0261, 0.0204, 0.0425, 0.0266, 0.0351, 0.0293, 0.0257,\n",
              "                      0.0279, 0.0201, 0.0323, 0.0276, 0.0349, 0.0255, 0.0328, 0.0272, 0.0310,\n",
              "                      0.0272, 0.0297, 0.0332, 0.0223, 0.0327, 0.0214, 0.0244, 0.0323, 0.0226,\n",
              "                      0.0276, 0.0202, 0.0320, 0.0300, 0.0281, 0.0208, 0.0287, 0.0262, 0.0185,\n",
              "                      0.0351, 0.0370, 0.0243, 0.0301, 0.0255, 0.0277, 0.0237, 0.0322, 0.0252,\n",
              "                      0.0381, 0.0218, 0.0253, 0.0265, 0.0243, 0.0247, 0.0258, 0.0285, 0.0291,\n",
              "                      0.0294, 0.0293, 0.0311, 0.0240, 0.0388, 0.0250, 0.0324, 0.0214, 0.0262,\n",
              "                      0.0315, 0.0189, 0.0253, 0.0322, 0.0256, 0.0314, 0.0251, 0.0237, 0.0224,\n",
              "                      0.0226, 0.0240, 0.0255, 0.0284, 0.0212, 0.0324, 0.0245, 0.0286, 0.0202,\n",
              "                      0.0242, 0.0363, 0.0257, 0.0227, 0.0291, 0.0257, 0.0240, 0.0327, 0.0286,\n",
              "                      0.0326, 0.0214, 0.0349, 0.0420, 0.0277, 0.0327, 0.0272, 0.0245, 0.0280,\n",
              "                      0.0207, 0.0228, 0.0321, 0.0404, 0.0232, 0.0303, 0.0304, 0.0348, 0.0381,\n",
              "                      0.0286, 0.0320, 0.0214, 0.0221, 0.0211, 0.0319, 0.0263, 0.0241, 0.0337,\n",
              "                      0.0362, 0.0367, 0.0301, 0.0235, 0.0344, 0.0362, 0.0184, 0.0376, 0.0284,\n",
              "                      0.0281, 0.0289, 0.0239, 0.0225, 0.0244, 0.0231, 0.0270, 0.0284, 0.0293,\n",
              "                      0.0244, 0.0246, 0.0273, 0.0203, 0.0323, 0.0329, 0.0207, 0.0295, 0.0317,\n",
              "                      0.0277, 0.0303, 0.0274, 0.0267, 0.0389, 0.0291, 0.0359, 0.0324, 0.0317,\n",
              "                      0.0374, 0.0230, 0.0314, 0.0316, 0.0332, 0.0325, 0.0234, 0.0263, 0.0206,\n",
              "                      0.0272, 0.0196, 0.0348, 0.0290, 0.0212, 0.0253, 0.0295, 0.0265],\n",
              "                     device='cuda:0')),\n",
              "             ('layer4.1.bn2.num_batches_tracked',\n",
              "              tensor(12039, device='cuda:0')),\n",
              "             ('fc.weight',\n",
              "              tensor([[ 0.0286,  0.0481, -0.0491,  ..., -0.0091, -0.0541,  0.0093],\n",
              "                      [ 0.0006, -0.0542,  0.0121,  ...,  0.0260,  0.0245, -0.0223],\n",
              "                      [-0.0422,  0.0899,  0.0117,  ...,  0.0100,  0.0178,  0.0309],\n",
              "                      ...,\n",
              "                      [ 0.0230,  0.0246,  0.0410,  ...,  0.0139, -0.0443, -0.0331],\n",
              "                      [ 0.0387, -0.0001, -0.0360,  ..., -0.0230,  0.0309,  0.0156],\n",
              "                      [ 0.0186,  0.0231, -0.0094,  ..., -0.0249,  0.0249, -0.0334]],\n",
              "                     device='cuda:0')),\n",
              "             ('fc.bias',\n",
              "              tensor([ 0.0045, -0.0063,  0.0535,  0.0261, -0.0246, -0.0033,  0.0065,  0.0330,\n",
              "                      -0.0232, -0.0068,  0.0562,  0.0184,  0.0445,  0.0472,  0.0286, -0.0110,\n",
              "                      -0.0164, -0.0068,  0.0239, -0.0032,  0.0399,  0.0280,  0.0069, -0.0194,\n",
              "                       0.0217, -0.0215,  0.0089,  0.0361,  0.0239,  0.0002,  0.0221, -0.0070,\n",
              "                       0.0047, -0.0307,  0.0527,  0.0129, -0.0155,  0.0276,  0.0512,  0.0265,\n",
              "                      -0.0049, -0.0115,  0.0012,  0.0398, -0.0272,  0.0081, -0.0236,  0.0070,\n",
              "                       0.0412, -0.0169,  0.0154,  0.0044,  0.0309, -0.0155,  0.0538,  0.0348,\n",
              "                       0.0049,  0.0377,  0.0080, -0.0213,  0.0455,  0.0117,  0.0282,  0.0497,\n",
              "                       0.0346,  0.0383,  0.0111,  0.0174, -0.0262,  0.0162, -0.0218, -0.0278,\n",
              "                      -0.0268,  0.0409, -0.0291,  0.0463,  0.0376,  0.0219, -0.0185,  0.0059,\n",
              "                       0.0084, -0.0180,  0.0287, -0.0034,  0.0218, -0.0215,  0.0433,  0.0507,\n",
              "                       0.0012,  0.0541,  0.0458,  0.0257,  0.0348,  0.0304,  0.0006,  0.0307,\n",
              "                      -0.0290,  0.0033,  0.0530,  0.0053,  0.0278,  0.0197,  0.0163, -0.0436,\n",
              "                       0.0202, -0.0443, -0.0172, -0.0297, -0.0186, -0.0217, -0.0045,  0.0271,\n",
              "                       0.0298, -0.0231, -0.0002, -0.0361,  0.0090, -0.0211,  0.0088,  0.0239,\n",
              "                       0.0062, -0.0019,  0.0117,  0.0034, -0.0235, -0.0180,  0.0040, -0.0188,\n",
              "                      -0.0335, -0.0239, -0.0058, -0.0164, -0.0259,  0.0376, -0.0083, -0.0163,\n",
              "                       0.0117,  0.0425,  0.0419, -0.0454,  0.0022,  0.0077, -0.0011, -0.0143,\n",
              "                       0.0143, -0.0227, -0.0259,  0.0299,  0.0398, -0.0338, -0.0144,  0.0193,\n",
              "                      -0.0316,  0.0075, -0.0258,  0.0089, -0.0364,  0.0189,  0.0377,  0.0295,\n",
              "                       0.0062, -0.0201, -0.0279,  0.0337,  0.0301,  0.0064, -0.0145, -0.0032,\n",
              "                      -0.0174, -0.0188,  0.0347,  0.0017, -0.0324,  0.0166, -0.0315, -0.0279,\n",
              "                      -0.0075, -0.0278, -0.0406,  0.0055,  0.0054,  0.0274,  0.0391, -0.0008,\n",
              "                      -0.0245,  0.0185,  0.0092, -0.0050,  0.0014, -0.0123,  0.0332,  0.0400,\n",
              "                      -0.0110,  0.0244, -0.0295, -0.0037, -0.0045, -0.0308,  0.0211, -0.0215,\n",
              "                       0.0089, -0.0207, -0.0132,  0.0157, -0.0052,  0.0151,  0.0141, -0.0002,\n",
              "                      -0.0191, -0.0342,  0.0368, -0.0415,  0.0252,  0.0227, -0.0385,  0.0387,\n",
              "                      -0.0302, -0.0087,  0.0126, -0.0327, -0.0200,  0.0163,  0.0121,  0.0367,\n",
              "                      -0.0381,  0.0328, -0.0342, -0.0082, -0.0170,  0.0043, -0.0281,  0.0245,\n",
              "                      -0.0010, -0.0136, -0.0075, -0.0276,  0.0068, -0.0336,  0.0340, -0.0340,\n",
              "                      -0.0269,  0.0048,  0.0400, -0.0435, -0.0331,  0.0333,  0.0181, -0.0018,\n",
              "                       0.0273,  0.0000, -0.0106, -0.0189,  0.0192,  0.0416, -0.0008,  0.0069,\n",
              "                       0.0318,  0.0138,  0.0215, -0.0154,  0.0043,  0.0351,  0.0098,  0.0123,\n",
              "                      -0.0373, -0.0355,  0.0118, -0.0368,  0.0264, -0.0345,  0.0410, -0.0346,\n",
              "                       0.0212,  0.0219, -0.0204,  0.0323, -0.0270,  0.0402, -0.0421,  0.0131,\n",
              "                      -0.0388, -0.0207, -0.0301, -0.0425,  0.0269,  0.0032, -0.0159,  0.0205,\n",
              "                      -0.0318, -0.0447,  0.0304,  0.0087,  0.0111, -0.0036, -0.0404,  0.0270,\n",
              "                       0.0266, -0.0165, -0.0220,  0.0137, -0.0270, -0.0145, -0.0214,  0.0070,\n",
              "                      -0.0322, -0.0070, -0.0001,  0.0351, -0.0424, -0.0323,  0.0236, -0.0026,\n",
              "                       0.0064,  0.0293, -0.0196, -0.0114, -0.0240,  0.0294,  0.0300, -0.0438,\n",
              "                       0.0012,  0.0208,  0.0206,  0.0305, -0.0263,  0.0066,  0.0338,  0.0380,\n",
              "                       0.0017,  0.0143,  0.0042, -0.0081, -0.0305,  0.0322, -0.0270, -0.0425,\n",
              "                      -0.0288,  0.0157, -0.0417, -0.0042, -0.0303,  0.0366,  0.0253,  0.0097,\n",
              "                       0.0346, -0.0138,  0.0299,  0.0010,  0.0197,  0.0016, -0.0414,  0.0216,\n",
              "                      -0.0151, -0.0224,  0.0039,  0.0336, -0.0270,  0.0416, -0.0050, -0.0338,\n",
              "                       0.0135,  0.0022,  0.0378, -0.0135, -0.0139,  0.0103, -0.0051,  0.0188,\n",
              "                       0.0222, -0.0419,  0.0414, -0.0237, -0.0287,  0.0101,  0.0141, -0.0148,\n",
              "                       0.0178, -0.0008,  0.0188,  0.0294, -0.0446,  0.0219,  0.0372, -0.0297,\n",
              "                       0.0159, -0.0248, -0.0293, -0.0453, -0.0137,  0.0189,  0.0215, -0.0036,\n",
              "                      -0.0132, -0.0369, -0.0230,  0.0184,  0.0306, -0.0041,  0.0131, -0.0327,\n",
              "                      -0.0229,  0.0348, -0.0203, -0.0271, -0.0322, -0.0427, -0.0172,  0.0220,\n",
              "                       0.0271, -0.0305,  0.0118, -0.0222, -0.0082,  0.0276,  0.0372, -0.0011,\n",
              "                      -0.0037,  0.0249, -0.0202,  0.0008,  0.0374,  0.0411, -0.0134,  0.0010,\n",
              "                      -0.0295,  0.0076,  0.0035,  0.0420, -0.0117,  0.0315,  0.0048,  0.0316,\n",
              "                      -0.0365, -0.0047,  0.0075, -0.0105, -0.0155, -0.0039,  0.0210,  0.0237,\n",
              "                       0.0275, -0.0054, -0.0406, -0.0079, -0.0308, -0.0168, -0.0372,  0.0034,\n",
              "                      -0.0354,  0.0162, -0.0453,  0.0125, -0.0440,  0.0137, -0.0188, -0.0040,\n",
              "                      -0.0427, -0.0229, -0.0261, -0.0002, -0.0031,  0.0307, -0.0039,  0.0129,\n",
              "                       0.0183,  0.0322, -0.0222,  0.0128,  0.0172, -0.0215,  0.0228,  0.0088,\n",
              "                       0.0224,  0.0280,  0.0385, -0.0316,  0.0409,  0.0120,  0.0014, -0.0271,\n",
              "                      -0.0130, -0.0133, -0.0359,  0.0070, -0.0079,  0.0161, -0.0356,  0.0144,\n",
              "                      -0.0270,  0.0075, -0.0248,  0.0159,  0.0173,  0.0087,  0.0083, -0.0105,\n",
              "                      -0.0368,  0.0350,  0.0004, -0.0377,  0.0330,  0.0128,  0.0256,  0.0393,\n",
              "                      -0.0055,  0.0236,  0.0138,  0.0059,  0.0058, -0.0230, -0.0175, -0.0418,\n",
              "                       0.0257, -0.0274, -0.0138, -0.0064,  0.0331,  0.0139, -0.0171,  0.0336,\n",
              "                      -0.0322, -0.0407, -0.0236, -0.0391,  0.0244, -0.0339, -0.0191,  0.0302,\n",
              "                       0.0315,  0.0237, -0.0119,  0.0284, -0.0174, -0.0411, -0.0243, -0.0057,\n",
              "                      -0.0450, -0.0177, -0.0156,  0.0154,  0.0412,  0.0423, -0.0008, -0.0152,\n",
              "                      -0.0318,  0.0333,  0.0387,  0.0010,  0.0024, -0.0369, -0.0209, -0.0323,\n",
              "                       0.0151, -0.0413, -0.0007,  0.0127, -0.0362,  0.0132,  0.0361, -0.0121,\n",
              "                       0.0338, -0.0262, -0.0329, -0.0016, -0.0283, -0.0120,  0.0230,  0.0419,\n",
              "                       0.0398, -0.0410,  0.0054, -0.0054,  0.0259, -0.0257, -0.0251, -0.0252,\n",
              "                       0.0193,  0.0313,  0.0174,  0.0063, -0.0160,  0.0096, -0.0202, -0.0446,\n",
              "                      -0.0089, -0.0320,  0.0085,  0.0160, -0.0393,  0.0211,  0.0024,  0.0401,\n",
              "                       0.0428, -0.0266,  0.0244,  0.0165,  0.0330, -0.0086,  0.0093,  0.0362,\n",
              "                      -0.0257, -0.0121, -0.0191, -0.0360, -0.0341,  0.0281, -0.0306, -0.0180,\n",
              "                       0.0058,  0.0038, -0.0108,  0.0212,  0.0318,  0.0010,  0.0369,  0.0349,\n",
              "                      -0.0289, -0.0387, -0.0412,  0.0101, -0.0429, -0.0449,  0.0381,  0.0062,\n",
              "                      -0.0273, -0.0447, -0.0376, -0.0219, -0.0346, -0.0164,  0.0221, -0.0146,\n",
              "                      -0.0039,  0.0333,  0.0253, -0.0116, -0.0287, -0.0259,  0.0290, -0.0381,\n",
              "                       0.0322,  0.0360, -0.0208, -0.0266,  0.0173,  0.0279, -0.0300, -0.0329,\n",
              "                      -0.0430,  0.0077, -0.0418, -0.0366, -0.0182,  0.0013,  0.0410, -0.0097,\n",
              "                      -0.0214, -0.0352,  0.0124,  0.0317,  0.0079, -0.0071,  0.0024,  0.0398,\n",
              "                       0.0420, -0.0076,  0.0284, -0.0349,  0.0358, -0.0173, -0.0134, -0.0302,\n",
              "                       0.0018,  0.0391, -0.0139,  0.0016, -0.0388, -0.0201, -0.0443, -0.0298,\n",
              "                      -0.0091,  0.0271,  0.0314,  0.0268,  0.0068, -0.0356, -0.0219,  0.0314,\n",
              "                      -0.0142, -0.0074, -0.0102, -0.0252, -0.0285, -0.0066,  0.0150,  0.0100,\n",
              "                      -0.0063, -0.0262, -0.0033,  0.0078,  0.0009, -0.0215,  0.0160, -0.0390,\n",
              "                       0.0118, -0.0380,  0.0376, -0.0428,  0.0141, -0.0318,  0.0186,  0.0219,\n",
              "                      -0.0375, -0.0348,  0.0092, -0.0014, -0.0385, -0.0105, -0.0424,  0.0396,\n",
              "                      -0.0377, -0.0220, -0.0100, -0.0359,  0.0100, -0.0179, -0.0277,  0.0080,\n",
              "                      -0.0361, -0.0293,  0.0079, -0.0055, -0.0158,  0.0360,  0.0006, -0.0025,\n",
              "                       0.0039, -0.0328, -0.0220,  0.0285, -0.0276, -0.0027,  0.0143, -0.0303,\n",
              "                      -0.0106, -0.0451,  0.0291, -0.0212, -0.0050,  0.0044, -0.0292,  0.0123,\n",
              "                       0.0410, -0.0200,  0.0385,  0.0209, -0.0439, -0.0034,  0.0009,  0.0241,\n",
              "                       0.0167,  0.0237, -0.0013, -0.0364, -0.0189, -0.0412, -0.0056,  0.0162,\n",
              "                      -0.0366, -0.0085, -0.0169, -0.0396, -0.0127, -0.0052,  0.0046,  0.0424,\n",
              "                       0.0420,  0.0107,  0.0238,  0.0131,  0.0065,  0.0287, -0.0052, -0.0113,\n",
              "                      -0.0174, -0.0200,  0.0255, -0.0358, -0.0442,  0.0186,  0.0148,  0.0241,\n",
              "                      -0.0080, -0.0202,  0.0219, -0.0107,  0.0132, -0.0326,  0.0145,  0.0165,\n",
              "                       0.0051,  0.0428, -0.0126,  0.0272,  0.0236,  0.0038,  0.0256, -0.0103,\n",
              "                      -0.0124, -0.0066,  0.0360, -0.0445,  0.0357, -0.0357, -0.0171, -0.0021,\n",
              "                       0.0342, -0.0340, -0.0382,  0.0108,  0.0092,  0.0035,  0.0039,  0.0108,\n",
              "                       0.0112, -0.0223, -0.0037,  0.0137,  0.0021,  0.0372, -0.0297,  0.0278,\n",
              "                       0.0004, -0.0224, -0.0204,  0.0099,  0.0175,  0.0365,  0.0354,  0.0219,\n",
              "                       0.0372, -0.0378,  0.0410,  0.0264, -0.0071,  0.0232, -0.0404,  0.0268,\n",
              "                      -0.0065, -0.0361, -0.0092, -0.0273, -0.0350, -0.0031, -0.0036, -0.0004,\n",
              "                      -0.0317,  0.0099, -0.0264,  0.0160, -0.0049,  0.0132, -0.0418,  0.0405,\n",
              "                       0.0356,  0.0155, -0.0110, -0.0142,  0.0227,  0.0374,  0.0027, -0.0029,\n",
              "                       0.0340, -0.0411, -0.0140,  0.0386,  0.0082, -0.0267,  0.0122,  0.0040,\n",
              "                      -0.0160,  0.0217,  0.0094,  0.0411,  0.0023, -0.0404,  0.0363, -0.0140,\n",
              "                      -0.0148,  0.0359, -0.0023, -0.0269,  0.0170, -0.0228, -0.0320,  0.0354,\n",
              "                      -0.0098, -0.0126,  0.0272,  0.0144,  0.0338,  0.0039, -0.0019, -0.0298,\n",
              "                       0.0133, -0.0125, -0.0368, -0.0442, -0.0017, -0.0399,  0.0123,  0.0273,\n",
              "                      -0.0002,  0.0073,  0.0308,  0.0134,  0.0123,  0.0150, -0.0024,  0.0414,\n",
              "                       0.0243,  0.0143, -0.0259, -0.0269, -0.0451, -0.0362, -0.0112, -0.0250,\n",
              "                       0.0278, -0.0049,  0.0285,  0.0311,  0.0169, -0.0289, -0.0118, -0.0428,\n",
              "                      -0.0194, -0.0401, -0.0093, -0.0406,  0.0119,  0.0343,  0.0068,  0.0211,\n",
              "                       0.0360,  0.0056,  0.0406,  0.0381,  0.0198, -0.0454,  0.0069,  0.0215,\n",
              "                       0.0360, -0.0202,  0.0379,  0.0384,  0.0204,  0.0141,  0.0402, -0.0105,\n",
              "                      -0.0316,  0.0324,  0.0398, -0.0433,  0.0299, -0.0033,  0.0405,  0.0033,\n",
              "                      -0.0236,  0.0072, -0.0159, -0.0212,  0.0065,  0.0191, -0.0394,  0.0119,\n",
              "                      -0.0114, -0.0437, -0.0416, -0.0392, -0.0046,  0.0181,  0.0254,  0.0377,\n",
              "                       0.0310,  0.0253,  0.0095, -0.0325, -0.0027,  0.0298,  0.0412, -0.0421,\n",
              "                       0.0267,  0.0185, -0.0007,  0.0364,  0.0319, -0.0300, -0.0133, -0.0441],\n",
              "                     device='cuda:0'))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "k1QqyrwG3Kt_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Inference for classification\n",
        "\n",
        "Now you'll write a function to use a trained network for inference. That is, you'll pass an image into the network and predict the class of the flower in the image. Write a function called `predict` that takes an image and a model, then returns the top $K$ most likely classes along with the probabilities. It should look like \n",
        "\n",
        "```python\n",
        "probs, classes = predict(image_path, model)\n",
        "print(probs)\n",
        "print(classes)\n",
        "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
        "> ['70', '3', '45', '62', '55']\n",
        "```\n",
        "\n",
        "First you'll need to handle processing the input image such that it can be used in your network. \n",
        "\n",
        "## Image Preprocessing\n",
        "\n",
        "You'll want to use `PIL` to load the image ([documentation](https://pillow.readthedocs.io/en/latest/reference/Image.html)). It's best to write a function that preprocesses the image so it can be used as input for the model. This function should process the images in the same manner used for training. \n",
        "\n",
        "First, resize the images where the shortest side is 256 pixels, keeping the aspect ratio. This can be done with the [`thumbnail`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) or [`resize`](http://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.thumbnail) methods. Then you'll need to crop out the center 224x224 portion of the image.\n",
        "\n",
        "Color channels of images are typically encoded as integers 0-255, but the model expected floats 0-1. You'll need to convert the values. It's easiest with a Numpy array, which you can get from a PIL image like so `np_image = np.array(pil_image)`.\n",
        "\n",
        "As before, the network expects the images to be normalized in a specific way. For the means, it's `[0.485, 0.456, 0.406]` and for the standard deviations `[0.229, 0.224, 0.225]`. You'll want to subtract the means from each color channel, then divide by the standard deviation. \n",
        "\n",
        "And finally, PyTorch expects the color channel to be the first dimension but it's the third dimension in the PIL image and Numpy array. You can reorder dimensions using [`ndarray.transpose`](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.ndarray.transpose.html). The color channel needs to be first and retain the order of the other two dimensions."
      ]
    },
    {
      "metadata": {
        "id": "8FuziAdu3KuA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
        "        returns an Numpy array\n",
        "    '''\n",
        "    \n",
        "    # TODO: Process a PIL image for use in a PyTorch model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vh-4XSJZ3KuD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To check your work, the function below converts a PyTorch tensor and displays it in the notebook. If your `process_image` function works, running the output through this function should return the original image (except for the cropped out portions)."
      ]
    },
    {
      "metadata": {
        "id": "Amoybpeo3KuD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imshow(image, ax=None, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    if ax is None:\n",
        "        fig, ax = plt.subplots()\n",
        "    \n",
        "    # PyTorch tensors assume the color channel is the first dimension\n",
        "    # but matplotlib assumes is the third dimension\n",
        "    image = image.numpy().transpose((1, 2, 0))\n",
        "    \n",
        "    # Undo preprocessing\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    image = std * image + mean\n",
        "    \n",
        "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
        "    image = np.clip(image, 0, 1)\n",
        "    \n",
        "    ax.imshow(image)\n",
        "    \n",
        "    return ax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PNUU_TQu3KuG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Class Prediction\n",
        "\n",
        "Once you can get images in the correct format, it's time to write a function for making predictions with your model. A common practice is to predict the top 5 or so (usually called top-$K$) most probable classes. You'll want to calculate the class probabilities then find the $K$ largest values.\n",
        "\n",
        "To get the top $K$ largest values in a tensor use [`x.topk(k)`](http://pytorch.org/docs/master/torch.html#torch.topk). This method returns both the highest `k` probabilities and the indices of those probabilities corresponding to the classes. You need to convert from these indices to the actual class labels using `class_to_idx` which hopefully you added to the model or from an `ImageFolder` you used to load the data ([see here](#Save-the-checkpoint)). Make sure to invert the dictionary so you get a mapping from index to class as well.\n",
        "\n",
        "Again, this method should take a path to an image and a model checkpoint, then return the probabilities and classes.\n",
        "\n",
        "```python\n",
        "probs, classes = predict(image_path, model)\n",
        "print(probs)\n",
        "print(classes)\n",
        "> [ 0.01558163  0.01541934  0.01452626  0.01443549  0.01407339]\n",
        "> ['70', '3', '45', '62', '55']\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "ZlgLO1653KuH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(image_path, model, topk=5):\n",
        "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
        "    '''\n",
        "    \n",
        "    # TODO: Implement the code to predict the class from an image file"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b5qmbXst3KuJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Sanity Checking\n",
        "\n",
        "Now that you can use a trained model for predictions, check to make sure it makes sense. Even if the validation accuracy is high, it's always good to check that there aren't obvious bugs. Use `matplotlib` to plot the probabilities for the top 5 classes as a bar graph, along with the input image. It should look like this:\n",
        "\n",
        "<img src='https://github.com/udacity/pytorch_challenge/blob/master/assets/inference_example.png?raw=1' width=300px>\n",
        "\n",
        "You can convert from the class integer encoding to actual flower names with the `cat_to_name.json` file (should have been loaded earlier in the notebook). To show a PyTorch tensor as an image, use the `imshow` function defined above."
      ]
    },
    {
      "metadata": {
        "id": "QmjvEOpx3KuK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TODO: Display an image along with the top 5 classes"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}