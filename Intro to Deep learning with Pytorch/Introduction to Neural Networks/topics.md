## Introduction to Neural Networks

## Check your understanding 
### Give yourself 1 point if you are able to answer the question in simple words
### If you get less than 20 marks you need to revisit the chapter again
### If you score more than 25 you have good grip over lesson 2
1. What is a Neural Network?

2. What is a classification problem and types?
3. Discuss perceptrons
4. Why Neural network?
5. Peceptrons as logical operators
6. What is the perceptron trick?
7. Explain perceptron algorithm?
8. How to use perceptron for Non-linear regions?
9. What is Error function and give types
10. Explain Log loss error function in detail
11. Discussed Discrete and Continuous error function
12. Softmax, One-hot encoding and its need
13. Maximum likelyhood and maximum probabilities
14. What is Cross-entropy? (Event and likelyhood)
15. Multi-class cross entropy
16. Explain Logistic regression, algorithm.
17. Math behind gradient descent
18. Non-linear data, models and Neural network architecture (Multilayer perceptron)
19. Theory and math behind - Feedforward, Backpropagation, training optimization models
20. How Overfitting and underfitting affects the model?
21. What is Early stopping (using Model complexity graphs - error v/s number of epochs)
22. How Regularization helps the model? Problem: which gives a smaller error - `x1 + x2` or `10x1 + 10x2`
23. Another way to avoid overfitting?
24. What is local minima and how to avoid it?
25. How to fix Vanishing gradient problem? Will having another activation function help?
26. Difference between Batch and stochastic gradient descent
27. What is the best learning rate? Is varying learning rate useful?
28. Local minimum can be avoided by momentum, True or false. Also state the formula
29. Give point if you know more than 3 error functions?
